#!/usr/bin/env bash
# This script was generated by bashly 1.0.4 (https://bashly.dannyb.co)
# Modifying it manually is not recommended

# :wrapper.bash3_bouncer
if [[ "${BASH_VERSINFO:-0}" -lt 4 ]]; then
  printf "bash version 4 or higher is required\n" >&2
  exit 1
fi

# :command.master_script

# :command.version_command
version_command() {
  echo "$version"
}

# :command.usage
playground_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground\n"
    echo

    printf "  🧠 CLI for Kafka Docker Playground 🐳\n  \n  👉 Check documentation https://kafka-docker-playground.io/#/cli\n"
    echo

  else
    printf "playground - 🧠 CLI for Kafka Docker Playground 🐳\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground COMMAND\n"
  printf "  playground [COMMAND] --help | -h\n"
  printf "  playground --version | -v\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "Run commands:")"
  printf "  %s   🕹️ Run any example, except for Confluent Cloud (in this case use run-ccloud command)\n" "$(green "run")                               "
  printf "  %s   ⚡ Simply re-run last example you ran with <playground run> or <playground run-ccloud>\n" "$(green "re-run")                            "
  printf "  %s   ⛅ Run any Confluent Cloud (ccloud) example\n" "$(green "run-ccloud")                        "
  printf "  %s   👐 When --file is not provided, simply open last example you ran with <playground run> or <playground run-ccloud>\n" "$(green "open")                              "
  printf "  %s   🛑 Stop currently running example\n" "$(green "stop")                              "
  echo
  printf "%s\n" "$(bold "Bootstrap commands:")"
  printf "  %s   🛠  Bootstrap reproduction model\n" "$(green "bootstrap-reproduction-model")      "
  echo
  printf "%s\n" "$(bold "Kafka commands:")"
  printf "  %s   📝 Get properties file from a container\n" "$(green "get-properties")                    "
  printf "  %s   🔰 Get all schemas versions for all subjects\n" "$(green "get-all-schemas")                   "
  printf "  %s   🔢 Get JMX metrics from a component\n" "$(green "get-jmx-metrics")                   "
  echo
  printf "%s\n" "$(bold "Debug commands:")"
  printf "  %s   ✨ Enable java remote debugging for container\n" "$(green "enable-remote-debugging")           "
  printf "  %s   🧬 Set log level for any package\n" "$(green "log-level")                         "
  echo
  printf "%s\n" "$(bold "Container commands:")"
  printf "  %s   🐳 Container commands\n" "$(green "container")                         "
  [[ -n $long_usage ]] && printf "  %s   💫 Recreate container(s)\n" "$(green "container recreate")                "
  [[ -n $long_usage ]] && printf "  %s   🖥️  Get ip address of running containers\n" "$(green "container get-ip-addresses")        "
  [[ -n $long_usage ]] && printf "  %s   💀 Kill all containers\n" "$(green "container kill-all")                "
  [[ -n $long_usage ]] && printf "  %s   🕵️  Tail and follow container logs\n" "$(green "container logs")                    "
  [[ -n $long_usage ]] && printf "  %s   🛬 SSH into container\n" "$(green "container ssh")                     "
  [[ -n $long_usage ]] && printf "  %s   🪄  Execute command in a container\n" "$(green "container exec")                    "
  [[ -n $long_usage ]] && printf "  %s   🔁 Restart a container\n" "$(green "container restart")                 "
  [[ -n $long_usage ]] && printf "  %s   ⏸️  Pause a container\n" "$(green "container pause")                   "
  [[ -n $long_usage ]] && printf "  %s   ⏯️  Resume a container\n" "$(green "container resume")                  "
  [[ -n $long_usage ]] && printf "  %s   🔫 Kill a container\n" "$(green "container kill")                    "
  echo
  printf "%s\n" "$(bold "Topic commands:")"
  printf "  %s   🗳 Topic commands\n" "$(green "topic")                             "
  [[ -n $long_usage ]] && printf "  %s   💯 Get number of records in a topic\n" "$(green "topic get-number-records")          "
  [[ -n $long_usage ]] && printf "  %s   📭 Display content of __consumer_offsets topic\n" "$(green "topic display-consumer-offsets")    "
  [[ -n $long_usage ]] && printf "  %s   🔬 Describe topic\n" "$(green "topic describe")                    "
  [[ -n $long_usage ]] && printf "  %s   📥 Consume topic from beginning\n" "$(green "topic consume")                     "
  [[ -n $long_usage ]] && printf "  %s   🛡️ Change topic's schema compatibility\n" "$(green "topic set-schema-compatibility")    "
  [[ -n $long_usage ]] && printf "  %s   🧞 Easily identify the usage of different schema versions within a topic.\n" "$(green "topic display-schema-id-statistics")"
  echo
  printf "%s\n" "$(bold "Connector commands:")"
  printf "  %s   🔗 Connector commands\n" "$(green "connector")                         "
  [[ -n $long_usage ]] && printf "  %s   🧩 Show status of all connectors\n" "$(green "connector status")                  "
  [[ -n $long_usage ]] && printf "  %s   🎨 Show all plugins installed\n" "$(green "connector plugins")                 "
  [[ -n $long_usage ]] && printf "  %s   ⏸️  Pause connector\n" "$(green "connector pause")                   "
  [[ -n $long_usage ]] && printf "  %s   🧞 Get current and latest version available on Confluent Hub for connector(s) used in example\n" "$(green "connector versions")                "
  [[ -n $long_usage ]] && printf "  %s   ♻️  Restart connector\n" "$(green "connector restart")                 "
  [[ -n $long_usage ]] && printf "  %s   ⏯️  Resume connector\n" "$(green "connector resume")                  "
  [[ -n $long_usage ]] && printf "  %s   🗑️  Delete connector\n" "$(green "connector delete")                  "
  [[ -n $long_usage ]] && printf "  %s   🐢 Show lag of sink connector\n" "$(green "connector show-lag")                "
  [[ -n $long_usage ]] && printf "  %s   🧬 Set connect log level\n" "$(green "connector log-level")               "
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo
    printf "  %s\n" "$(magenta "--version, -v")"
    printf "    Show version number\n"
    echo

  fi
}

# :command.usage
playground_get_connector_list_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-connector-list - Return some completion for connector list\n"
    echo

  else
    printf "playground get-connector-list - Return some completion for connector list\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-connector-list\n"
  printf "  playground get-connector-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_get_kafka_region_list_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-kafka-region-list - Return some completion for confluent cloud kafka cluster region list\n"
    echo

  else
    printf "playground get-kafka-region-list - Return some completion for confluent cloud kafka cluster region list\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-kafka-region-list\n"
  printf "  playground get-kafka-region-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_get_topic_list_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-topic-list - Return some completion for topic list\n"
    echo

  else
    printf "playground get-topic-list - Return some completion for topic list\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-topic-list [OPTIONS]\n"
  printf "  playground get-topic-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--skip-connect-internal-topics")"
    printf "\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_get_examples_list_with_fzf_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-examples-list-with-fzf - Return some completion for examples list\n"
    echo

  else
    printf "playground get-examples-list-with-fzf - Return some completion for examples list\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-examples-list-with-fzf [CUR] [OPTIONS]\n"
  printf "  playground get-examples-list-with-fzf --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--without-repro")"
    printf "\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--sink-only")"
    printf "\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--ccloud-only")"
    printf "\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_get_zip_or_jar_with_fzf_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-zip-or-jar-with-fzf - Return some completion for zip or jar list\n"
    echo

  else
    printf "playground get-zip-or-jar-with-fzf - Return some completion for zip or jar list\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-zip-or-jar-with-fzf [CUR] [OPTIONS]\n"
  printf "  playground get-zip-or-jar-with-fzf --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--type TYPE")"
    printf "\n"
    printf "    Allowed: zip, jar\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_get_any_file_with_fzf_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-any-file-with-fzf - Return some completion for any files\n"
    echo

  else
    printf "playground get-any-file-with-fzf - Return some completion for any files\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-any-file-with-fzf [CUR]\n"
  printf "  playground get-any-file-with-fzf --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_bashly_reload_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground bashly-reload\n"
    echo

  else
    printf "playground bashly-reload\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground bashly-reload\n"
  printf "  playground bashly-reload --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_run_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground run - 🕹️ Run any example, except for Confluent Cloud (in this case use run-ccloud command)\n"
    echo

  else
    printf "playground run - 🕹️ Run any example, except for Confluent Cloud (in this case use run-ccloud command)\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground run [OPTIONS] [ARGUMENTS...]\n"
  printf "  playground run --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--file, -f FILE (required)")"
    printf "    🔖 Example file to run\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--open, -o")"
    printf "    📖 Opening example file with text editor set with config.ini (default is\n    code)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--tag TAG")"
    printf "    🎯 Confluent Platform (CP) version to use\n    \n    Must be greater or equal to 5.0.0\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-tag CONNECTOR_TAG")"
    printf "    🔗 Connector version to use\n    \n    By default, for each connector, the latest available version on Confluent\n    Hub is used\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-zip CONNECTOR_ZIP")"
    printf "    🤐 Connector zip to use\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion \n            use folder_zip_or_jar (default: ~/Downloads) in config.ini file to\n    configure where to search the files (current folder is always used)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-jar CONNECTOR_JAR")"
    printf "    ♨️ Connector jar to use\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion \n            use folder_zip_or_jar (default: ~/Downloads) in config.ini file to\n    configure where to search the files (current folder is always used)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-ksqldb")"
    printf "    🚀 Enable ksqlDB\n    \n    By default, ksqldb-server and ksqldb-cli containers are not started for\n    every test\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-control-center")"
    printf "    💠 Enable Control Center\n    \n    By default, control-center container is not started for every test\n    \n    Control Center is reachable at http://127.0.0.1:9021\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-conduktor")"
    printf "    🐺 Enable Conduktor Platform\n    \n    By default, Conduktor Platform container is not started for every test\n    \n    Conduktor is reachable at http://127.0.0.1:8080/console (admin/admin)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-multiple-brokers")"
    printf "    3️⃣ Enable multiple brokers\n    \n    By default, there is only one broker node enabled\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-multiple-connect-workers")"
    printf "    🥉 Enable multiple connect node\n    \n    By default, there is only one connect node enabled\n    \n    It only works when plaintext environment is used\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-jmx-grafana")"
    printf "    Enable Grafana, Prometheus and Pyroscope\n    \n    📊 Grafana is reachable at http://127.0.0.1:3000\n    🛡️ Prometheus is reachable at http://127.0.0.1:9090\n    📛 Pyroscope is reachable at http://127.0.0.1:4040\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-kcat")"
    printf "    🐈‍⬛ Enable kcat\n    \n    You can use it with:\n    \n    $ docker exec kcat kcat -b broker:9092 -L\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-sr-maven-plugin-app")"
    printf "    🔰 Enable Schema Registry Maven plugin App\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-sql-datagen")"
    printf "    🌪️ Enable SQL Datagen injection\n    \n    This only works for Oracle, MySql, Postgres and Microsoft Sql Server source\n    connector examples with JDBC and Debezium\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    echo "  ARGUMENTS..."
    printf "    Arguments to use by example script\n    \n    Most of examples support to get required options either by using arguments\n    or environment variables.\n    \n    Example with Zendesk:\n    \n    playground run -f zendesk-source<tab> <ZENDESK_URL> <ZENDESK_USERNAME>\n    <ZENDESK_PASSWORD>\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground run -f zendesk-source<tab> --tag 7.2.1 --enable-control-center\n  <ZENDESK_URL> <ZENDESK_USERNAME> <ZENDESK_PASSWORD>\n"
    printf "  playground run -f jdbc<tab> --connector-tag 10.6.0 --enable-jmx-grafana --open\n"
    echo

  fi
}

# :command.usage
playground_re_run_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground re-run - ⚡ Simply re-run last example you ran with <playground run> or <playground run-ccloud>\n"
    echo

  else
    printf "playground re-run - ⚡ Simply re-run last example you ran with <playground run> or <playground run-ccloud>\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground re-run [OPTIONS] [ARGUMENTS...]\n"
  printf "  playground re-run --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--tag TAG")"
    printf "    🎯 Confluent Platform (CP) version to use\n    \n    Must be greater or equal to 5.0.0\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-tag CONNECTOR_TAG")"
    printf "    🔗 Connector version to use\n    \n    By default, for each connector, the latest available version on Confluent\n    Hub is used\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-zip CONNECTOR_ZIP")"
    printf "    🤐 Connector zip to use\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion \n            use folder_zip_or_jar (default: ~/Downloads) in config.ini file to\n    configure where to search the files (current folder is always used)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-jar CONNECTOR_JAR")"
    printf "    ♨️ Connector jar to use\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion \n            use folder_zip_or_jar (default: ~/Downloads) in config.ini file to\n    configure where to search the files (current folder is always used)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-ksqldb")"
    printf "    🚀 Enable ksqlDB\n    \n    By default, ksqldb-server and ksqldb-cli containers are not started for\n    every test\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-control-center")"
    printf "    💠 Enable Control Center\n    \n    By default, control-center container is not started for every test\n    \n    Control Center is reachable at http://127.0.0.1:9021\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-conduktor")"
    printf "    🐺 Enable Conduktor Platform\n    \n    By default, Conduktor Platform container is not started for every test\n    \n    Conduktor is reachable at http://127.0.0.1:8080/console (admin/admin)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-multiple-brokers")"
    printf "    3️⃣ Enable multiple brokers\n    \n    By default, there is only one broker node enabled\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-multiple-connect-workers")"
    printf "    🥉 Enable multiple connect node\n    \n    By default, there is only one connect node enabled\n    \n    It only works when plaintext environment is used\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-jmx-grafana")"
    printf "    Enable Grafana, Prometheus and Pyroscope\n    \n    📊 Grafana is reachable at http://127.0.0.1:3000\n    🛡️ Prometheus is reachable at http://127.0.0.1:9090\n    📛 Pyroscope is reachable at http://127.0.0.1:4040\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-kcat")"
    printf "    🐈‍⬛ Enable kcat\n    \n    You can use it with:\n    \n    $ docker exec kcat kcat -b broker:9092 -L\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-sr-maven-plugin-app")"
    printf "    🔰 Enable Schema Registry Maven plugin App\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-sql-datagen")"
    printf "    🌪️ Enable SQL Datagen injection\n    \n    This only works for Oracle, MySql, Postgres and Microsoft Sql Server source\n    connector examples with JDBC and Debezium\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    echo "  ARGUMENTS..."
    printf "    Arguments to use by example script\n    \n    Most of examples support to get required options either by using arguments\n    or environment variables.\n    \n    Example with Zendesk:\n    \n    playground run -f zendesk-source<tab> <ZENDESK_URL> <ZENDESK_USERNAME>\n    <ZENDESK_PASSWORD>\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground re-run\n"
    printf "  playground re-run --tag=6.2.1\n"
    echo

  fi
}

# :command.usage
playground_run_ccloud_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground run-ccloud\n"
    echo

    printf "  ⛅ Run any Confluent Cloud (ccloud) example\n  \n  All you have to do is to be already logged in with confluent CLI.\n  \n  By default, a new Confluent Cloud environment with a Cluster will be created.\n  \n  You can configure the new cluster by setting:\n  \n  --cluster-cloud (or CLUSTER_CLOUD environment variable)\n  --cluster-region (or CLUSTER_REGION environment variable)\n  --cluster-environment (or ENVIRONMENT environment variable)\n  \n  In case you want to use your own existing cluster, you need to setup, in\n  addition to previous ones:\n  \n  --cluster-name (or CLUSTER_NAME environment variable)\n  --cluster-creds (or CLUSTER_CREDS environment variable)\n  --cluster-schema-registry-creds (or SCHEMA_REGISTRY_CREDS environment\n  variable)\n"
    echo

  else
    printf "playground run-ccloud - ⛅ Run any Confluent Cloud (ccloud) example\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground run-ccloud [OPTIONS] [ARGUMENTS...]\n"
  printf "  playground run-ccloud --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--file, -f FILE (required)")"
    printf "    🔖 Example file to run\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--open, -o")"
    printf "    📖 Opening example file with text editor set with config.ini (default is\n    code)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--tag TAG")"
    printf "    🎯 Confluent Platform (CP) version to use\n    \n    Must be greater or equal to 5.0.0\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-tag CONNECTOR_TAG")"
    printf "    🔗 Connector version to use\n    \n    By default, for each connector, the latest available version on Confluent\n    Hub is used\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-zip CONNECTOR_ZIP")"
    printf "    🤐 Connector zip to use\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion \n            use folder_zip_or_jar (default: ~/Downloads) in config.ini file to\n    configure where to search the files (current folder is always used)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-jar CONNECTOR_JAR")"
    printf "    ♨️ Connector jar to use\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion \n            use folder_zip_or_jar (default: ~/Downloads) in config.ini file to\n    configure where to search the files (current folder is always used)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-control-center")"
    printf "    💠 Enable Control Center\n    \n    By default, control-center container is not started for every test\n    \n    Control Center is reachable at http://127.0.0.1:9021\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-conduktor")"
    printf "    🐺 Enable Conduktor Platform\n    \n    By default, Conduktor Platform container is not started for every test\n    \n    Conduktor is reachable at http://127.0.0.1:8080/console (admin/admin)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-kcat")"
    printf "    🐈‍⬛ Enable kcat\n    \n    You can use it with:\n    \n    $ docker exec kcat kcat -b broker:9092 -L\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-cloud CLUSTER-CLOUD")"
    printf "    🌤 The cloud provider: aws, gcp or azure. Default is aws\n    \n    🎓 Tip: you can also use CLUSTER_CLOUD environment variable\n"
    printf "    Allowed: aws, gcp, azure\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-region CLUSTER-REGION")"
    printf "    🗺 The Cloud region. \n    \n    🎓 Tip: you can also use CLUSTER_REGION environment variable\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-environment CLUSTER-ENVIRONMENT")"
    printf "    🌐 The environment id where want your new cluster (example: env-xxxxx)\n    \n    ℹ️ Optional, if not set, new environment will be created\n    \n    🎓 Tip: you can also use ENVIRONMENT environment variable\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-name CLUSTER-NAME")"
    printf "    🎰 The cluster name. \n    \n    ❣️ Only required if you want to use your own existing cluster\n    \n    🎓 Tip: you can also use CLUSTER_NAME environment variable\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-creds CLUSTER-CREDS")"
    printf "    🔒 The Kafka api key and secret to use, it should be separated with\n    semi-colon (example: <API_KEY>:<API_KEY_SECRET>)\n    \n    ❣️ Only required if you want to use your own existing cluster\n    \n    🎓 Tip: you can also use CLUSTER_CREDS environment variable\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-schema-registry-creds CLUSTER-SCHEMA-REGISTRY-CREDS")"
    printf "    🔒 The Schema Registry api key and secret to use, it should be separated with\n    semi-colon (example: <SR_API_KEY>:<SR_API_KEY_SECRET>)\n    \n    ℹ️ Optional, if not set, new credentials will be created\n    \n    ❣️ Only required if you want to use your own existing cluster\n    \n    🎓 Tip: you can also use SCHEMA_REGISTRY_CREDS environment variable\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    echo "  ARGUMENTS..."
    printf "    Arguments to use by example script\n    \n    Most of examples support to get required options either by using arguments\n    or environment variables.\n    \n    Example with Zendesk:\n    \n    playground run -f zendesk-source<tab> <ZENDESK_URL> <ZENDESK_USERNAME>\n    <ZENDESK_PASSWORD>\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground run-ccloud mqtt<tab> --cluster-cloud aws --cluster-region eu-west-3\n  --enable-control-center --connector-tag 1.2.3\n"
    echo

  fi
}

# :command.usage
playground_open_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground open\n"
    echo

    printf "  👐 When --file is not provided, simply open last example you ran with\n  <playground run> or <playground run-ccloud>\n  \n  Otherwise, open any file from the playground using --file.\n"
    echo

  else
    printf "playground open - 👐 When --file is not provided, simply open last example you ran with <playground run> or <playground run-ccloud>\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground open [OPTIONS]\n"
  printf "  playground open --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--file, -f FILE")"
    printf "    🔎 Search any file and open it.\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_stop_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground stop - 🛑 Stop currently running example\n"
    echo

  else
    printf "playground stop - 🛑 Stop currently running example\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground stop\n"
  printf "  playground stop --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_bootstrap_reproduction_model_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground bootstrap-reproduction-model\n"
    echo

    printf "  🛠  Bootstrap reproduction model\n  \n  👉 Check documentation\n  https://kafka-docker-playground.io/#/reusables?id=%f0%9f%9b%a0-bootstrap-reproduction-model\n"
    echo

  else
    printf "playground bootstrap-reproduction-model - 🛠  Bootstrap reproduction model\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground bootstrap-reproduction-model [OPTIONS] [ARGUMENTS...]\n"
  printf "  playground bootstrap-reproduction-model --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--tag TAG")"
    printf "    🎯 Confluent Platform (CP) version to use\n    \n    Must be greater or equal to 5.0.0\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-tag CONNECTOR_TAG")"
    printf "    🔗 Connector version to use\n    \n    By default, for each connector, the latest available version on Confluent\n    Hub is used\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-zip CONNECTOR_ZIP")"
    printf "    🤐 Connector zip to use\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion \n            use folder_zip_or_jar (default: ~/Downloads) in config.ini file to\n    configure where to search the files (current folder is always used)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-jar CONNECTOR_JAR")"
    printf "    ♨️ Connector jar to use\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion \n            use folder_zip_or_jar (default: ~/Downloads) in config.ini file to\n    configure where to search the files (current folder is always used)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-ksqldb")"
    printf "    🚀 Enable ksqlDB\n    \n    By default, ksqldb-server and ksqldb-cli containers are not started for\n    every test\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-control-center")"
    printf "    💠 Enable Control Center\n    \n    By default, control-center container is not started for every test\n    \n    Control Center is reachable at http://127.0.0.1:9021\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-conduktor")"
    printf "    🐺 Enable Conduktor Platform\n    \n    By default, Conduktor Platform container is not started for every test\n    \n    Conduktor is reachable at http://127.0.0.1:8080/console (admin/admin)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-multiple-brokers")"
    printf "    3️⃣ Enable multiple brokers\n    \n    By default, there is only one broker node enabled\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-multiple-connect-workers")"
    printf "    🥉 Enable multiple connect node\n    \n    By default, there is only one connect node enabled\n    \n    It only works when plaintext environment is used\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-jmx-grafana")"
    printf "    Enable Grafana, Prometheus and Pyroscope\n    \n    📊 Grafana is reachable at http://127.0.0.1:3000\n    🛡️ Prometheus is reachable at http://127.0.0.1:9090\n    📛 Pyroscope is reachable at http://127.0.0.1:4040\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-kcat")"
    printf "    🐈‍⬛ Enable kcat\n    \n    You can use it with:\n    \n    $ docker exec kcat kcat -b broker:9092 -L\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-sr-maven-plugin-app")"
    printf "    🔰 Enable Schema Registry Maven plugin App\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-sql-datagen")"
    printf "    🌪️ Enable SQL Datagen injection\n    \n    This only works for Oracle, MySql, Postgres and Microsoft Sql Server source\n    connector examples with JDBC and Debezium\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-region CLUSTER-REGION")"
    printf "    🗺 The Cloud region. \n    \n    🎓 Tip: you can also use CLUSTER_REGION environment variable\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-environment CLUSTER-ENVIRONMENT")"
    printf "    🌐 The environment id where want your new cluster (example: env-xxxxx)\n    \n    ℹ️ Optional, if not set, new environment will be created\n    \n    🎓 Tip: you can also use ENVIRONMENT environment variable\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-name CLUSTER-NAME")"
    printf "    🎰 The cluster name. \n    \n    ❣️ Only required if you want to use your own existing cluster\n    \n    🎓 Tip: you can also use CLUSTER_NAME environment variable\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-creds CLUSTER-CREDS")"
    printf "    🔒 The Kafka api key and secret to use, it should be separated with\n    semi-colon (example: <API_KEY>:<API_KEY_SECRET>)\n    \n    ❣️ Only required if you want to use your own existing cluster\n    \n    🎓 Tip: you can also use CLUSTER_CREDS environment variable\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-schema-registry-creds CLUSTER-SCHEMA-REGISTRY-CREDS")"
    printf "    🔒 The Schema Registry api key and secret to use, it should be separated with\n    semi-colon (example: <SR_API_KEY>:<SR_API_KEY_SECRET>)\n    \n    ℹ️ Optional, if not set, new credentials will be created\n    \n    ❣️ Only required if you want to use your own existing cluster\n    \n    🎓 Tip: you can also use SCHEMA_REGISTRY_CREDS environment variable\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--file, -f FILE (required)")"
    printf "    🔖 Example file to use as basis\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--description, -d DESCRIPTION (required)")"
    printf "    💭 Description for the reproduction model\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--producer, -p PRODUCER-TYPE")"
    printf "    ♨️ Java producer type to use\n    \n    One of avro, avro-with-key, protobuf, protobuf-with-key, json-schema,\n    json-schema-with-key\n    \n    🎓 Tip: 'with-key' will also produce key with selected converter, otherwise\n    LongConverter is used\n"
    printf "    Allowed: none, avro, avro-with-key, protobuf, protobuf-with-key, json-schema, json-schema-with-key\n"
    printf "    Default: none\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--nb-producers, -n NB-PRODUCERS")"
    printf "    2️⃣ Number of java producers to generate\n"
    printf "    Default: \n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--producer-schema-key")"
    printf "    🔰 Schema to use for the key\n    \n    ✨ Copy and paste the schema you want to use for the key, save and close the\n    file to continue\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--producer-schema-value")"
    printf "    🔰 Schema to use for the value\n    \n    ✨ Copy and paste the schema you want to use for the key, save and close the\n    file to continue\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--custom-smt")"
    printf "    ⚙️ Add a custom SMT (which is a no-op)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--pipeline SINK_FILE")"
    printf "    🔖 Sink example file to use for creating a pipeline\n    \n    ❕ It must be absolute full path. \n    \n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    echo "  ARGUMENTS..."
    printf "    Arguments to use by example script\n    \n    Most of examples support to get required options either by using arguments\n    or environment variables.\n    \n    Example with Zendesk:\n    \n    playground run -f zendesk-source<tab> <ZENDESK_URL> <ZENDESK_USERNAME>\n    <ZENDESK_PASSWORD>\n"
    echo

    # :command.usage_environment_variables
    printf "%s\n" "$(bold "Environment Variables:")"

    # :environment_variable.usage
    printf "  %s\n" "$(cyan "OUTPUT_FOLDER")"
    printf "    📁 Output folder where to generate bootstrapped files\n"
    printf "    Default: reproduction-models\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground bootstrap-reproduction-model -f hdfs2<tab> -d \"simple test\"\n"
    printf "  playground bootstrap-reproduction-model -f /full/path/hdfs2-sink.sh -d\n  \"testing with avro producer\" --producer avro --producer-schema-value\n  myschema<tab>\n"
    printf "  playground bootstrap-reproduction-model -f hdfs2<tab> -d \"testing with 2\n  protobuf producers\" --producer protobuf --nb-producers 2\n"
    printf "  playground bootstrap-reproduction-model -f hdfs2<tab> -d \"testing custom smt\"\n  --custom-smt\n"
    printf "  playground bootstrap-reproduction-model -f debeziumpostgres<tab> -d \"create\n  pipeline\" --pipeline jdbcsink<tab>\n"
    echo

  fi
}

# :command.usage
playground_get_properties_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-properties\n"
    echo

    printf "  📝 Get properties file from a container\n  \n  👉 Check documentation\n  https://kafka-docker-playground.io/#/how-to-use?id=%f0%9f%93%9d-see-properties-file\n"
    echo

  else
    printf "playground get-properties - 📝 Get properties file from a container\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-properties [OPTIONS]\n"
  printf "  playground get-properties --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    🐳 Container name\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground get-properties\n"
    printf "  playground get-properties --container broker\n"
    printf "  playground get-properties -c broker\n"
    echo

  fi
}

# :command.usage
playground_get_all_schemas_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-all-schemas - 🔰 Get all schemas versions for all subjects\n"
    echo

  else
    printf "playground get-all-schemas - 🔰 Get all schemas versions for all subjects\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-all-schemas [OPTIONS]\n"
  printf "  playground get-all-schemas --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--open, -o")"
    printf "    🔖 Save output to a file and open with text editor set with config.ini\n    (default is code)\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground get-all-schemas\n"
    echo

  fi
}

# :command.usage
playground_enable_remote_debugging_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground enable-remote-debugging\n"
    echo

    printf "  ✨ Enable java remote debugging for container\n  \n  👉 Check documentation\n  https://kafka-docker-playground.io/#/reusables?id=%e2%9c%a8-remote-debugging\n"
    echo

  else
    printf "playground enable-remote-debugging - ✨ Enable java remote debugging for container\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground enable-remote-debugging [OPTIONS]\n"
  printf "  playground enable-remote-debugging --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    🐳 Container name\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground enable-remote-debugging\n"
    printf "  playground enable-remote-debugging --container broker\n"
    printf "  playground enable-remote-debugging -c broker\n"
    echo

  fi
}

# :command.usage
playground_log_level_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground log-level - 🧬 Set log level for any package\n"
    echo

  else
    printf "playground log-level - 🧬 Set log level for any package\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground log-level COMMAND\n"
  printf "  playground log-level [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   Get log levels\n" "$(green "get")"
  printf "  %s   Set log level for specific logger\n" "$(green "set")"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground log-level get\n"
    printf "  playground log-level get -p io.confluent.connect.oracle.cdc\n"
    printf "  playground log-level get --package io.confluent.connect.oracle.cdc\n"
    printf "  playground log-level set -p io.confluent.connect.oracle.cdc.logging.LogUtils\n  -l TRACE\n"
    echo

  fi
}

# :command.usage
playground_log_level_get_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground log-level get - Get log levels\n"
    echo

  else
    printf "playground log-level get - Get log levels\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground log-level get [OPTIONS]\n"
  printf "  playground log-level get --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--package, -p PACKAGE")"
    printf "    Package name\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_log_level_set_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground log-level set - Set log level for specific logger\n"
    echo

  else
    printf "playground log-level set - Set log level for specific logger\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground log-level set [OPTIONS]\n"
  printf "  playground log-level set --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--package, -p PACKAGE (required)")"
    printf "    📦 Package name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--level, -l LEVEL (required)")"
    printf "    ❕Log level\n"
    printf "    Allowed: INFO, WARN, DEBUG, TRACE\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_get_jmx_metrics_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-jmx-metrics\n"
    echo

    printf "  🔢 Get JMX metrics from a component\n  \n  👉 Check documentation\n  https://kafka-docker-playground.io/#/how-to-use?id=%f0%9f%94%a2-jmx-metrics\n"
    echo

  else
    printf "playground get-jmx-metrics - 🔢 Get JMX metrics from a component\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-jmx-metrics [OPTIONS]\n"
  printf "  playground get-jmx-metrics --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--component, -c COMPONENT")"
    printf "    Component name\n"
    printf "    Allowed: zookeeper, broker, connect, schema-registry\n"
    printf "    Default: connect\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--domain, -d DOMAIN")"
    printf "    Domain name\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground get-jmx-metrics --component connect\n"
    printf "  playground get-jmx-metrics --component connect --domain \"kafka.connect\n  kafka.consumer kafka.producer\"\n"
    printf "  playground get-jmx-metrics -c broker\n"
    echo

  fi
}

# :command.usage
playground_container_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container - 🐳 Container commands\n"
    echo

  else
    printf "playground container - 🐳 Container commands\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container COMMAND\n"
  printf "  playground container [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "Container commands:")"
  printf "  %s   💫 Recreate container(s)\n" "$(green "recreate")        "
  printf "  %s   🖥️  Get ip address of running containers\n" "$(green "get-ip-addresses")"
  printf "  %s   💀 Kill all containers\n" "$(green "kill-all")        "
  printf "  %s   🕵️  Tail and follow container logs\n" "$(green "logs")            "
  printf "  %s   🛬 SSH into container\n" "$(green "ssh")             "
  printf "  %s   🪄  Execute command in a container\n" "$(green "exec")            "
  printf "  %s   🔁 Restart a container\n" "$(green "restart")         "
  printf "  %s   ⏸️  Pause a container\n" "$(green "pause")           "
  printf "  %s   ⏯️  Resume a container\n" "$(green "resume")          "
  printf "  %s   🔫 Kill a container\n" "$(green "kill")            "
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_recreate_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container recreate\n"
    echo

    printf "  💫 Recreate container(s)\n  \n  👉 Check documentation\n  https://kafka-docker-playground.io/#/how-to-use?id=%e2%99%bb%ef%b8%8f-re-create-containers\n"
    echo

  else
    printf "playground container recreate - 💫 Recreate container(s)\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container recreate\n"
  printf "  playground container recreate --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_get_ip_addresses_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container get-ip-addresses - 🖥️  Get ip address of running containers\n"
    echo

  else
    printf "playground container get-ip-addresses - 🖥️  Get ip address of running containers\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container get-ip-addresses\n"
  printf "  playground container get-ip-addresses --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground get-ip-address-container\n"
    echo

  fi
}

# :command.usage
playground_container_kill_all_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container kill-all - 💀 Kill all containers\n"
    echo

  else
    printf "playground container kill-all - 💀 Kill all containers\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container kill-all\n"
  printf "  playground container kill-all --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_logs_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container logs - 🕵️  Tail and follow container logs\n"
    echo

  else
    printf "playground container logs - 🕵️  Tail and follow container logs\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container logs [OPTIONS]\n"
  printf "  playground container logs --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    🐳 Container name\n"
    printf "    Default: connect\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--open, -o")"
    printf "    🔖 Save output to a file and open with text editor set with config.ini\n    (default is code)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--wait-for-log, -w LOG")"
    printf "    😴 Wait until log appears\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--max-wait, -m MAX_WAIT")"
    printf "    ⏳ Max time in seconds to wait when using --wait-for-log (default 600s)\n"
    printf "    Default: 600\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground container logs --container connect\n"
    printf "  playground container logs -c connect --open\n"
    printf "  playground container logs -c connect --wait-for-log \"StackOverflowError\"\n"
    echo

  fi
}

# :command.usage
playground_container_ssh_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container ssh - 🛬 SSH into container\n"
    echo

  else
    printf "playground container ssh - 🛬 SSH into container\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container ssh [OPTIONS]\n"
  printf "  playground container ssh --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    🐳 Container name\n"
    printf "    Default: connect\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--shell, -s SHELL")"
    printf "    💾 Shell to use (default is bash)\n"
    printf "    Allowed: bash, sh, ksh, zsh\n"
    printf "    Default: bash\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground ssh -c connect\n"
    printf "  playground ssh -c connect -s sh\n"
    printf "  playground ssh --container connect --shell sh\n"
    echo

  fi
}

# :command.usage
playground_container_exec_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container exec - 🪄  Execute command in a container\n"
    echo

  else
    printf "playground container exec - 🪄  Execute command in a container\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container exec [OPTIONS]\n"
  printf "  playground container exec --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    🐳 Container name\n"
    printf "    Default: connect\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--command COMMAND (required)")"
    printf "    📲 Command to execute\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--root")"
    printf "    👑 Run command as root\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--shell SHELL")"
    printf "    💾 Shell to use (default is bash)\n"
    printf "    Allowed: bash, sh, ksh, zsh\n"
    printf "    Default: bash\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground exec -c connect -d \"date\"\n"
    printf "  playground exec -c connect -d \"whoami\" --root\n"
    printf "  playground exec --container connect --command \"whoami\" --shell sh\n"
    echo

  fi
}

# :command.usage
playground_container_restart_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container restart - 🔁 Restart a container\n"
    echo

  else
    printf "playground container restart - 🔁 Restart a container\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container restart [OPTIONS]\n"
  printf "  playground container restart --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    🐳 Container name\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_pause_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container pause - ⏸️  Pause a container\n"
    echo

  else
    printf "playground container pause - ⏸️  Pause a container\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container pause [OPTIONS]\n"
  printf "  playground container pause --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    🐳 Container name\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_resume_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container resume - ⏯️  Resume a container\n"
    echo

  else
    printf "playground container resume - ⏯️  Resume a container\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container resume [OPTIONS]\n"
  printf "  playground container resume --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    🐳 Container name\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_kill_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container kill - 🔫 Kill a container\n"
    echo

  else
    printf "playground container kill - 🔫 Kill a container\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container kill [OPTIONS]\n"
  printf "  playground container kill --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    🐳 Container name\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic - 🗳 Topic commands\n"
    echo

  else
    printf "playground topic - 🗳 Topic commands\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic COMMAND\n"
  printf "  playground topic [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "Topic commands:")"
  printf "  %s   💯 Get number of records in a topic\n" "$(green "get-number-records")          "
  printf "  %s   📭 Display content of __consumer_offsets topic\n" "$(green "display-consumer-offsets")    "
  printf "  %s   🔬 Describe topic\n" "$(green "describe")                    "
  printf "  %s   📥 Consume topic from beginning\n" "$(green "consume")                     "
  printf "  %s   🛡️ Change topic's schema compatibility\n" "$(green "set-schema-compatibility")    "
  printf "  %s   🧞 Easily identify the usage of different schema versions within a topic.\n" "$(green "display-schema-id-statistics")"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_get_number_records_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic get-number-records - 💯 Get number of records in a topic\n"
    echo

  else
    printf "playground topic get-number-records - 💯 Get number of records in a topic\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic get-number-records [OPTIONS]\n"
  printf "  playground topic get-number-records --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC")"
    printf "    🗳 Topic name\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground get-number-records --topic a-topic\n"
    printf "  playground get-number-records -t a-topic\n"
    echo

  fi
}

# :command.usage
playground_topic_display_consumer_offsets_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic display-consumer-offsets - 📭 Display content of __consumer_offsets topic\n"
    echo

  else
    printf "playground topic display-consumer-offsets - 📭 Display content of __consumer_offsets topic\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic display-consumer-offsets\n"
  printf "  playground topic display-consumer-offsets --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_describe_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic describe - 🔬 Describe topic\n"
    echo

  else
    printf "playground topic describe - 🔬 Describe topic\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic describe [OPTIONS]\n"
  printf "  playground topic describe --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC")"
    printf "    🗳 Topic name\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_consume_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic consume - 📥 Consume topic from beginning\n"
    echo

  else
    printf "playground topic consume - 📥 Consume topic from beginning\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic consume [OPTIONS]\n"
  printf "  playground topic consume --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC")"
    printf "    🗳 Topic name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--max-messages MAX-MESSAGES")"
    printf "    Max number of messages to consume\n"
    printf "    Default: \n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--min-expected-messages MIN-EXPECTED-MESSAGES")"
    printf "    Minimum expected number of messages to be present in topic, returns an error\n    if this is not the case\n    \n    Note: --topic should be specified in this case.\n"
    printf "    Default: \n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--grep GREP")"
    printf "    Verify that topic content contains record which contains specified string\n"
    printf "    Default: \n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_set_schema_compatibility_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic set-schema-compatibility - 🛡️ Change topic's schema compatibility\n"
    echo

  else
    printf "playground topic set-schema-compatibility - 🛡️ Change topic's schema compatibility\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic set-schema-compatibility [OPTIONS]\n"
  printf "  playground topic set-schema-compatibility --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC")"
    printf "    🗳 Topic name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--compatibility COMPATIBILITY (required)")"
    printf "    Schema Registry compatibility rule\n"
    printf "    Allowed: BACKWARD, BACKWARD_TRANSITIVE, FORWARD, FORWARD_TRANSITIVE, FULL, FULL_TRANSITIVE, NONE\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_display_schema_id_statistics_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic display-schema-id-statistics\n"
    echo

    printf "  🧞 Easily identify the usage of different schema versions within a topic.\n  \n  It makes use of https://github.com/EladLeev/schema-registry-statistics\n  \n  It only works when plaintext environment is used\n"
    echo

  else
    printf "playground topic display-schema-id-statistics - 🧞 Easily identify the usage of different schema versions within a topic.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic display-schema-id-statistics [OPTIONS]\n"
  printf "  playground topic display-schema-id-statistics --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC")"
    printf "    🗳 Topic name\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector - 🔗 Connector commands\n"
    echo

  else
    printf "playground connector - 🔗 Connector commands\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector COMMAND\n"
  printf "  playground connector [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   🧩 Show status of all connectors\n" "$(green "status")   "
  printf "  %s   🎨 Show all plugins installed\n" "$(green "plugins")  "
  printf "  %s   ⏸️  Pause connector\n" "$(green "pause")    "
  printf "  %s   🧞 Get current and latest version available on Confluent Hub for connector(s) used in example\n" "$(green "versions") "
  printf "  %s   ♻️  Restart connector\n" "$(green "restart")  "
  printf "  %s   ⏯️  Resume connector\n" "$(green "resume")   "
  printf "  %s   🗑️  Delete connector\n" "$(green "delete")   "
  printf "  %s   🐢 Show lag of sink connector\n" "$(green "show-lag") "
  printf "  %s   🧬 Set connect log level\n" "$(green "log-level")"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground connector status\n"
    printf "  playground connector status --json\n"
    printf "  playground connector resume --connector <connector-name>\n"
    printf "  playground connector pause -c <connector-name>\n"
    printf "  playground connector delete -c <connector-name>\n"
    echo

  fi
}

# :command.usage
playground_connector_status_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector status - 🧩 Show status of all connectors\n"
    echo

  else
    printf "playground connector status - 🧩 Show status of all connectors\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector status\n"
  printf "  playground connector status --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_plugins_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector plugins - 🎨 Show all plugins installed\n"
    echo

  else
    printf "playground connector plugins - 🎨 Show all plugins installed\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector plugins\n"
  printf "  playground connector plugins --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_pause_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector pause - ⏸️  Pause connector\n"
    echo

  else
    printf "playground connector pause - ⏸️  Pause connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector pause [OPTIONS]\n"
  printf "  playground connector pause --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_versions_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector versions - 🧞 Get current and latest version available on Confluent Hub for connector(s) used in example\n"
    echo

  else
    printf "playground connector versions - 🧞 Get current and latest version available on Confluent Hub for connector(s) used in example\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector versions\n"
  printf "  playground connector versions --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_restart_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector restart - ♻️  Restart connector\n"
    echo

  else
    printf "playground connector restart - ♻️  Restart connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector restart [OPTIONS]\n"
  printf "  playground connector restart --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_resume_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector resume - ⏯️  Resume connector\n"
    echo

  else
    printf "playground connector resume - ⏯️  Resume connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector resume [OPTIONS]\n"
  printf "  playground connector resume --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_delete_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector delete - 🗑️  Delete connector\n"
    echo

  else
    printf "playground connector delete - 🗑️  Delete connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector delete [OPTIONS]\n"
  printf "  playground connector delete --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_show_lag_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector show-lag - 🐢 Show lag of sink connector\n"
    echo

  else
    printf "playground connector show-lag - 🐢 Show lag of sink connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector show-lag [OPTIONS]\n"
  printf "  playground connector show-lag --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_log_level_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector log-level - 🧬 Set connect log level\n"
    echo

  else
    printf "playground connector log-level - 🧬 Set connect log level\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector log-level [OPTIONS]\n"
  printf "  playground connector log-level --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--level, -l LEVEL (required)")"
    printf "    Log level\n"
    printf "    Allowed: INFO, WARN, DEBUG, TRACE\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground connector log-level --connector <connector-name> --level TRACE\n"
    printf "  playground connector log-level --level DEBUG\n"
    echo

  fi
}

# :command.normalize_input
normalize_input() {
  local arg flags

  while [[ $# -gt 0 ]]; do
    arg="$1"
    if [[ $arg =~ ^(--[a-zA-Z0-9_\-]+)=(.+)$ ]]; then
      input+=("${BASH_REMATCH[1]}")
      input+=("${BASH_REMATCH[2]}")
    elif [[ $arg =~ ^(-[a-zA-Z0-9])=(.+)$ ]]; then
      input+=("${BASH_REMATCH[1]}")
      input+=("${BASH_REMATCH[2]}")
    elif [[ $arg =~ ^-([a-zA-Z0-9][a-zA-Z0-9]+)$ ]]; then
      flags="${BASH_REMATCH[1]}"
      for ((i = 0; i < ${#flags}; i++)); do
        input+=("-${flags:i:1}")
      done
    else
      input+=("$arg")
    fi

    shift
  done
}
# :command.inspect_args
inspect_args() {
  if ((${#args[@]})); then
    readarray -t sorted_keys < <(printf '%s\n' "${!args[@]}" | sort)
    echo args:
    for k in "${sorted_keys[@]}"; do echo "- \${args[$k]} = ${args[$k]}"; done
  else
    echo args: none
  fi

  if ((${#other_args[@]})); then
    echo
    echo other_args:
    echo "- \${other_args[*]} = ${other_args[*]}"
    for i in "${!other_args[@]}"; do
      echo "- \${other_args[$i]} = ${other_args[$i]}"
    done
  fi

  if ((${#deps[@]})); then
    readarray -t sorted_keys < <(printf '%s\n' "${!deps[@]}" | sort)
    echo
    echo deps:
    for k in "${sorted_keys[@]}"; do echo "- \${deps[$k]} = ${deps[$k]}"; done
  fi

}

# :command.user_lib
# src/lib/cli_function.sh
function get_environment_used() {
  if [ ! -f /tmp/playground-command ]
  then
    echo "error"
    return
  fi

  patterns=("environment/2way-ssl" "environment/sasl-ssl" "environment/rbac-sasl-plain" "environment/kerberos" "environment/ssl_kerberos" "environment/ldap-authorizer-sasl-plain" "environment/sasl-plain" "environment/ldap-sasl-plain" "environment/sasl-scram" "environment/mdc-plaintext" "environment/mdc-sasl-plain" "environment/mdc-kerberos" "ccloud/environment")

  for pattern in "${patterns[@]}"; do
    if grep -q "$pattern" /tmp/playground-command; then
      echo "${pattern#*/}"
      return
    fi
  done

  echo "plaintext"
}

function get_connect_url_and_security() {
  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi
  connect_url="http://localhost:8083"
  security=""
  if [[ "$environment" == "sasl-ssl" ]] || [[ "$environment" == "2way-ssl" ]]
  then
      connect_url="https://localhost:8083"
      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

      security="--cert $DIR_CLI/../../environment/$environment/security/connect.certificate.pem --key $DIR_CLI/../../environment/$environment/security/connect.key --tlsv1.2 --cacert $DIR_CLI/../../environment/$environment/security/snakeoil-ca-1.crt"
  elif [[ "$environment" == "rbac-sasl-plain" ]]
  then
      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

      security="-u connectorSubmitter:connectorSubmitter"
  fi

  echo "$connect_url@$security"
}

function get_sr_url_and_security() {
  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi

  sr_url="http://localhost:8081"
  security_sr=""

  if [[ "$environment" == "sasl-ssl" ]] || [[ "$environment" == "2way-ssl" ]]
  then
      sr_url="https://localhost:8081"
      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

      security="--cert $DIR_CLI/../../environment/$environment/security/schema-registry.certificate.pem --key $DIR_CLI/../../environment/$environment/security/schema-registry.key --tlsv1.2 --cacert $DIR_CLI/../../environment/$environment/security/snakeoil-ca-1.crt"
  elif [[ "$environment" == "rbac-sasl-plain" ]]
  then
      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

      security="-u superUser:superUser"
  elif [[ "$environment" == "environment" ]]
  then
    if [ -f /tmp/delta_configs/env.delta ]
    then
        source /tmp/delta_configs/env.delta
    else
        logerror "ERROR: /tmp/delta_configs/env.delta has not been generated"
        exit 1
    fi
    sr_url=$SCHEMA_REGISTRY_URL
    security="-u $SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO"
  fi

  echo "$sr_url@$security"
}

function get_security_broker() {
  config_file_name="$1"
  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi

  container="broker"
  security=""
  if [[ "$environment" == "kerberos" ]] || [[ "$environment" == "ssl_kerberos" ]]
  then
      container="client"
      security="$config_file_name /etc/kafka/consumer.properties"

      docker exec -i client kinit -k -t /var/lib/secret/kafka-connect.key connect
  elif [ "$environment" == "ldap-authorizer-sasl-plain" ]
  then
      security="$config_file_name /service/kafka/users/kafka.properties"
  elif [ "$environment" == "ldap-sasl-plain" ] || [ "$environment" == "sasl-plain" ] || [ "$environment" == "sasl-scram" ]
  then
      security="$config_file_name /tmp/client.properties"
  elif [ "$environment" != "plaintext" ]
  then
      security="$config_file_name /etc/kafka/secrets/client_without_interceptors.config"
  fi
  echo "$container@$security"
}

function get_connector_list() {
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  curl $security -s "$connect_url/connectors" | jq -r '.[]' | tr '\n' ' ' | sed -e 's/[[:space:]]*$//'
}

function get_fzf_version() {
    version=$(fzf --version | grep -oE "[0-9]+\.[0-9]+\.[0-9]+" | cut -d " " -f 1)
    echo "$version"
}

function get_examples_list_with_fzf() {
  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  dir2=$(echo ${dir1%/*})

  cur="$1"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_options=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  if [[ $(type -f bat 2>&1) =~ "not found" ]]
  then
    res=$(find $dir2 -name \*.sh ! -name 'stop.sh' ! -path '*/scripts/*' ! -path '*/ccloud/*' ! -path '*/sample-sql-scripts/*' ! -path '*/ora-*/*' ! -path '*/security/*' | fzf --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --prompt="🍺" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "-3,-2,-1" $fzf_option_wrap $fzf_option_pointer --preview 'cat {}');echo "$cur@$res"
  else
    res=$(find $dir2 -name \*.sh ! -name 'stop.sh' ! -path '*/scripts/*' ! -path '*/ccloud/*' ! -path '*/sample-sql-scripts/*' ! -path '*/ora-*/*' ! -path '*/security/*' | fzf --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --prompt="🍺" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "-3,-2,-1" $fzf_option_wrap $fzf_option_pointer --preview 'bat --style=plain --color=always --line-range :500 {}');echo "$cur@$res"
  fi
}

function get_examples_list_with_fzf_ccloud_only() {
  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  dir2=$(echo ${dir1%/*})

  cur="$1"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_options=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  if [[ $(type -f bat 2>&1) =~ "not found" ]]
  then
    res=$(find $dir2 -name \*.sh ! -name 'stop.sh' -path '*/ccloud*' ! -path '*/sample-sql-scripts/*' ! -path '*/ora-*/*' ! -path '*/security/*' | fzf --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --prompt="🍺" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "-3,-2,-1" $fzf_option_wrap $fzf_option_pointer --preview 'cat {}');echo "$cur@$res"
  else
    res=$(find $dir2 -name \*.sh ! -name 'stop.sh' -path '*/ccloud*' ! -path '*/sample-sql-scripts/*' ! -path '*/ora-*/*' ! -path '*/security/*' | fzf --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --prompt="🍺" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "-3,-2,-1" $fzf_option_wrap $fzf_option_pointer --preview 'bat --style=plain --color=always --line-range :500 {}');echo "$cur@$res"
  fi
}

function get_examples_list_with_fzf_without_repro() {
  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  dir2=$(echo ${dir1%/*})

  cur="$1"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_options=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  if [[ $(type -f bat 2>&1) =~ "not found" ]]
  then
    res=$(find $dir2 -name \*.sh ! -name 'stop.sh' ! -path '*/scripts/*' ! -path '*/sample-sql-scripts/*' ! -path '*/ora-*/*' ! -path '*/security/*' ! -path '*/reproduction-models/*' | fzf --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --prompt="🍺" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "-3,-2,-1" $fzf_option_wrap $fzf_option_pointer --preview 'cat {}');echo "$cur@$res"
  else
    res=$(find $dir2 -name \*.sh ! -name 'stop.sh' ! -path '*/scripts/*' ! -path '*/sample-sql-scripts/*' ! -path '*/ora-*/*' ! -path '*/security/*' ! -path '*/reproduction-models/*' | fzf --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --prompt="🍺" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "-3,-2,-1" $fzf_option_wrap $fzf_option_pointer --preview 'bat --style=plain --color=always --line-range :500 {}');echo "$cur@$res"
  fi
}

function get_examples_list_with_fzf_without_repro_sink_only() {
  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  dir2=$(echo ${dir1%/*})

  cur="$1"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_options=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  if [[ $(type -f bat 2>&1) =~ "not found" ]]
  then
    res=$(find $dir2 -name \*.sh ! -name 'stop.sh' -path '*/connect-*-sink/*' ! -path '*/scripts/*' ! -path '*/sample-sql-scripts/*' ! -path '*/ora-*/*' ! -path '*/security/*' ! -path '*/reproduction-models/*' | fzf --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --prompt="🍺" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "-3,-2,-1" $fzf_option_wrap $fzf_option_pointer --preview 'cat {}');echo "$cur@$res"
  else
    res=$(find $dir2 -name \*.sh ! -name 'stop.sh' -path '*/connect-*-sink/*' ! -path '*/scripts/*' ! -path '*/sample-sql-scripts/*' ! -path '*/ora-*/*' ! -path '*/security/*' ! -path '*/reproduction-models/*' | fzf --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --prompt="🍺" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "-3,-2,-1" $fzf_option_wrap $fzf_option_pointer --preview 'bat --style=plain --color=always --line-range :500 {}');echo "$cur@$res"
  fi
}

function get_zip_or_jar_with_fzf() {
  cur="$1"
  type="$2"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_options=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  if config_has_key "folder_zip_or_jar"
  then
    folder_zip_or_jar=$(config_get "folder_zip_or_jar")
  else
    logerror "Could not find config value <folder_zip_or_jar> !"
    exit 1
  fi

  folder_zip_or_jar=${folder_zip_or_jar//\~/$HOME}
  folder_zip_or_jar=${folder_zip_or_jar//,/ }

  res=$(find $folder_zip_or_jar $PWD -name \*.$type ! -path '*/\.*' | fzf --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --prompt="🍺" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer);echo "$cur@$res"
}

function get_any_files_with_fzf() {
  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  dir2=$(echo ${dir1%/*})

  cur="$1"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_options=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  res=$(find $dir2 -type f ! -path '*/\.*' | fzf --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --prompt="🍺" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer);echo "$cur@$res"
}

function filter_not_mdc_environment() {
  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi

  if [[ "$environment" == "mdc"* ]]
  then
    echo "$environment is not supported with this command !"
  fi
}

function filter_schema_registry_running() {
  ret=$(get_sr_url_and_security)

  sr_url=$(echo "$ret" | cut -d "@" -f 1)
  sr_security=$(echo "$ret" | cut -d "@" -f 2)

  ret=$(curl $sr_security -s "${sr_url}/config")
  if [ $? != 0 ]
  then
    echo "schema registry rest api should be running to run this command"
  fi
}

function filter_connect_running() {
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  ret=$(curl $security -s "${connect_url}")
  if [ $? != 0 ]
  then
    echo "connect rest api should be running to run this command"
  fi
}

function filter_docker_running() {
  docker info >/dev/null 2>&1 || echo "Docker must be running"
}

# src/lib/colors.sh
print_in_color() {
  local color="$1"
  shift
  if [[ -z ${NO_COLOR+x} ]]; then
    printf "$color%b\e[0m\n" "$*"
  else
    printf "%b\n" "$*"
  fi
}

red() { print_in_color "\e[31m" "$*"; }
green() { print_in_color "\e[32m" "$*"; }
yellow() { print_in_color "\e[33m" "$*"; }
blue() { print_in_color "\e[34m" "$*"; }
magenta() { print_in_color "\e[35m" "$*"; }
cyan() { print_in_color "\e[36m" "$*"; }
bold() { print_in_color "\e[1m" "$*"; }
underlined() { print_in_color "\e[4m" "$*"; }
red_bold() { print_in_color "\e[1;31m" "$*"; }
green_bold() { print_in_color "\e[1;32m" "$*"; }
yellow_bold() { print_in_color "\e[1;33m" "$*"; }
blue_bold() { print_in_color "\e[1;34m" "$*"; }
magenta_bold() { print_in_color "\e[1;35m" "$*"; }
cyan_bold() { print_in_color "\e[1;36m" "$*"; }
red_underlined() { print_in_color "\e[4;31m" "$*"; }
green_underlined() { print_in_color "\e[4;32m" "$*"; }
yellow_underlined() { print_in_color "\e[4;33m" "$*"; }
blue_underlined() { print_in_color "\e[4;34m" "$*"; }
magenta_underlined() { print_in_color "\e[4;35m" "$*"; }
cyan_underlined() { print_in_color "\e[4;36m" "$*"; }

# src/lib/config.sh
config_init() {
  CONFIG_FILE=${CONFIG_FILE:=config.ini}
  [[ -f "$CONFIG_FILE" ]] || touch "$CONFIG_FILE"
}

config_get() {
  local key=$1
  local regex="^$key *= *(.+)$"
  local value=""

  config_init

  while IFS= read -r line || [ -n "$line" ]; do
    if [[ $line =~ $regex ]]; then
      value="${BASH_REMATCH[1]}"
      break
    fi
  done <"$CONFIG_FILE"

  echo "$value"
}

config_set() {
  local key=$1
  shift
  local value="$*"

  config_init

  local regex="^($key) *= *.+$"
  local output=""
  local found_key=""
  local newline

  while IFS= read -r line || [ -n "$line" ]; do
    newline=$line
    if [[ $line =~ $regex ]]; then
      found_key="${BASH_REMATCH[1]}"
      newline="$key = $value"
      output="$output$newline\n"
    elif [[ $line ]]; then
      output="$output$line\n"
    fi
  done <"$CONFIG_FILE"

  if [[ -z $found_key ]]; then
    output="$output$key = $value\n"
  fi

  printf "%b\n" "$output" >"$CONFIG_FILE"
}

config_del() {
  local key=$1

  local regex="^($key) *="
  local output=""

  config_init

  while IFS= read -r line || [ -n "$line" ]; do
    if [[ $line ]] && [[ ! $line =~ $regex ]]; then
      output="$output$line\n"
    fi
  done <"$CONFIG_FILE"

  printf "%b\n" "$output" >"$CONFIG_FILE"
}

config_show() {
  config_init
  cat "$CONFIG_FILE"
}

config_keys() {
  local regex="^([a-zA-Z0-9_\-\/\.]+) *="

  config_init

  local keys=()
  local key

  while IFS= read -r line || [ -n "$line" ]; do
    if [[ $line =~ $regex ]]; then
      key="${BASH_REMATCH[1]}"
      keys+=("$key")
    fi
  done <"$CONFIG_FILE"
  echo "${keys[@]}"
}

config_has_key() {
  [[ $(config_get "$1") ]]
}

# src/lib/heredocs.sh
function get_properties_command_heredoc () {
docker exec -i "$1" sh << EOF
ps -ef | grep properties | grep java | grep -v grep | awk '{ print \$NF }' > /tmp/propertie_file
propertie_file=\$(cat /tmp/propertie_file)
if [ ! -f \$propertie_file ]
then
  logerror 'ERROR: Could not determine properties file!'
  exit 1
fi
cat \$propertie_file | grep -v None | grep . | sort
EOF
}

function get_producer_heredoc () {
        cat << EOF >> $tmp_dir/producer

  $producer_hostname:
    build:
      context: ../../$output_folder/$final_dir/$producer_hostname/
    hostname: producer
    container_name: $producer_hostname
    environment:
      KAFKA_BOOTSTRAP_SERVERS: broker:9092
      TOPIC: "$topic_name"
      REPLICATION_FACTOR: 1
      NUMBER_OF_PARTITIONS: 1
      NB_MESSAGES: 10 # -1 for MAX_VALUE
      MESSAGE_BACKOFF: 100 # Frequency of message injection
      KAFKA_ACKS: "all" # default: "1"
      KAFKA_REQUEST_TIMEOUT_MS: 20000
      KAFKA_RETRY_BACKOFF_MS: 500
      KAFKA_CLIENT_ID: "my-java-$producer_hostname"
      KAFKA_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      JAVA_OPTS: \${GRAFANA_AGENT_PRODUCER}
    volumes:
      - ../../environment/plaintext/jmx-exporter:/usr/share/jmx_exporter/
      - ../../$output_folder/$final_dir/$producer_hostname/target/producer-1.0.0-jar-with-dependencies.jar:/producer-1.0.0-jar-with-dependencies.jar

EOF
}

function get_producer_ccloud_heredoc () {
        cat << EOF >> $tmp_dir/producer

  $producer_hostname:
    build:
      context: ../../$output_folder/$final_dir/$producer_hostname/
    hostname: producer
    container_name: $producer_hostname
    environment:
      KAFKA_BOOTSTRAP_SERVERS: \$BOOTSTRAP_SERVERS
      KAFKA_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: "https"
      KAFKA_SASL_MECHANISM: "PLAIN"
      KAFKA_SASL_JAAS_CONFIG: \$SASL_JAAS_CONFIG
      KAFKA_SECURITY_PROTOCOL: "SASL_SSL"
      TOPIC: "$topic_name"
      REPLICATION_FACTOR: 3
      NUMBER_OF_PARTITIONS: 1
      NB_MESSAGES: 10 # -1 for MAX_VALUE
      MESSAGE_BACKOFF: 100 # Frequency of message injection
      KAFKA_ACKS: "all" # default: "1"
      KAFKA_REQUEST_TIMEOUT_MS: 20000
      KAFKA_RETRY_BACKOFF_MS: 500
      KAFKA_CLIENT_ID: "my-java-$producer_hostname"
      KAFKA_SCHEMA_REGISTRY_URL: \$SCHEMA_REGISTRY_URL
      KAFKA_BASIC_AUTH_CREDENTIALS_SOURCE: \$BASIC_AUTH_CREDENTIALS_SOURCE
      KAFKA_SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO: \$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO
      JAVA_OPTS: \${GRAFANA_AGENT_PRODUCER}
      EXTRA_ARGS:

    volumes:
      - ../../environment/plaintext/jmx-exporter:/usr/share/jmx_exporter/
      - ../../$output_folder/$final_dir/$producer_hostname/target/producer-1.0.0-jar-with-dependencies.jar:/producer-1.0.0-jar-with-dependencies.jar

EOF
}

function get_producer_build_heredoc () {
    cat << EOF > $tmp_dir/build_producer
for component in $list
do
    set +e
    log "🏗 Building jar for \${component}"
    docker run -i --rm -e KAFKA_CLIENT_TAG=\$KAFKA_CLIENT_TAG -e TAG=\$TAG_BASE -v "\${DIR}/\${component}":/usr/src/mymaven -v "\$HOME/.m2":/root/.m2 -v "\$PWD/../../scripts/settings.xml:/tmp/settings.xml" -v "\${DIR}/\${component}/target:/usr/src/mymaven/target" -w /usr/src/mymaven maven:3.6.1-jdk-11 mvn -s /tmp/settings.xml -Dkafka.tag=\$TAG -Dkafka.client.tag=\$KAFKA_CLIENT_TAG package > /tmp/result.log 2>&1
    if [ \$? != 0 ]
    then
        logerror "ERROR: failed to build java component $component"
        tail -500 /tmp/result.log
        exit 1
    fi
    set -e
done

EOF
}

function get_producer_fixthis_heredoc () {
    cat << EOF >> $tmp_dir/java_producer
# 🚨🚨🚨 FIXTHIS: move it to the correct place 🚨🚨🚨
EOF
}

function get_producer_run_heredoc () {
    cat << EOF >> $tmp_dir/java_producer
log "✨ Run the $schema_format java producer v$i which produces to topic $topic_name"
docker exec $producer_hostname bash -c "java \${JAVA_OPTS} -jar producer-1.0.0-jar-with-dependencies.jar"
EOF
}

function get_producer_run_heredoc () {
    cat << EOF >> $tmp_dir/java_producer
log "✨ Run the $schema_format java producer v$i which produces to topic $topic_name"
docker exec $producer_hostname bash -c "java \${JAVA_OPTS} -jar producer-1.0.0-jar-with-dependencies.jar"
EOF
}

function get_remote_debugging_command_heredoc () {
tmp_dir=$(mktemp -d -t ci-XXXXXXXXXX)
cat << EOF > $tmp_dir/docker-compose-remote-debugging.yml
version: '3.5'
services:
  $1:
    environment:
      # https://kafka-docker-playground.io/#/reusables?id=✨-remote-debugging
      KAFKA_DEBUG: 'true'
      # With JDK9+, need to specify address=*:5005, see https://www.baeldung.com/java-application-remote-debugging#from-java9
      JAVA_DEBUG_OPTS: '-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=0.0.0.0:5005'
EOF

sed -e "s|up -d|-f $tmp_dir/docker-compose-remote-debugging.yml up -d|g" \
    /tmp/playground-command > /tmp/playground-command-debugging
}

function get_custom_smt_build_heredoc () {
    cat << EOF > $tmp_dir/build_custom_smt
for component in $custom_smt_name
do
    set +e
    log "🏗 Building jar for \${component}"
    docker run -i --rm -e KAFKA_CLIENT_TAG=\$KAFKA_CLIENT_TAG -e TAG=\$TAG_BASE -v "\${DIR}/\${component}":/usr/src/mymaven -v "\$HOME/.m2":/root/.m2 -v "\$PWD/../../scripts/settings.xml:/tmp/settings.xml" -v "\${DIR}/\${component}/target:/usr/src/mymaven/target" -w /usr/src/mymaven maven:3.6.1-jdk-11 mvn -s /tmp/settings.xml -Dkafka.tag=\$TAG -Dkafka.client.tag=\$KAFKA_CLIENT_TAG package > /tmp/result.log 2>&1
    if [ \$? != 0 ]
    then
        logerror "ERROR: failed to build java component $component"
        tail -500 /tmp/result.log
        exit 1
    fi
    set -e
done

EOF
}

# src/lib/send_completions.sh
send_completions() {
  echo $'# playground completion                                    -*- shell-script -*-'
  echo $''
  echo $'# This bash completions script was generated by'
  echo $'# completely (https://github.com/dannyben/completely)'
  echo $'# Modifying it manually is not recommended'
  echo $''
  echo $'_playground_completions_filter() {'
  echo $'  local words="$1"'
  echo $'  local cur=${COMP_WORDS[COMP_CWORD]}'
  echo $'  local result=()'
  echo $''
  echo $'  if [[ "${cur:0:1}" == "-" ]]; then'
  echo $'    echo "$words"'
  echo $'  '
  echo $'  else'
  echo $'    for word in $words; do'
  echo $'      [[ "${word:0:1}" != "-" ]] && result+=("$word")'
  echo $'    done'
  echo $''
  echo $'    echo "${result[*]}"'
  echo $''
  echo $'  fi'
  echo $'}'
  echo $''
  echo $'_playground_completions() {'
  echo $'  local cur=${COMP_WORDS[COMP_CWORD]}'
  echo $'  local compwords=("${COMP_WORDS[@]:1:$COMP_CWORD-1}")'
  echo $'  local compline="${compwords[*]}"'
  echo $''
  echo $'  case "$compline" in'
  echo $'    \'recreate-container\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'get-properties\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h broker.* connect.* schema-registry.* zookeeper.*")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'completions\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'properties\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h broker.* connect.* schema-registry.* zookeeper.*")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'bootstrap\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -A file -W "$(_playground_completions_filter "--help -h avro avro-with-key json-schema json-schema-with-key none protobuf protobuf-with-key")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'recreate\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'boot\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -A file -W "$(_playground_completions_filter "--help -h avro avro-with-key json-schema json-schema-with-key none protobuf protobuf-with-key")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'get\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h broker.* connect.* schema-registry.* zookeeper.*")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'b\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -A file -W "$(_playground_completions_filter "--help -h avro avro-with-key json-schema json-schema-with-key none protobuf protobuf-with-key")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'g\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h broker.* connect.* schema-registry.* zookeeper.*")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'r\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    *)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help --version -h -v b boot bootstrap completions g get get-properties properties r recreate recreate-container")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'  esac'
  echo $'} &&'
  echo $'complete -F _playground_completions playground'
  echo $''
  echo $'# ex: filetype=sh'
}

# src/lib/utils_function.sh
function log() {
  YELLOW='\033[0;33m'
  NC='\033[0m' # No Color
  echo -e "$YELLOW`date +"%H:%M:%S"` ℹ️ $@$NC"
}

function logerror() {
  RED='\033[0;31m'
  NC='\033[0m' # No Color
  echo -e "$RED`date +"%H:%M:%S"` 🔥 $@$NC"
}

function logwarn() {
  PURPLE='\033[0;35m'
  NC='\033[0m' # No Color
  echo -e "$PURPLE`date +"%H:%M:%S"` ❗ $@$NC"
}

function urlencode() {
  # https://gist.github.com/cdown/1163649
  # urlencode <string>

  old_lc_collate=$LC_COLLATE
  LC_COLLATE=C

  local length="${#1}"
  for (( i = 0; i < length; i++ )); do
      local c="${1:$i:1}"
      case $c in
          [a-zA-Z0-9.~_-]) printf '%s' "$c" ;;
          *) printf '%%%02X' "'$c" ;;
      esac
  done

  LC_COLLATE=$old_lc_collate
}

function jq() {
    if [[ $(type -f jq 2>&1) =~ "not found" ]]
    then
      docker run --rm -i imega/jq "$@"
    else
      $(which jq) "$@"
    fi
}

function yq() {
    if [[ $(type -f yq 2>&1) =~ "not found" ]]
    then
      docker run -u0 -v /tmp:/tmp --rm -i mikefarah/yq "$@"
    else
      $(which yq) "$@"
    fi
}

# https://stackoverflow.com/a/24067243
function version_gt() {
  test "$(printf '%s\n' "$@" | sort -V | head -n 1)" != "$1";
}

function set_kafka_client_tag()
{
    if [[ $TAG_BASE = 7.4.* ]]
    then
      export KAFKA_CLIENT_TAG="3.4.0"
    fi

    if [[ $TAG_BASE = 7.3.* ]]
    then
      export KAFKA_CLIENT_TAG="3.3.0"
    fi

    if [[ $TAG_BASE = 7.2.* ]]
    then
      export KAFKA_CLIENT_TAG="3.2.0"
    fi

    if [[ $TAG_BASE = 7.1.* ]]
    then
      export KAFKA_CLIENT_TAG="3.1.0"
    fi

    if [[ $TAG_BASE = 7.0.* ]]
    then
      export KAFKA_CLIENT_TAG="3.0.0"
    fi

    if [[ $TAG_BASE = 6.2.* ]]
    then
      export KAFKA_CLIENT_TAG="2.8.0"
    fi

    if [[ $TAG_BASE = 6.1.* ]]
    then
      export KAFKA_CLIENT_TAG="2.7.0"
    fi

    if [[ $TAG_BASE = 6.0.* ]]
    then
      export KAFKA_CLIENT_TAG="2.6.0"
    fi

    if [[ $TAG_BASE = 5.5.* ]]
    then
      export KAFKA_CLIENT_TAG="2.5.0"
    fi

    if [[ $TAG_BASE = 5.4.* ]]
    then
      export KAFKA_CLIENT_TAG="2.4.0"
    fi

    if [[ $TAG_BASE = 5.3.* ]]
    then
      export KAFKA_CLIENT_TAG="2.3.0"
    fi

    if [[ $TAG_BASE = 5.2.* ]]
    then
      export KAFKA_CLIENT_TAG="2.2.0"
    fi

    if [[ $TAG_BASE = 5.1.* ]]
    then
      export KAFKA_CLIENT_TAG="2.1.0"
    fi

    if [[ $TAG_BASE = 5.0.* ]]
    then
      export KAFKA_CLIENT_TAG="2.0.0"
    fi
}

function displaytime {
  local T=$1
  local D=$((T/60/60/24))
  local H=$((T/60/60%24))
  local M=$((T/60%60))
  local S=$((T%60))
  (( $D > 0 )) && printf '%d days ' $D
  (( $H > 0 )) && printf '%d hours ' $H
  (( $M > 0 )) && printf '%d minutes ' $M
  (( $D > 0 || $H > 0 || $M > 0 )) && printf 'and '
  printf '%d seconds\n' $S
}

function choosejar()
{
  log "☕ Select the jar to replace:"
  select jar
  do
    # Check the selected menu jar number
    if [ 1 -le "$REPLY" ] && [ "$REPLY" -le $# ];
    then
      break;
    else
      logwarn "Wrong selection: select any number from 1-$#"
    fi
  done
}

function verify_installed()
{
  local cmd="$1"
  if [[ $(type $cmd 2>&1) =~ "not found" ]]; then
    echo -e "\nERROR: This script requires '$cmd'. Please install '$cmd' and run again.\n"
    exit 1
  fi
}

function maybe_create_image()
{
  set +e
  log "🧰 Checking if Docker image ${CP_CONNECT_IMAGE}:${CONNECT_TAG} contains additional tools"
  log "🧰 it can take a while if image is downloaded for the first time"
  docker run --rm ${CP_CONNECT_IMAGE}:${CONNECT_TAG} type unzip > /dev/null 2>&1
  if [ $? != 0 ]
  then
    if [[ "$TAG" == *ubi8 ]] || version_gt $TAG_BASE "5.9.0"
    then
      export CONNECT_USER="appuser"
      if [ `uname -m` = "arm64" ]
      then
        CONNECT_3RDPARTY_INSTALL="if [ ! -f /tmp/done ]; then yum -y install --disablerepo='Confluent*' bind-utils openssl unzip findutils net-tools nc jq which iptables libmnl krb5-workstation krb5-libs vim && yum clean all && rm -rf /var/cache/yum && dnf -y install iproute && rpm -i --nosignature http://mirror.centos.org/centos/8-stream/BaseOS/aarch64/os/Packages/iproute-tc-5.18.0-1.el8.aarch64.rpm && rpm -i --nosignature https://rpmfind.net/linux/centos/8-stream/AppStream/aarch64/os/Packages/tcpdump-4.9.3-2.el8.aarch64.rpm && touch /tmp/done; fi"
      else
        CONNECT_3RDPARTY_INSTALL="if [ ! -f /tmp/done ]; then wget http://vault.centos.org/8.1.1911/BaseOS/x86_64/os/Packages/iproute-tc-4.18.0-15.el8.x86_64.rpm && rpm -i --nodeps --nosignature http://vault.centos.org/8.1.1911/BaseOS/x86_64/os/Packages/iproute-tc-4.18.0-15.el8.x86_64.rpm && curl http://mirror.centos.org/centos/8-stream/AppStream/x86_64/os/Packages/tcpdump-4.9.3-1.el8.x86_64.rpm -o tcpdump-4.9.3-1.el8.x86_64.rpm && rpm -Uvh tcpdump-4.9.3-1.el8.x86_64.rpm && yum -y install --disablerepo='Confluent*' bind-utils openssl unzip findutils net-tools nc jq which iptables libmnl krb5-workstation krb5-libs vim && yum clean all && rm -rf /var/cache/yum && touch /tmp/done; fi"
      fi
    else
      export CONNECT_USER="root"
      CONNECT_3RDPARTY_INSTALL="if [ ! -f /tmp/done ]; then apt-get update && echo bind-utils openssl unzip findutils net-tools nc jq which iptables iproute tree | xargs -n 1 apt-get install --force-yes -y && rm -rf /var/lib/apt/lists/* && touch /tmp/done; fi"
    fi

    tmp_dir=$(mktemp -d -t ci-XXXXXXXXXX)
cat << EOF > $tmp_dir/Dockerfile
FROM ${CP_CONNECT_IMAGE}:${CONNECT_TAG}
USER root
RUN ${CONNECT_3RDPARTY_INSTALL}
USER ${CONNECT_USER}
EOF
    log "👷📦 Re-building Docker image ${CP_CONNECT_IMAGE}:${CONNECT_TAG} to include additional tools"
    docker build -t ${CP_CONNECT_IMAGE}:${CONNECT_TAG} $tmp_dir
    rm -rf $tmp_dir
  fi
  set -e
}

function verify_docker_and_memory()
{
  set +e
  docker info > /dev/null 2>&1
  if [[ $? -ne 0 ]]
  then
    logerror "Cannot connect to the Docker daemon. Is the docker daemon running?"
    exit 1
  fi
  set -e
  # Check only with Mac OS
  # if [[ "$OSTYPE" == "darwin"* ]]
  # then
  #   # Verify Docker memory is increased to at least 8GB
  #   DOCKER_MEMORY=$(docker system info | grep Memory | grep -o "[0-9\.]\+")
  #   if (( $(echo "$DOCKER_MEMORY 7.0" | awk '{print ($1 < $2)}') )); then
  #       logerror "WARNING: Did you remember to increase the memory available to Docker to at least 8GB (default is 2GB)? Demo may otherwise not work properly"
  #       exit 1
  #   fi
  # fi
  return 0
}

function verify_confluent_login()
{
  local cmd="$1"
  set +e
  output=$($cmd 2>&1)
  set -e
  if [ "${output}" = "Error: You must login to run that command." ] || [ "${output}" = "Error: Your session has expired. Please login again." ]; then
    logerror "This script requires confluent CLI to be logged in. Please execute 'confluent login' and run again."
    exit 1
  fi
}

function verify_confluent_details()
{
    if [ "$(confluent prompt -f "%E")" = "(none)" ]
    then
        logerror "confluent command is badly configured: environment is not set"
        logerror "Example: confluent kafka environment list"
        logerror "then: confluent kafka environment use <environment id>"
        exit 1
    fi

    if [ "$(confluent prompt -f "%K")" = "(none)" ]
    then
        logerror "confluent command is badly configured: cluster is not set"
        logerror "Example: confluent kafka cluster list"
        logerror "then: confluent kafka cluster use <cluster id>"
        exit 1
    fi

    if [ "$(confluent prompt -f "%a")" = "(none)" ]
    then
        logerror "confluent command is badly configured: api key is not set"
        logerror "Example: confluent api-key store <api key> <password>"
        logerror "then: confluent api-key use <api key>"
        exit 1
    fi

    CCLOUD_PROMPT_FMT='You will be using Confluent Cloud cluster with user={{fgcolor "green" "%u"}}, environment={{fgcolor "red" "%E"}}, cluster={{fgcolor "cyan" "%K"}}, api key={{fgcolor "yellow" "%a"}}'
    confluent prompt -f "$CCLOUD_PROMPT_FMT"
}

function check_if_continue()
{
    if [ ! -z "$CI" ]
    then
        # running with github actions, continue
        return
    fi
    read -p "Continue (y/n)?" choice
    case "$choice" in
    y|Y ) ;;
    n|N ) exit 1;;
    * ) logerror "invalid response!";exit 1;;
    esac
}

function create_topic()
{
  local topic="$1"
  log "Check if topic $topic exists"
  confluent kafka topic create "$topic" --partitions 1 --dry-run 2>/dev/null
  if [[ $? == 0 ]]; then
    log "Create topic $topic"
    log "confluent kafka topic create $topic --partitions 1"
    confluent kafka topic create "$topic" --partitions 1 || true
  else
    log "Topic $topic already exists"
  fi
}

function delete_topic()
{
  local topic="$1"
  log "Check if topic $topic exists"
  confluent kafka topic create "$topic" --partitions 1 --dry-run 2>/dev/null
  if [[ $? != 0 ]]; then
    log "Delete topic $topic"
    log "confluent kafka topic delete $topic --force"
    confluent kafka topic delete "$topic" --force || true
  else
    log "Topic $topic does not exist"
  fi
}

function version_gt() {
  test "$(printf '%s\n' "$@" | sort -V | head -n 1)" != "$1";
}

function get_docker_compose_version() {
  docker-compose version | grep "^docker-compose version" | cut -d' ' -f3 | cut -d',' -f1
}

function check_docker_compose_version() {
  REQUIRED_DOCKER_COMPOSE_VER=${1:-"1.28.0"}
  DOCKER_COMPOSE_VER=$(get_docker_compose_version)

  if version_gt $REQUIRED_DOCKER_COMPOSE_VER $DOCKER_COMPOSE_VER; then
    log "docker-compose version ${REQUIRED_DOCKER_COMPOSE_VER} or greater is required.  Current reported version: ${DOCKER_COMPOSE_VER}"
    exit 1
  fi
}

function get_confluent_version() {
  confluent version | grep "^Version:" | cut -d':' -f2 | cut -d'v' -f2
}

function get_ansible_version() {
  ansible --version | grep "core" | cut -d'[' -f2 | cut -d']' -f1 | cut -d' ' -f 2
}

function check_confluent_version() {
  REQUIRED_CONFLUENT_VER=${1:-"3.0.0"}
  CONFLUENT_VER=$(get_confluent_version)

  if version_gt $REQUIRED_CONFLUENT_VER $CONFLUENT_VER; then
    log "confluent version ${REQUIRED_CONFLUENT_VER} or greater is required.  Current reported version: ${CONFLUENT_VER}"
    echo 'To update run: confluent update'
    exit 1
  fi
}

function container_to_ip() {
    name=$1
    echo $(docker exec $name hostname -I)
}

function block_host() {
    name=$1
    shift 1

    # https://serverfault.com/a/906499
    docker exec --privileged -t $name bash -c "tc qdisc add dev eth0 root handle 1: prio" 2>&1

    for ip in $@; do
        docker exec --privileged -t $name bash -c "tc filter add dev eth0 protocol ip parent 1: prio 1 u32 match ip dst $ip flowid 1:1" 2>&1
    done

    docker exec --privileged -t $name bash -c "tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip dst 0.0.0.0/0 flowid 1:2" 2>&1
    docker exec --privileged -t $name bash -c "tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip protocol 1 0xff flowid 1:2" 2>&1
    docker exec --privileged -t $name bash -c "tc qdisc add dev eth0 parent 1:1 handle 10: netem loss 100%" 2>&1
    docker exec --privileged -t $name bash -c "tc qdisc add dev eth0 parent 1:2 handle 20: sfq" 2>&1
}

function remove_partition() {
    for name in $@; do
        docker exec --privileged -t $name bash -c "tc qdisc del dev eth0 root"
    done
}

function aws() {

    if [ -z "$AWS_ACCESS_KEY_ID" ] && [ -z "$AWS_SECRET_ACCESS_KEY" ] && [ ! -f $HOME/.aws/config ] && [ ! -f $HOME/.aws/credentials ]
    then
      logerror 'ERROR: Neither AWS_ACCESS_KEY_ID/AWS_SECRET_ACCESS_KEY or $HOME/.aws/credentials are set. AWS credentials must be set !'
      if [ -z "$AWS_ACCESS_KEY_ID" ]
      then
        log 'AWS_ACCESS_KEY_ID environment variable is not set.'
      fi
      if [ -z "$AWS_SECRET_ACCESS_KEY" ]
      then
        log 'AWS_SECRET_ACCESS_KEY environment variable is not set.'
      fi
      if [ ! -f $HOME/.aws/credentials ]
      then
        log '$HOME/.aws/credentials does not exist.'
      fi
      return 1
    fi

    if [ ! -f $HOME/.aws/config ]
    then
          tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
cat << EOF > $tmp_dir/config
[default]
region = $AWS_REGION
EOF
    fi

    if [ ! -f $HOME/.aws/credentials ]
    then
      #log "Using aws cli with environment variables AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY"
      docker run --rm -iv $tmp_dir/config:/root/.aws/config -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY -v $(pwd):/aws -v /tmp:/tmp amazon/aws-cli "$@"
      rm -rf $tmp_dir
    else
      #log "Using aws cli with credentials file"
      docker run --rm -iv $HOME/.aws:/root/.aws -v $(pwd):/aws -v /tmp:/tmp amazon/aws-cli "$@"
    fi
}

function timeout() {
  if [[ $(type -f timeout 2>&1) =~ "not found" ]]; then
    # ignore
    shift
    eval "$@"
  else
    $(which timeout) "$@"
  fi
}

function az() {
    docker run -v /tmp:/tmp -v $HOME/.azure:/home/az/.azure -e HOME=/home/az --rm -i mcr.microsoft.com/azure-cli az "$@"
}

function display_docker_container_error_log() {
  set +e
  logerror "####################################################"
  logerror "🐳 docker ps"
  docker ps
  logerror "####################################################"
  for container in $(docker ps  --format="{{.Names}}")
  do
      logerror "####################################################"
      logerror "$container logs"
      if [[ "$container" == "connect" ]] || [[ "$container" == "sap" ]]
      then
          # always show all logs for connect
          docker container logs --tail=100 $container 2>&1 | grep -v "was supplied but isn't a known config"
      else
          docker container logs $container 2>&1 | egrep "ERROR|FATAL"

      fi
      logwarn "####################################################"
  done
}

function retry() {
  local n=1
  local max_retriable=4
  local max_default_retry=2
  while true; do
    "$@"
    ret=$?
    if [ $ret -eq 0 ]
    then
      return 0
    elif [ $ret -eq 111 ] # skipped
    then
      return 111
    elif [ $ret -eq 107 ] # known issue https://github.com/vdesabou/kafka-docker-playground/issues/907
    then
      return 107
    else
      test_file=$(echo "$@" | awk '{ print $4}')
      script=$(basename $test_file)
      # check for retriable scripts in scripts/tests-retriable.txt
      grep "$script" ${DIR}/tests-retriable.txt > /dev/null
      if [ $? = 0 ]
      then
        if [[ $n -lt $max_retriable ]]; then
          ((n++))
          logwarn "####################################################"
          logwarn "🧟‍♂️ The test $script (retriable) has failed. Retrying (attempt $n/$max_retriable)"
          logwarn "####################################################"
          display_docker_container_error_log
        else
          logerror "💀 The test $script (retriable) has failed after $n attempts."
          return 1
        fi
      else
        if [[ $n -lt $max_default_retry ]]; then
          ((n++))
          logwarn "####################################################"
          logwarn "🎰 The test $script (default_retry) has failed. Retrying (attempt $n/$max_default_retry)"
          logwarn "####################################################"
          display_docker_container_error_log
        else
          logerror "💀 The test $script (default_retry) has failed after $n attempts."
          return 1
        fi
      fi
    fi
  done
}

retrycmd() {
    local -r -i max_attempts="$1"; shift
    local -r -i sleep_interval="$1"; shift
    local -r cmd="$@"
    local -i attempt_num=1

    until $cmd
    do
        if (( attempt_num == max_attempts ))
        then
            display_docker_container_error_log
            logerror "Failed after $attempt_num attempts. Please troubleshoot and run again."
            return 1
        else
            printf "."
            ((attempt_num++))
            sleep $sleep_interval
        fi
    done
    printf "\n"
}

# for RBAC, taken from cp-demo
function host_check_kafka_cluster_registered() {
  KAFKA_CLUSTER_ID=$(docker container exec zookeeper zookeeper-shell zookeeper:2181 get /cluster/id 2> /dev/null | grep \"version\" | jq -r .id)
  if [ -z "$KAFKA_CLUSTER_ID" ]; then
    return 1
  fi
  echo $KAFKA_CLUSTER_ID
  return 0
}

# for RBAC, taken from cp-demo
function host_check_mds_up() {
  docker container logs broker > /tmp/out.txt 2>&1
  FOUND=$(cat /tmp/out.txt | grep "Started NetworkTrafficServerConnector")
  if [ -z "$FOUND" ]; then
    return 1
  fi
  return 0
}

# for RBAC, taken from cp-demo
function mds_login() {
  MDS_URL=$1
  SUPER_USER=$2
  SUPER_USER_PASSWORD=$3

  # Log into MDS
  if [[ $(type expect 2>&1) =~ "not found" ]]; then
    echo "'expect' is not found. Install 'expect' and try again"
    exit 1
  fi
  echo -e "\n# Login"
  OUTPUT=$(
  expect <<END
    log_user 1
    spawn confluent login --url $MDS_URL
    expect "Username: "
    send "${SUPER_USER}\r";
    expect "Password: "
    send "${SUPER_USER_PASSWORD}\r";
    expect "Logged in as "
    set result $expect_out(buffer)
END
  )
  echo "$OUTPUT"
  if [[ ! "$OUTPUT" =~ "Logged in as" ]]; then
    echo "Failed to log into MDS.  Please check all parameters and run again"
    exit 1
  fi
}

# https://raw.githubusercontent.com/zlabjp/kubernetes-scripts/master/wait-until-pods-ready

function __is_pod_ready() {
  [[ "$(kubectl get po "$1" -n $namespace -o 'jsonpath={.status.conditions[?(@.type=="Ready")].status}')" == 'True' ]]
}

function __pods_ready() {
  local pod

  [[ "$#" == 0 ]] && return 0

  for pod in $pods; do
    __is_pod_ready "$pod" || return 1
  done

  return 0
}

function wait-until-pods-ready() {
  local period interval i pods

  if [[ $# != 3 ]]; then
    echo "Usage: wait-until-pods-ready PERIOD INTERVAL NAMESPACE" >&2
    echo "" >&2
    echo "This script waits for all pods to be ready in the current namespace." >&2

    return 1
  fi

  period="$1"
  interval="$2"
  namespace="$3"

  sleep 10

  for ((i=0; i<$period; i+=$interval)); do
    pods="$(kubectl get po -n $namespace -o 'jsonpath={.items[*].metadata.name}')"
    if __pods_ready $pods; then
      return 0
    fi

    echo "Waiting for pods to be ready..."
    sleep "$interval"
  done

  echo "Waited for $period seconds, but all pods are not ready yet."
  return 1
}

function wait_for_datagen_connector_to_inject_data () {
  sleep 3
  connector_name="$1"
  datagen_tasks="$2"
  prefix_cmd="$3"
  set +e
  # wait for all tasks to be FAILED with org.apache.kafka.connect.errors.ConnectException: Stopping connector: generated the configured xxx number of messages
  MAX_WAIT=3600
  CUR_WAIT=0
  log "⌛ Waiting up to $MAX_WAIT seconds for connector $connector_name to finish injecting requested load"
  $prefix_cmd curl -s -X GET http://localhost:8083/connectors/datagen-${connector_name}/status | jq .tasks[].trace | grep "generated the configured" | wc -l > /tmp/out.txt 2>&1
  while [[ ! $(cat /tmp/out.txt) =~ "${datagen_tasks}" ]]; do
    sleep 5
    $prefix_cmd curl -s -X GET http://localhost:8083/connectors/datagen-${connector_name}/status | jq .tasks[].trace | grep "generated the configured" | wc -l > /tmp/out.txt 2>&1
    CUR_WAIT=$(( CUR_WAIT+10 ))
    if [[ "$CUR_WAIT" -gt "$MAX_WAIT" ]]; then
      echo -e "\nERROR: Please troubleshoot'.\n"
      $prefix_cmd curl -s -X GET http://localhost:8083/connectors/datagen-${connector_name}/status | jq
      exit 1
    fi
  done
  log "Connector $connector_name has finish injecting requested load"
  set -e
}

# https://gist.github.com/Fuxy22/da4b7ca3bcb0bfea2c582964eafeb4ed
# remove specified host from /etc/hosts
function removehost() {
    if [ ! -z "$1" ]
    then
        HOSTNAME=$1

        if [ -n "$(grep $HOSTNAME /etc/hosts)" ]
        then
            echo "$HOSTNAME Found in your /etc/hosts, Removing now...";
            sudo sed -i".bak" "/$HOSTNAME/d" /etc/hosts
        else
            echo "$HOSTNAME was not found in your /etc/hosts";
        fi
    else
        echo "Error: missing required parameters."
        echo "Usage: "
        echo "  removehost domain"
    fi
}

# https://gist.github.com/Fuxy22/da4b7ca3bcb0bfea2c582964eafeb4ed
#add new ip host pair to /etc/hosts
function addhost() {
    if [ $# -eq 2 ]
    then
        IP=$1
        HOSTNAME=$2

        if [ -n "$(grep $HOSTNAME /etc/hosts)" ]
            then
                echo "$HOSTNAME already exists:";
                echo $(grep $HOSTNAME /etc/hosts);
            else
                echo "Adding $HOSTNAME to your /etc/hosts";
                printf "%s\t%s\n" "$IP" "$HOSTNAME" | sudo tee -a /etc/hosts > /dev/null;

                if [ -n "$(grep $HOSTNAME /etc/hosts)" ]
                    then
                        echo "$HOSTNAME was added succesfully:";
                        echo $(grep $HOSTNAME /etc/hosts);
                    else
                        echo "Failed to Add $HOSTNAME, Try again!";
                fi
        fi
    else
        echo "Error: missing required parameters."
        echo "Usage: "
        echo "  addhost ip domain"
    fi
}

function stop_all() {
  current_dir="$1"
  cd ${current_dir}
  if ls docker-compose.* 1> /dev/null 2>&1;
  then
    for docker_compose_file in $(ls docker-compose.*)
    do
        environment=$(echo $docker_compose_file | cut -d "." -f 2)
        ${DIR}/../../environment/${environment}/stop.sh "${PWD}/${docker_compose_file}"
    done
  else
    ${DIR}/../../environment/plaintext/stop.sh
  fi
  cd -
}

function display_jmx_info() {
  if [ -z "$ENABLE_JMX_GRAFANA" ]
  then
    log "📊 JMX metrics are available locally on those ports:"
  else
    log "🛡️ Prometheus is reachable at http://127.0.0.1:9090"
    log "📛 Pyroscope is reachable at http://127.0.0.1:4040"
    log "📊 Grafana is reachable at http://127.0.0.1:3000 or JMX metrics are available locally on those ports:"
  fi

  log "    - zookeeper       : 9999"
  log "    - broker          : 10000"
  log "    - schema-registry : 10001"
  log "    - connect         : 10002"

  if [ ! -z "$ENABLE_KSQLDB" ]
  then
    log "    - ksqldb-server   : 10003"
  fi
}
function get_jmx_metrics() {
  JMXTERM_VERSION="1.0.2"
  JMXTERM_UBER_JAR="/tmp/jmxterm-$JMXTERM_VERSION-uber.jar"
  if [ ! -f $JMXTERM_UBER_JAR ]
  then
    curl -L https://github.com/jiaqi/jmxterm/releases/download/v$JMXTERM_VERSION/jmxterm-$JMXTERM_VERSION-uber.jar -o $JMXTERM_UBER_JAR -s
  fi

  rm -f /tmp/commands
  rm -f /tmp/jmx_metrics.log

  component="$1"
  domains="$2"
  if [ "$domains" = "" ]
  then
    # non existing domain: all domains will be in output !
    logwarn "You did not specify a list of domains, all domains will be exported!"
    domains="ALL"
  fi

  case "$component" in
  zookeeper )
    port=9999
  ;;
  broker )
    port=10000
  ;;
  schema-registry )
    port=10001
  ;;
  connect )
    port=10002
  ;;
  n|N ) ;;
  * ) logerror "invalid component $component! it should be one of zookeeper, broker, schema-registry or connect";exit 1;;
  esac

  docker cp $JMXTERM_UBER_JAR $component:$JMXTERM_UBER_JAR
  if [ "$domains" = "ALL" ]
  then

log "This is the list of domains for component $component"
docker exec -i $component java -jar $JMXTERM_UBER_JAR  -l localhost:$port -n -v silent << EOF
domains
exit
EOF
  fi

for domain in `echo $domains`
do
docker exec -i $component java -jar $JMXTERM_UBER_JAR  -l localhost:$port -n -v silent > /tmp/beans.log << EOF
domain $domain
beans
exit
EOF
  while read line; do echo "get *"  -b $line; done < /tmp/beans.log >> /tmp/commands

  echo "####### domain $domain ########" >> /tmp/jmx_metrics.log
  docker exec -i $component java -jar $JMXTERM_UBER_JAR  -l localhost:$port -n < /tmp/commands >> /tmp/jmx_metrics.log 2>&1
done

  if config_has_key "editor"
  then
    editor=$(config_get "editor")
    log "📖 Opening /tmp/jmx_metrics.log using configured editor $editor"
    $editor /tmp/jmx_metrics.log
  else
    if [[ $(type code 2>&1) =~ "not found" ]]
    then
      logerror "Could not determine an editor to use as default code is not found - you can change editor by updating config.ini"
      exit 1
    else
      log "📖 Opening /tmp/jmx_metrics.log with code (default) - you can change editor by updating config.ini"
      code /tmp/jmx_metrics.log
    fi
  fi
}

# https://www.linuxjournal.com/content/validating-ip-address-bash-script
function valid_ip()
{
    local  ip=$1
    local  stat=1

    if [[ $ip =~ ^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$ ]]; then
        OIFS=$IFS
        IFS='.'
        ip=($ip)
        IFS=$OIFS
        [[ ${ip[0]} -le 255 && ${ip[1]} -le 255 \
            && ${ip[2]} -le 255 && ${ip[3]} -le 255 ]]
        stat=$?
    fi
    return $stat
}

function container_to_name() {
    container=$1
    echo "${PWD##*/}_${container}_1"
}

function container_to_ip() {
    if [ $# -lt 1 ]; then
        echo "Usage: container_to_ip container"
    fi
    echo $(docker inspect $1 -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}')
}

function clear_traffic_control() {
    if [ $# -lt 1 ]; then
        echo "Usage: clear_traffic_control src_container"
    fi

    src_container=$1

    echo "Removing all traffic control settings on $src_container"

    # Delete the entry from the tc table so the changes made to tc do not persist
    docker exec --privileged -u0 -t $src_container tc qdisc del dev eth0 root
}

function get_latency() {
    if [ $# -lt 2 ]; then
        echo "Usage: get_latency src_container dst_container"
    fi
    src_container=$1
    dst_container=$2
    docker exec --privileged -u0 -t $src_container ping $dst_container -c 4 -W 80 | tail -1 | awk -F '/' '{print $5}'
}

# https://serverfault.com/a/906499
function add_latency() {
    if [ $# -lt 3 ]; then
        echo "Usage: add_latency src_container dst_container (or ip address) latency"
        echo "Example: add_latency container-1 container-2 100ms"
    fi

    src_container=$1
    if valid_ip $2
    then

      dst_ip=$2
    else

      dst_ip=$(container_to_ip $2)
    fi
    latency=$3

    set +e
    clear_traffic_control $src_container
    set -e

    echo "Adding $latency latency from $src_container to $2"

    # Add a classful priority queue which lets us differentiate messages.
    # This queue is named 1:.
    # Three children classes, 1:1, 1:2 and 1:3, are automatically created.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 root handle 1: prio

    # Add a filter to the parent queue 1: (also called 1:0). The filter has priority 1 (if we had more filters this would make a difference).
    # For all messages with the ip of dst_ip as their destination, it routes them to class 1:1, which
    # subsequently sends them to its only child, queue 10: (All messages need to  "end up" in a queue).
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol ip parent 1: prio 1 u32 match ip dst $dst_ip flowid 1:1

    # Route the rest of the of the packets without any control.
    # Add a filter to the parent queue 1:. The filter has priority 2.
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip dst 0.0.0.0/0 flowid 1:2
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip protocol 1 0xff flowid 1:2

    # Add a child queue named 10: under class 1:1. All outgoing packets that will be routed to 10: will have delay applied them.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:1 handle 10: netem delay $latency

    # Add a child queue named 20: under class 1:2
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:2 handle 20: sfq
}

function add_packet_corruption() {
    if [ $# -lt 3 ]; then
        echo "Usage: add_packet_corruption src_container dst_container (or ip address) corrupt"
        echo "Exemple: add_packet_corruption container-1 container-2 1%"
    fi

    src_container=$1
    if valid_ip $2
    then

      dst_ip=$2
    else

      dst_ip=$(container_to_ip $2)
    fi
    corruption=$3

    set +e
    clear_traffic_control $src_container
    set -e

    echo "Adding $corruption corruption from $src_container to $2"

    # Add a classful priority queue which lets us differentiate messages.
    # This queue is named 1:.
    # Three children classes, 1:1, 1:2 and 1:3, are automatically created.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 root handle 1: prio

    # Add a filter to the parent queue 1: (also called 1:0). The filter has priority 1 (if we had more filters this would make a difference).
    # For all messages with the ip of dst_ip as their destination, it routes them to class 1:1, which
    # subsequently sends them to its only child, queue 10: (All messages need to  "end up" in a queue).
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol ip parent 1: prio 1 u32 match ip dst $dst_ip flowid 1:1

    # Route the rest of the of the packets without any control.
    # Add a filter to the parent queue 1:. The filter has priority 2.
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip dst 0.0.0.0/0 flowid 1:2

    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip protocol 1 0xff flowid 1:2

    # Add a child queue named 10: under class 1:1. All outgoing packets that will be routed to 10: will have corrupt applied them.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:1 handle 10: netem corrupt $corruption

    # Add a child queue named 20: under class 1:2
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:2 handle 20: sfq

}

function add_packet_loss() {
    if [ $# -lt 3 ]; then
        echo "Usage: add_packet_loss src_container dst_container (or ip address) corrupt"
        echo "Exemple: add_packet_loss container-1 container-2 1%"
    fi

    src_container=$1
    if valid_ip $2
    then

      dst_ip=$2
    else

      dst_ip=$(container_to_ip $2)
    fi
    loss=$3

    set +e
    clear_traffic_control $src_container
    set -e

    echo "Adding $loss loss from $src_container to $2"

    # Add a classful priority queue which lets us differentiate messages.
    # This queue is named 1:.
    # Three children classes, 1:1, 1:2 and 1:3, are automatically created.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 root handle 1: prio

    # Add a filter to the parent queue 1: (also called 1:0). The filter has priority 1 (if we had more filters this would make a difference).
    # For all messages with the ip of dst_ip as their destination, it routes them to class 1:1, which
    # subsequently sends them to its only child, queue 10: (All messages need to  "end up" in a queue).
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol ip parent 1: prio 1 u32 match ip dst $dst_ip flowid 1:1

    # Route the rest of the of the packets without any control.
    # Add a filter to the parent queue 1:. The filter has priority 2.
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip dst 0.0.0.0/0 flowid 1:2

    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip protocol 1 0xff flowid 1:2

    # Add a child queue named 10: under class 1:1. All outgoing packets that will be routed to 10: will have loss applied them.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:1 handle 10: netem loss $loss

    # Add a child queue named 20: under class 1:2
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:2 handle 20: sfq

}

function get_3rdparty_file () {
  file="$1"

  if [ -f $file ]
  then
    log "$file already present, skipping"
    return
  fi

  folder="3rdparty"
  if [[ "$file" == *repro* ]]
  then
    folder="repro-files"
  fi
  set +e
  aws s3 ls s3://kafka-docker-playground/$folder/$file > /dev/null 2>&1
  if [ $? -eq 0 ]
  then
      log "Downloading <s3://kafka-docker-playground/$folder/$file> from S3 bucket"
      aws s3 cp --only-show-errors "s3://kafka-docker-playground/$folder/$file" .
      if [ $? -eq 0 ]; then
        log "📄 <s3://kafka-docker-playground/$folder/$file> was downloaded from S3 bucket"
      fi
      if [[ "$OSTYPE" == "darwin"* ]]
      then
          # workaround for issue on linux, see https://github.com/vdesabou/kafka-docker-playground/issues/851#issuecomment-821151962
          chmod a+rw $file
      else
          # on CI, docker is run as runneradmin user, need to use sudo
          sudo chmod a+rw $file
      fi
  fi
  set -e
}

function remove_cdb_oracle_image() {
  ZIP_FILE="$1"
  SETUP_FOLDER="$2"

  if [ "$ZIP_FILE" == "linuxx64_12201_database.zip" ]
  then
      ORACLE_VERSION="12.2.0.1-ee"
  elif [ "$ZIP_FILE" == "LINUX.X64_180000_db_home.zip" ]
  then
      ORACLE_VERSION="18.3.0-ee"
  elif [ "$ZIP_FILE" == "LINUX.X64_213000_db_home.zip" ]
  then
      ORACLE_VERSION="21.3.0-ee"
  else
      ORACLE_VERSION="19.3.0-ee"
  fi

  SETUP_FILE=${SETUP_FOLDER}/01_user-setup.sh
  SETUP_FILE_CKSUM=$(cksum $SETUP_FILE | awk '{ print $1 }')
  ORACLE_IMAGE="db-prebuilt-$SETUP_FILE_CKSUM:$ORACLE_VERSION"

  if ! test -z "$(docker images -q $ORACLE_IMAGE)"
  then
    log "🧹 Removing Oracle image $ORACLE_IMAGE"
    docker image rm $ORACLE_IMAGE
  fi
}

function create_or_get_oracle_image() {
  ZIP_FILE="$1"
  SETUP_FOLDER="$2"

  if [ "$ZIP_FILE" == "linuxx64_12201_database.zip" ]
  then
      ORACLE_VERSION="12.2.0.1-ee"
  elif [ "$ZIP_FILE" == "LINUX.X64_180000_db_home.zip" ]
  then
      ORACLE_VERSION="18.3.0-ee"
  elif [ "$ZIP_FILE" == "LINUX.X64_213000_db_home.zip" ]
  then
      ORACLE_VERSION="21.3.0-ee"
  else
      ORACLE_VERSION="19.3.0-ee"
  fi
  # used for docker-images repo
  DOCKERFILE_VERSION=$(echo "$ORACLE_VERSION" | cut -d "-" -f 1)

  # https://github.com/oracle/docker-images/tree/main/OracleDatabase/SingleInstance/samples/prebuiltdb
  SETUP_FILE=${SETUP_FOLDER}/01_user-setup.sh
  SETUP_FILE_CKSUM=$(cksum $SETUP_FILE | awk '{ print $1 }')
  export ORACLE_IMAGE="db-prebuilt-$SETUP_FILE_CKSUM:$ORACLE_VERSION"
  TEMP_CONTAINER="oracle-build-$ORACLE_VERSION-$(basename $SETUP_FOLDER)"

  if test -z "$(docker images -q $ORACLE_IMAGE)"
  then
    set +e
    aws s3 ls s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar > /dev/null 2>&1
    if [ $? -eq 0 ]
    then
        log "Downloading <s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar> from S3 bucket"
        aws s3 cp --only-show-errors "s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar" /tmp/
        if [ $? -eq 0 ]
        then
          log "📄 <s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar> was downloaded from S3 bucket"
          docker load -i /tmp/$ORACLE_IMAGE.tar
          if [ $? -eq 0 ]
          then
            log "📄 image $ORACLE_IMAGE has been installed locally"
          fi
          log "🧹 Removing /tmp/$ORACLE_IMAGE.tar"
          rm -f /tmp/$ORACLE_IMAGE.tar
        fi
    else
        logwarn "If you're a Confluent employee, please check this link https://confluent.slack.com/archives/C0116NM415F/p1636391410032900 and also here https://confluent.slack.com/archives/C0116NM415F/p1636389483030900."
    fi
    set -e
  fi

  if ! test -z "$(docker images -q $ORACLE_IMAGE)"
  then
    log "✨ Using Oracle prebuilt image $ORACLE_IMAGE (oracle version 🔢 $ORACLE_VERSION and 📂 setup folder $SETUP_FOLDER)"
    return
  fi

  BASE_ORACLE_IMAGE="oracle/database:$ORACLE_VERSION"

  if test -z "$(docker images -q $BASE_ORACLE_IMAGE)"
  then
    set +e
    aws s3 ls s3://kafka-docker-playground/3rdparty/oracle_database_$ORACLE_VERSION.tar > /dev/null 2>&1
    if [ $? -eq 0 ]
    then
        log "Downloading <s3://kafka-docker-playground/3rdparty/oracle_database_$ORACLE_VERSION.tar> from S3 bucket"
        aws s3 cp --only-show-errors "s3://kafka-docker-playground/3rdparty/oracle_database_$ORACLE_VERSION.tar" /tmp/
        if [ $? -eq 0 ]
        then
          log "📄 <s3://kafka-docker-playground/3rdparty/oracle_database_$ORACLE_VERSION.tar> was downloaded from S3 bucket"
          docker load -i /tmp/oracle_database_$ORACLE_VERSION.tar
          if [ $? -eq 0 ]
          then
            log "📄 image $BASE_ORACLE_IMAGE has been installed locally"
          fi
          log "🧹 Removing /tmp/$ORACLE_IMAGE.tar"
          rm -f /tmp/oracle_database_$ORACLE_VERSION.tar
        fi
    fi
    set -e
  fi

  if test -z "$(docker images -q $BASE_ORACLE_IMAGE)"
  then
      if [ ! -f ${ZIP_FILE} ]
      then
          set +e
          aws s3 ls s3://kafka-docker-playground/3rdparty/${ZIP_FILE} > /dev/null 2>&1
          if [ $? -eq 0 ]
          then
              log "Downloading <s3://kafka-docker-playground/3rdparty/${ZIP_FILE}> from S3 bucket"
              aws s3 cp --only-show-errors "s3://kafka-docker-playground/3rdparty/${ZIP_FILE}" .
              if [ $? -eq 0 ]; then
                    log "📄 <s3://kafka-docker-playground/3rdparty/${ZIP_FILE}> was downloaded from S3 bucket"
              fi
          fi
          set -e
      fi
      if [ ! -f ${ZIP_FILE} ]
      then
          logerror "ERROR: ${ZIP_FILE} is missing. It must be downloaded manually in order to acknowledge user agreement"
          exit 1
      fi
      log "👷 Building $BASE_ORACLE_IMAGE docker image..it can take a while...(more than 15 minutes!)"
      OLDDIR=$PWD
      rm -rf docker-images
      git clone https://github.com/oracle/docker-images.git

      mv ${ZIP_FILE} docker-images/OracleDatabase/SingleInstance/dockerfiles/$DOCKERFILE_VERSION/${ZIP_FILE}
      cd docker-images/OracleDatabase/SingleInstance/dockerfiles
      ./buildContainerImage.sh -v $DOCKERFILE_VERSION -e
      rm -rf docker-images
      cd ${OLDDIR}
  fi

  export ORACLE_IMAGE="db-prebuilt-$SETUP_FILE_CKSUM:$ORACLE_VERSION"

  if test -z "$(docker images -q $ORACLE_IMAGE)"
  then
      log "🏭 Prebuilt $ORACLE_IMAGE docker image does not exist, building it now..it can take a while..."
      log "🚦 Startup a container ${TEMP_CONTAINER} with setup folder $SETUP_FOLDER and create the database"
      cd $SETUP_FOLDER
      docker run -d -e ORACLE_PWD=Admin123 -v $PWD:/opt/oracle/scripts/setup --name ${TEMP_CONTAINER} ${BASE_ORACLE_IMAGE}
      cd -

      MAX_WAIT=2500
      CUR_WAIT=0
      log "⌛ Waiting up to $MAX_WAIT seconds for ${TEMP_CONTAINER} to start"
      docker container logs ${TEMP_CONTAINER} > /tmp/out.txt 2>&1
      while [[ ! $(cat /tmp/out.txt) =~ "DATABASE IS READY TO USE" ]]; do
      sleep 10
      docker container logs ${TEMP_CONTAINER} > /tmp/out.txt 2>&1
      CUR_WAIT=$(( CUR_WAIT+10 ))
      if [[ "$CUR_WAIT" -gt "$MAX_WAIT" ]]; then
            logerror "ERROR: The logs in ${TEMP_CONTAINER} container do not show 'DATABASE IS READY TO USE' after $MAX_WAIT seconds. Please troubleshoot with 'docker container ps' and 'docker container logs'.\n"
            exit 1
      fi
      done
      log "${TEMP_CONTAINER} has started! Check logs in /tmp/${TEMP_CONTAINER}.log"
      docker container logs ${TEMP_CONTAINER} > /tmp/${TEMP_CONTAINER}.log 2>&1
      log "🛑 Stop the running container"
      docker stop -t 600 ${TEMP_CONTAINER}
      log "🛠 Create the image with the prebuilt database"
      docker commit -m "Image with prebuilt database" ${TEMP_CONTAINER} ${ORACLE_IMAGE}
      log "🧹 Clean up ${TEMP_CONTAINER}"
      docker rm ${TEMP_CONTAINER}

      if [ ! -z "$CI" ]
      then
          set +e
          aws s3 ls s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar > /dev/null 2>&1
          if [ $? -ne 0 ]
          then
              log "📄 Uploading </tmp/$ORACLE_IMAGE.tar> to S3 bucket"
              docker save -o /tmp/$ORACLE_IMAGE.tar $ORACLE_IMAGE
              aws s3 cp --only-show-errors "/tmp/$ORACLE_IMAGE.tar" "s3://kafka-docker-playground/3rdparty/"
              if [ $? -eq 0 ]; then
                    log "📄 </tmp/$ORACLE_IMAGE.tar> was uploaded to S3 bucket"
              fi
          fi
          set -e
      fi
  fi

  log "✨ Using Oracle prebuilt image $ORACLE_IMAGE (oracle version 🔢 $ORACLE_VERSION and 📂 setup folder $SETUP_FOLDER)"
}

function print_code_pass() {
  local MESSAGE=""
	local CODE=""
  OPTIND=1
  while getopts ":c:m:" opt; do
    case ${opt} in
			c ) CODE=${OPTARG};;
      m ) MESSAGE=${OPTARG};;
		esac
	done
  shift $((OPTIND-1))
	printf "${PRETTY_PASS}${PRETTY_CODE}%s\e[0m\n" "${CODE}"
	[[ -z "$MESSAGE" ]] || printf "\t$MESSAGE\n"

}
function print_code_error() {
  local MESSAGE=""
	local CODE=""
  OPTIND=1
  while getopts ":c:m:" opt; do
    case ${opt} in
			c ) CODE=${OPTARG};;
      m ) MESSAGE=${OPTARG};;
		esac
	done
  shift $((OPTIND-1))
	printf "${PRETTY_ERROR}${PRETTY_CODE}%s\e[0m\n" "${CODE}"
	[[ -z "$MESSAGE" ]] || printf "\t$MESSAGE\n"

}

function exit_with_error()
{
  local USAGE="\nUsage: exit_with_error -c code -n name -m message -l line_number\n"
  local NAME=""
  local MESSAGE=""
  local CODE=$UNSPECIFIED_ERROR
  local LINE=
  OPTIND=1
  while getopts ":n:m:c:l:" opt; do
    case ${opt} in
      n ) NAME=${OPTARG};;
      m ) MESSAGE=${OPTARG};;
      c ) CODE=${OPTARG};;
      l ) LINE=${OPTARG};;
      ? ) printf $USAGE;return 1;;
    esac
  done
  shift $((OPTIND-1))
  print_error "error ${CODE} occurred in ${NAME} at line $LINE"
	printf "\t${MESSAGE}\n"
  exit $CODE
}

function maybe_delete_ccloud_environment () {
  DELTA_CONFIGS_ENV=/tmp/delta_configs/env.delta

  if [ -f $DELTA_CONFIGS_ENV ]
  then
    source $DELTA_CONFIGS_ENV
  else
    logerror "ERROR: $DELTA_CONFIGS_ENV has not been generated"
    exit 1
  fi

  if [ -z "$CLUSTER_NAME" ]
  then
    #

    # CLUSTER_NAME is not set
    #
    log "🧹❌ Confluent Cloud cluster will be deleted..."
    verify_installed "confluent"
    check_confluent_version 2.0.0 || exit 1
    verify_confluent_login  "confluent kafka cluster list"

    export QUIET=true

    if [ ! -z "$ENVIRONMENT" ]
    then
      log "🌐 ENVIRONMENT $ENVIRONMENT is set, it will not be deleted"
      export PRESERVE_ENVIRONMENT=true
    else
      export PRESERVE_ENVIRONMENT=false
    fi
    SERVICE_ACCOUNT_ID=$(ccloud:get_service_account_from_current_cluster_name)
    set +e
    ccloud::destroy_ccloud_stack $SERVICE_ACCOUNT_ID
    set -e
  fi
}

function bootstrap_ccloud_environment () {
  DELTA_CONFIGS_ENV=/tmp/delta_configs/env.delta

  if [ -z "$CI" ] && [ -z "$CLOUDFORMATION" ]
  then
    # not running with CI
    verify_installed "confluent"
    check_confluent_version 3.0.0 || exit 1
    verify_confluent_login  "confluent kafka cluster list"
  else
      log "Installing confluent CLI"
      curl -L --http1.1 https://cnfl.io/cli | sudo sh -s -- -b /usr/local/bin
      export PATH=$PATH:/usr/local/bin
      log "##################################################"
      log "Log in to Confluent Cloud"
      log "##################################################"
      confluent login --save
  fi

  if [ -z "$CLUSTER_NAME" ]
  then
    #

    # CLUSTER_NAME is not set
    #
    log "🛠👷‍♀️ CLUSTER_NAME is not set, a new Confluent Cloud cluster will be created..."
    log "🎓 If you wanted to use an existing cluster, set CLUSTER_NAME, ENVIRONMENT, CLUSTER_CLOUD, CLUSTER_REGION and CLUSTER_CREDS (also optionnaly SCHEMA_REGISTRY_CREDS)"

    if [ -z "$CLUSTER_CLOUD" ] || [ -z "$CLUSTER_REGION" ]
    then
      logwarn "CLUSTER_CLOUD and/or CLUSTER_REGION are not set, the cluster will be created 🌤 AWS provider and 🗺 eu-west-2 region"
      export CLUSTER_CLOUD=aws

      export CLUSTER_REGION=eu-west-2
    fi

    if [ ! -z $ENVIRONMENT ]
    then
      log "🌐 ENVIRONMENT is set with $ENVIRONMENT and will be used"
    fi
    log "🌤  CLUSTER_CLOUD is set with $CLUSTER_CLOUD"
    log "🗺  CLUSTER_REGION is set with $CLUSTER_REGION"

    export EXAMPLE=$(basename $PWD)
    export WARMUP_TIME=15
    export QUIET=true
  else
    #

    # CLUSTER_NAME is set
    #
    log "🌱 CLUSTER_NAME is set, your existing Confluent Cloud cluster will be used..."
    if [ -z $ENVIRONMENT ] || [ -z $CLUSTER_CLOUD ] || [ -z $CLUSTER_CLOUD ] || [ -z $CLUSTER_REGION ] || [ -z $CLUSTER_CREDS ]
    then
      logerror "One mandatory environment variable to use your cluster is missing:"
      logerror "ENVIRONMENT=$ENVIRONMENT"
      logerror "CLUSTER_NAME=$CLUSTER_NAME"
      logerror "CLUSTER_CLOUD=$CLUSTER_CLOUD"
      logerror "CLUSTER_REGION=$CLUSTER_REGION"
      logerror "CLUSTER_CREDS=$CLUSTER_CREDS"
      exit 1
    fi

    log "🌐 ENVIRONMENT is set with $ENVIRONMENT"
    log "🎰 CLUSTER_NAME is set with $CLUSTER_NAME"
    log "🌤  CLUSTER_CLOUD is set with $CLUSTER_CLOUD"
    log "🗺  CLUSTER_REGION is set with $CLUSTER_REGION"

    export WARMUP_TIME=0
  fi

  check_if_continue

  ccloud::create_ccloud_stack false  \
    && print_code_pass -c "ccloud::create_ccloud_stack false"

  CCLOUD_CONFIG_FILE=/tmp/tmp.config
  export CCLOUD_CONFIG_FILE=$CCLOUD_CONFIG_FILE
  ccloud::validate_ccloud_config $CCLOUD_CONFIG_FILE || exit 1

  ccloud::generate_configs $CCLOUD_CONFIG_FILE \
    && print_code_pass -c "ccloud::generate_configs $CCLOUD_CONFIG_FILE"

  if [ -f $DELTA_CONFIGS_ENV ]
  then
    source $DELTA_CONFIGS_ENV
  else
    logerror "ERROR: $DELTA_CONFIGS_ENV has not been generated"
    exit 1
  fi
}

function create_ccloud_connector() {
  file=$1

  log "Creating connector from $file"
  confluent connect cluster create --config-file $file
  if [[ $? != 0 ]]
  then
    logerror "Exit status was not 0 while creating connector from $file.  Please troubleshoot and try again"
  fi

  return 0
}

function validate_ccloud_connector_up() {
  confluent connect cluster list -o json | jq -e 'map(select(.name == "'"$1"'" and .status == "RUNNING")) | .[]' > /dev/null 2>&1
}

function get_ccloud_connector_lcc() {
  confluent connect cluster list -o json | jq -r -e 'map(select(.name == "'"$1"'")) | .[].id'
}

function ccloud::retry() {
    local -r -i max_wait="$1"; shift
    local -r cmd="$@"

    local -i sleep_interval=5
    local -i curr_wait=0

    until $cmd
    do
        if (( curr_wait >= max_wait ))
        then
            echo "ERROR: Failed after $curr_wait seconds. Please troubleshoot and run again."
            return 1
        else
            printf "."
            curr_wait=$((curr_wait+sleep_interval))
            sleep $sleep_interval
        fi
    done
    printf "\n"
}

function wait_for_ccloud_connector_up() {
  filename=$1
  maxWait=$2

  connectorName=$(cat $filename | jq -r .name)
  connectorId=$(get_ccloud_connector_lcc $connectorName)
  log "Waiting up to $maxWait seconds for connector $connectorName ($connectorId) to be RUNNING"
  ccloud::retry $maxWait validate_ccloud_connector_up $connectorName || exit 1
  log "Connector $connectorName ($connectorId) is RUNNING"

  return 0
}

function delete_ccloud_connector() {
  filename=$1
  connectorName=$(cat $filename | jq -r .name)
  connectorId=$(get_ccloud_connector_lcc $connectorName)

  log "Deleting connector $connectorName ($connectorId)"
  confluent connect cluster delete $connectorId --force
  return 0
}

function wait_for_log () {
     message="$1"
     container=${2:-connect}
     max_wait=${3:-600}
     cur_wait=0
     log "⌛ Waiting up to $max_wait seconds for message $message to be present in $container container logs..."
     docker container logs connect > /tmp/out.txt 2>&1
     while ! grep "$message" /tmp/out.txt > /dev/null;
     do
          sleep 10
          docker container logs connect > /tmp/out.txt 2>&1
          cur_wait=$(( cur_wait+10 ))
          if [[ "$cur_wait" -gt "$max_wait" ]]; then
               logerror "The logs in $container container do not show '$message' after $max_wait seconds. Please troubleshoot with 'docker container ps' and 'docker container logs'."
               return 1
          fi
     done
     grep "$message" /tmp/out.txt
     log "The log is there !"
}


CLI_MIN_VERSION=${CLI_MIN_VERSION:-2.5.0}

# --------------------------------------------------------------
# Library
# --------------------------------------------------------------

function ccloud::validate_expect_installed() {
  if [[ $(type expect 2>&1) =~ "not found" ]]; then
    echo "'expect' is not found. Install 'expect' and try again"
    exit 1
  fi

  return 0
}
function ccloud::validate_cli_installed() {
  if [[ $(type confluent 2>&1) =~ "not found" ]]; then
    echo "'confluent' is not found. Install the Confluent CLI (https://docs.confluent.io/confluent-cli/current/install.html) and try again."
    exit 1
  fi
}

function ccloud::validate_cli_v2() {
  ccloud::validate_cli_installed || exit 1

  if [[ -z $(confluent version 2>&1 | grep "Go") ]]; then
    echo "This example requires the new Confluent CLI. Please update your version and try again."
    exit 1
  fi

  return 0
}

function ccloud::validate_logged_in_cli() {
  ccloud::validate_cli_v2 || exit 1

  if [[ "$(confluent kafka cluster list 2>&1)" =~ "confluent login" ]]; then
    echo
    echo "ERROR: Not logged into Confluent Cloud."
    echo "Log in with the command 'confluent login --save' before running the example. The '--save' argument saves your Confluent Cloud user login credentials or refresh token (in the case of SSO) to the local netrc file."
    exit 1
  fi

  return 0
}

function ccloud::get_version_cli() {
  confluent version | grep "^Version:" | cut -d':' -f2 | cut -d'v' -f2
}

function ccloud::validate_version_cli() {
  ccloud::validate_cli_installed || exit 1

  CLI_VERSION=$(ccloud::get_version_cli)

  if ccloud::version_gt $CLI_MIN_VERSION $CLI_VERSION; then
    echo "confluent version ${CLI_MIN_VERSION} or greater is required. Current version: ${CLI_VERSION}"
    echo "To update, follow: https://docs.confluent.io/confluent-cli/current/migrate.html"
    exit 1
  fi
}

function ccloud::validate_psql_installed() {
  if [[ $(type psql 2>&1) =~ "not found" ]]; then
    echo "psql is not found. Install psql and try again"
    exit 1
  fi

  return 0
}

function ccloud::validate_aws_cli_installed() {
  if [[ $(type aws 2>&1) =~ "not found" ]]; then
    echo "AWS CLI is not found. Install AWS CLI and try again"
    exit 1
  fi

  return 0
}

function ccloud::get_version_aws_cli() {
  version_major=$(aws --version 2>&1 | awk -F/ '{print $2;}' | head -c 1)
  if [[ "$version_major" -eq 2 ]]; then
    echo "2"
  else
    echo "1"
  fi
  return 0
}

function ccloud::validate_gsutil_installed() {
  if [[ $(type gsutil 2>&1) =~ "not found" ]]; then
    echo "Google Cloud gsutil is not found. Install Google Cloud gsutil and try again"
    exit 1
  fi

  return 0
}

function ccloud::validate_az_installed() {
  if [[ $(type az 2>&1) =~ "not found" ]]; then
    echo "Azure CLI is not found. Install Azure CLI and try again"
    exit 1
  fi

  return 0
}

function ccloud::validate_cloud_source() {
  config=$1

  source $config

  if [[ "$DATA_SOURCE" == "kinesis" ]]; then
    ccloud::validate_aws_cli_installed || exit 1
    if [[ -z "$KINESIS_REGION" || -z "$AWS_PROFILE" ]]; then
      echo "ERROR: DATA_SOURCE=kinesis, but KINESIS_REGION or AWS_PROFILE is not set.  Please set these parameters in config/demo.cfg and try again."
      exit 1
    fi
    aws kinesis list-streams --profile $AWS_PROFILE --region $KINESIS_REGION > /dev/null \
      || { echo "Could not run 'aws kinesis list-streams'.  Check credentials and run again." ; exit 1; }
  elif [[ "$DATA_SOURCE" == "rds" ]]; then
    ccloud::validate_aws_cli_installed || exit 1
    if [[ -z "$RDS_REGION" || -z "$AWS_PROFILE" ]]; then
      echo "ERROR: DATA_SOURCE=rds, but RDS_REGION or AWS_PROFILE is not set.  Please set these parameters in config/demo.cfg and try again."
      exit 1
    fi
    aws rds describe-db-instances --profile $AWS_PROFILE --region $RDS_REGION > /dev/null \
      || { echo "Could not run 'aws rds describe-db-instances'.  Check credentials and run again." ; exit 1; }
  else
    echo "Cloud source $cloudsource is not valid.  Must be one of [kinesis|rds]."
    exit 1
  fi

  return 0
}

function ccloud::validate_cloud_storage() {
  config=$1

  source $config
  storage=$DESTINATION_STORAGE

  if [[ "$storage" == "s3" ]]; then
    ccloud::validate_aws_cli_installed || exit 1
    ccloud::validate_credentials_s3 $S3_PROFILE $S3_BUCKET || exit 1
    aws s3api list-buckets --profile $S3_PROFILE --region $STORAGE_REGION > /dev/null \
      || { echo "Could not run 'aws s3api list-buckets'.  Check credentials and run again." ; exit 1; }
  elif [[ "$storage" == "gcs" ]]; then
    ccloud::validate_gsutil_installed || exit 1
    ccloud::validate_credentials_gcp $GCS_CREDENTIALS_FILE $GCS_BUCKET || exit 1
  elif [[ "$storage" == "az" ]]; then
    ccloud::validate_az_installed || exit 1
    ccloud::validate_credentials_az $AZBLOB_STORAGE_ACCOUNT $AZBLOB_CONTAINER || exit 1
  else
    echo "Storage destination $storage is not valid.  Must be one of [s3|gcs|az]."
    exit 1
  fi

  return 0
}

function ccloud::validate_credentials_gcp() {
  GCS_CREDENTIALS_FILE=$1
  GCS_BUCKET=$2

  if [[ -z "$GCS_CREDENTIALS_FILE" || -z "$GCS_BUCKET" ]]; then
    echo "ERROR: DESTINATION_STORAGE=gcs, but GCS_CREDENTIALS_FILE or GCS_BUCKET is not set.  Please set these parameters in config/demo.cfg and try again."
    exit 1
  fi

  gcloud auth activate-service-account --key-file $GCS_CREDENTIALS_FILE || {
    echo "ERROR: Cannot activate service account with key file $GCS_CREDENTIALS_FILE. Verify your credentials and try again."
    exit 1
  }

  # Create JSON-formatted string of the GCS credentials
  export GCS_CREDENTIALS=$(python ./stringify-gcp-credentials.py $GCS_CREDENTIALS_FILE)
  # Remove leading and trailing double quotes, otherwise connector creation from CLI fails
  GCS_CREDENTIALS=$(echo "${GCS_CREDENTIALS:1:${#GCS_CREDENTIALS}-2}")

  return 0
}

function ccloud::validate_credentials_az() {
  AZBLOB_STORAGE_ACCOUNT=$1
  AZBLOB_CONTAINER=$2

  if [[ -z "$AZBLOB_STORAGE_ACCOUNT" || -z "$AZBLOB_CONTAINER" ]]; then
    echo "ERROR: DESTINATION_STORAGE=az, but AZBLOB_STORAGE_ACCOUNT or AZBLOB_CONTAINER is not set.  Please set these parameters in config/demo.cfg and try again."
    exit 1
  fi

  if [[ "$AZBLOB_STORAGE_ACCOUNT" == "default" ]]; then
    echo "ERROR: Azure Blob storage account name cannot be 'default'. Verify the value of the storage account name (did you create one?) in config/demo.cfg, as specified by the parameter AZBLOB_STORAGE_ACCOUNT, and try again."
    exit 1
  fi

  exists=$(az storage account check-name --name $AZBLOB_STORAGE_ACCOUNT | jq -r .reason)
  if [[ "$exists" != "AlreadyExists" ]]; then
    echo "ERROR: Azure Blob storage account name $AZBLOB_STORAGE_ACCOUNT does not exist. Check the value of AZBLOB_STORAGE_ACCOUNT in config/demo.cfg and try again."
    exit 1
  fi
  export AZBLOB_ACCOUNT_KEY=$(az storage account keys list --account-name $AZBLOB_STORAGE_ACCOUNT | jq -r '.[0].value')
  if [[ "$AZBLOB_ACCOUNT_KEY" == "" ]]; then
    echo "ERROR: Cannot get the key for Azure Blob storage account name $AZBLOB_STORAGE_ACCOUNT. Check the value of AZBLOB_STORAGE_ACCOUNT in config/demo.cfg, and your key, and try again."
    exit 1
  fi

  return 0
}

function ccloud::validate_credentials_s3() {
  S3_PROFILE=$1
  S3_BUCKET=$2

  if [[ -z "$S3_PROFILE" || -z "$S3_BUCKET" ]]; then
    echo "ERROR: DESTINATION_STORAGE=s3, but S3_PROFILE or S3_BUCKET is not set.  Please set these parameters in config/demo.cfg and try again."
    exit 1
  fi

  aws configure get aws_access_key_id --profile $S3_PROFILE 1>/dev/null || {
    echo "ERROR: Cannot determine aws_access_key_id from S3_PROFILE=$S3_PROFILE.  Verify your credentials and try again."
    exit 1
  }
  aws configure get aws_secret_access_key --profile $S3_PROFILE 1>/dev/null || {
    echo "ERROR: Cannot determine aws_secret_access_key from S3_PROFILE=$S3_PROFILE.  Verify your credentials and try again."
    exit 1
  }
  return 0
}

function ccloud::validate_schema_registry_up() {
  auth=$1
  sr_endpoint=$2

  curl --silent -u $auth $sr_endpoint > /dev/null || {
    echo "ERROR: Could not validate credentials to Confluent Cloud Schema Registry. Please troubleshoot"
    exit 1
  }

  echo "Validated credentials to Confluent Cloud Schema Registry at $sr_endpoint"
  return 0
}

function ccloud::get_environment_id_from_service_id() {
  SERVICE_ACCOUNT_ID=$1

  ENVIRONMENT_NAME_PREFIX=${ENVIRONMENT_NAME_PREFIX:-"pg-$SERVICE_ACCOUNT_ID"}
  local environment_id=$(confluent environment list -o json | jq -r 'map(select(.name | startswith("'"$ENVIRONMENT_NAME_PREFIX"'"))) | .[].id')

  echo $environment_id

  return 0
}

function ccloud::create_and_use_environment() {
  ENVIRONMENT_NAME=$1

  OUTPUT=$(confluent environment create $ENVIRONMENT_NAME -o json)
  (($? != 0)) && { echo "ERROR: Failed to create environment $ENVIRONMENT_NAME. Please troubleshoot and run again"; exit 1; }
  ENVIRONMENT=$(echo "$OUTPUT" | jq -r ".id")
  confluent environment use $ENVIRONMENT &>/dev/null

  echo $ENVIRONMENT

  return 0
}

function ccloud::find_cluster() {
  CLUSTER_NAME=$1
  CLUSTER_CLOUD=$2
  CLUSTER_REGION=$3

  local FOUND_CLUSTER=$(confluent kafka cluster list -o json | jq -c -r '.[] | select((.name == "'"$CLUSTER_NAME"'") and (.provider == "'"$CLUSTER_CLOUD"'") and (.region == "'"$CLUSTER_REGION"'"))')
  [[ ! -z "$FOUND_CLUSTER" ]] && {
      echo "$FOUND_CLUSTER" | jq -r .id
      return 0

    } || {
      return 1
    }
}

function ccloud::create_and_use_cluster() {
  CLUSTER_NAME=$1
  CLUSTER_CLOUD=$2
  CLUSTER_REGION=$3
  CLUSTER_TYPE=$4

  OUTPUT=$(confluent kafka cluster create "$CLUSTER_NAME" --cloud $CLUSTER_CLOUD --region $CLUSTER_REGION --type $CLUSTER_TYPE --output json 2>&1)
  (($? != 0)) && { echo "$OUTPUT"; exit 1; }
  CLUSTER=$(echo "$OUTPUT" | jq -r .id)
  confluent kafka cluster use $CLUSTER 2>/dev/null
  echo $CLUSTER

  return 0
}

function ccloud::maybe_create_and_use_cluster() {
  CLUSTER_NAME=$1
  CLUSTER_CLOUD=$2
  CLUSTER_REGION=$3
  CLUSTER_TYPE=$4
  CLUSTER_ID=$(ccloud::find_cluster $CLUSTER_NAME $CLUSTER_CLOUD $CLUSTER_REGION)
  if [ $? -eq 0 ]
  then
    confluent kafka cluster use $CLUSTER_ID
    echo $CLUSTER_ID
  else

    # VINC: added
    if [[ ! -z "$CLUSTER_CREDS" ]]
    then
      echo "ERROR: Could not find your $CLUSTER_CLOUD cluster $CLUSTER_NAME in region $CLUSTER_REGION"
      echo "Make sure CLUSTER_CLOUD and CLUSTER_REGION are set with values that correspond to your cluster!"
      exit 1
    else
      OUTPUT=$(ccloud::create_and_use_cluster "$CLUSTER_NAME" "$CLUSTER_CLOUD" "$CLUSTER_REGION" "$CLUSTER_TYPE")
      (($? != 0)) && { echo "$OUTPUT"; exit 1; }
      echo "$OUTPUT"
    fi
  fi

  return 0
}

function ccloud::create_service_account() {
  SERVICE_NAME=$1

  CCLOUD_EMAIL=$(confluent prompt -f '%u')
  OUTPUT=$(confluent iam service-account create $SERVICE_NAME --description "SA for $EXAMPLE run by $CCLOUD_EMAIL"  -o json)
  SERVICE_ACCOUNT_ID=$(echo "$OUTPUT" | jq -r ".id")

  echo $SERVICE_ACCOUNT_ID

  return 0
}

function ccloud:get_service_account_from_current_cluster_name() {
  SERVICE_ACCOUNT_ID=$(confluent kafka cluster describe -o json | jq -r '.name' | awk -F'-' '{print $3 "-" $4;}')

  echo $SERVICE_ACCOUNT_ID

  return 0
}

function ccloud::enable_schema_registry() {
  SCHEMA_REGISTRY_CLOUD=$1
  SCHEMA_REGISTRY_GEO=$2

  OUTPUT=$(confluent schema-registry cluster enable --cloud $SCHEMA_REGISTRY_CLOUD --geo $SCHEMA_REGISTRY_GEO -o json)
  SCHEMA_REGISTRY=$(echo "$OUTPUT" | jq -r ".id")

  echo $SCHEMA_REGISTRY

  return 0
}

function ccloud::find_credentials_resource() {
  SERVICE_ACCOUNT_ID=$1
  RESOURCE=$2
  local FOUND_CRED=$(confluent api-key list -o json | jq -c -r 'map(select((.resource_id == "'"$RESOURCE"'") and (.owner_resource_id == "'"$SERVICE_ACCOUNT_ID"'")))')
  local FOUND_COUNT=$(echo "$FOUND_CRED" | jq 'length')
  [[ $FOUND_COUNT -ne 0 ]] && {
      echo "$FOUND_CRED" | jq -r '.[0].api_key'
      return 0

    } || {
      return 1
    }
}
function ccloud::create_credentials_resource() {
  SERVICE_ACCOUNT_ID=$1
  RESOURCE=$2

  OUTPUT=$(confluent api-key create --service-account $SERVICE_ACCOUNT_ID --resource $RESOURCE -o json)
  API_KEY_SA=$(echo "$OUTPUT" | jq -r ".api_key")
  API_SECRET_SA=$(echo "$OUTPUT" | jq -r ".api_secret")
  echo "${API_KEY_SA}:${API_SECRET_SA}"

  # vinc
  sleep 30
  return 0
}
# The return from this function will be a colon ':' delimited
#   list, if the api-key is created the second element of the
#   list will be the secret.  If the api-key is being reused
#   the second element of the list will be empty
function ccloud::maybe_create_credentials_resource() {
  SERVICE_ACCOUNT_ID=$1
  RESOURCE=$2

  local KEY=$(ccloud::find_credentials_resource $SERVICE_ACCOUNT_ID $RESOURCE)
  [[ -z $KEY ]] && {
    ccloud::create_credentials_resource $SERVICE_ACCOUNT_ID $RESOURCE
  } || {
    echo "$KEY:"; # the secret cannot be retrieved from a found key, caller needs to handle this
    return 0
  }
}

function ccloud::find_ksqldb_app() {
  KSQLDB_NAME=$1
  CLUSTER=$2

  local FOUND_APP=$(confluent ksql cluster list -o json | jq -c -r 'map(select((.name == "'"$KSQLDB_NAME"'") and (.kafka == "'"$CLUSTER"'")))')
  local FOUND_COUNT=$(echo "$FOUND_APP" | jq 'length')
  [[ $FOUND_COUNT -ne 0 ]] && {
      echo "$FOUND_APP" | jq -r '.[].id'
      return 0

    } || {
      return 1
    }
}

function ccloud::create_ksqldb_app() {
  KSQLDB_NAME=$1
  CLUSTER=$2
  # colon deliminated credentials (APIKEY:APISECRET)
  local ksqlDB_kafka_creds=$3
  local kafka_api_key=$(echo $ksqlDB_kafka_creds | cut -d':' -f1)
  local kafka_api_secret=$(echo $ksqlDB_kafka_creds | cut -d':' -f2)

  KSQLDB=$(confluent ksql cluster create --cluster $CLUSTER --api-key "$kafka_api_key" --api-secret "$kafka_api_secret" --csu 1 -o json "$KSQLDB_NAME" | jq -r ".id")
  echo $KSQLDB

  return 0
}
function ccloud::maybe_create_ksqldb_app() {
  KSQLDB_NAME=$1
  CLUSTER=$2
  # colon deliminated credentials (APIKEY:APISECRET)
  local ksqlDB_kafka_creds=$3

  APP_ID=$(ccloud::find_ksqldb_app $KSQLDB_NAME $CLUSTER)
  if [ $? -eq 0 ]
  then
    echo $APP_ID
  else
    ccloud::create_ksqldb_app "$KSQLDB_NAME" "$CLUSTER" "$ksqlDB_kafka_creds"
  fi

  return 0
}

function ccloud::create_acls_all_resources_full_access() {
  SERVICE_ACCOUNT_ID=$1
  # Setting default QUIET=false to surface potential errors
  QUIET="${QUIET:-false}"
  [[ $QUIET == "true" ]] &&
    local REDIRECT_TO="/dev/null" ||
    local REDIRECT_TO="/dev/tty"

  confluent kafka acl create --allow --service-account $SERVICE_ACCOUNT_ID --operations CREATE,DELETE,WRITE,READ,DESCRIBE,DESCRIBE_CONFIGS --topic '*' &>"$REDIRECT_TO"

  confluent kafka acl create --allow --service-account $SERVICE_ACCOUNT_ID --operations READ,WRITE,CREATE,DESCRIBE --consumer-group '*' &>"$REDIRECT_TO"

  confluent kafka acl create --allow --service-account $SERVICE_ACCOUNT_ID --operations DESCRIBE,WRITE --transactional-id '*' &>"$REDIRECT_TO"

  confluent kafka acl create --allow --service-account $SERVICE_ACCOUNT_ID --operations IDEMPOTENT-WRITE,DESCRIBE --cluster-scope &>"$REDIRECT_TO"

  return 0
}

function ccloud::delete_acls_ccloud_stack() {
  SERVICE_ACCOUNT_ID=$1
  # Setting default QUIET=false to surface potential errors
  QUIET="${QUIET:-false}"
  [[ $QUIET == "true" ]] &&
    local REDIRECT_TO="/dev/null" ||
    local REDIRECT_TO="/dev/tty"

  echo "Deleting ACLs for service account ID $SERVICE_ACCOUNT_ID"

  confluent kafka acl delete --allow --service-account $SERVICE_ACCOUNT_ID --operations CREATE,DELETE,WRITE,READ,DESCRIBE,DESCRIBE_CONFIGS --topic '*' &>"$REDIRECT_TO"

  confluent kafka acl delete --allow --service-account $SERVICE_ACCOUNT_ID --operations READ,WRITE,CREATE,DESCRIBE --consumer-group '*' &>"$REDIRECT_TO"

  confluent kafka acl delete --allow --service-account $SERVICE_ACCOUNT_ID --operations DESCRIBE,WRITE --transactional-id '*' &>"$REDIRECT_TO"

  confluent kafka acl delete --allow --service-account $SERVICE_ACCOUNT_ID --operations IDEMPOTENT-WRITE,DESCRIBE --cluster-scope &>"$REDIRECT_TO"

  return 0
}

function ccloud::validate_ccloud_config() {
  [ -z "$1" ] && {
    echo "ccloud::validate_ccloud_config expects one parameter (configuration file with Confluent Cloud connection information)"
    exit 1
  }

  local cfg_file="$1"
  local bootstrap=$(grep "bootstrap\.servers" "$cfg_file" | cut -d'=' -f2-)
  [ -z "$bootstrap" ] && {
    echo "ERROR: Cannot read the 'bootstrap.servers' key-value pair from $cfg_file."
    exit 1;
  }
  return 0;
}

function ccloud::validate_ksqldb_up() {
  [ -z "$1" ] && {
    echo "ccloud::validate_ksqldb_up expects one parameter (ksqldb endpoint)"
    exit 1
  }

  [ $# -gt 1 ] && echo "WARN: ccloud::validate_ksqldb_up function expects one parameter"

  local ksqldb_endpoint=$1

  ccloud::validate_logged_in_cli || exit 1

  local ksqldb_meta=$(confluent ksql cluster list -o json | jq -r 'map(select(.endpoint == "'"$ksqldb_endpoint"'")) | .[]')

  local ksqldb_appid=$(echo "$ksqldb_meta" | jq -r '.id')
  if [[ "$ksqldb_appid" == "" ]]; then
    echo "ERROR: Confluent Cloud ksqlDB endpoint $ksqldb_endpoint is not found. Provision a ksqlDB cluster via the Confluent Cloud UI and add the configuration parameter ksql.endpoint and ksql.basic.auth.user.info into your Confluent Cloud configuration file at $ccloud_config_file and try again."
    exit 1
  fi

  local ksqldb_status=$(echo "$ksqldb_meta" | jq -r '.status')
  if [[ $ksqldb_status != "UP" ]]; then
    echo "ERROR: Confluent Cloud ksqlDB endpoint $ksqldb_endpoint with id $ksqlDBAppId is not in UP state. Troubleshoot and try again."
    exit 1
  fi

  return 0
}

function ccloud::validate_azure_account() {
  AZBLOB_STORAGE_ACCOUNT=$1

  if [[ "$AZBLOB_STORAGE_ACCOUNT" == "default" ]]; then
    echo "ERROR: Azure Blob storage account name cannot be 'default'. Verify the value of the storage account name (did you create one?) in config/demo.cfg, as specified by the parameter AZBLOB_STORAGE_ACCOUNT, and try again."
    exit 1
  fi

  exists=$(az storage account check-name --name $AZBLOB_STORAGE_ACCOUNT | jq -r .reason)
  if [[ "$exists" != "AlreadyExists" ]]; then
    echo "ERROR: Azure Blob storage account name $AZBLOB_STORAGE_ACCOUNT does not exist. Check the value of STORAGE_PROFILE in config/demo.cfg and try again."
    exit 1
  fi
  export AZBLOB_ACCOUNT_KEY=$(az storage account keys list --account-name $AZBLOB_STORAGE_ACCOUNT | jq -r '.[0].value')
  if [[ "$AZBLOB_ACCOUNT_KEY" == "" ]]; then
    echo "ERROR: Cannot get the key for Azure Blob storage account name $AZBLOB_STORAGE_ACCOUNT. Check the value of STORAGE_PROFILE in config/demo.cfg, and your key, and try again."
    exit 1
  fi

  return 0
}

function ccloud::validate_credentials_ksqldb() {
  ksqldb_endpoint=$1
  ccloud_config_file=$2
  credentials=$3

  response=$(curl ${ksqldb_endpoint}/info \
             -H "Content-Type: application/vnd.ksql.v1+json; charset=utf-8" \
             --silent \
             -u $credentials)
  if [[ "$response" =~ "Unauthorized" ]]; then
    echo "ERROR: Authorization failed to the ksqlDB cluster. Check your ksqlDB credentials set in the configuration parameter ksql.basic.auth.user.info in your Confluent Cloud configuration file at $ccloud_config_file and try again."
    exit 1
  fi

  echo "Validated credentials to Confluent Cloud ksqlDB at $ksqldb_endpoint"
  return 0
}

function ccloud::create_connector() {
  file=$1

  echo -e "\nCreating connector from $file\n"

  # About the Confluent CLI command 'confluent connect cluster create':
  # - Typical usage of this CLI would be 'confluent connect cluster create --config-file <filename>'
  # - However, in this example, the connector's configuration file contains parameters that need to be first substituted
  #   so the CLI command includes eval and heredoc.
  # - The '-vvv' is added for verbose output
  confluent connect cluster create -vvv --config <(eval "cat <<EOF
$(<$file)
EOF
")
  if [[ $? != 0 ]]; then
    echo "ERROR: Exit status was not 0 while creating connector from $file.  Please troubleshoot and try again"
    exit 1
  fi

  return 0
}

function ccloud::validate_connector_up() {
  confluent connect cluster list -o json | jq -e 'map(select(.name == "'"$1"'" and .status == "RUNNING")) | .[]' > /dev/null 2>&1
}

function ccloud::wait_for_connector_up() {
  filename=$1
  maxWait=$2

  connectorName=$(cat $filename | jq -r .name)
  echo "Waiting up to $maxWait seconds for connector $filename ($connectorName) to be RUNNING"
  ccloud::retry $maxWait ccloud::validate_connector_up $connectorName || exit 1
  echo "Connector $filename ($connectorName) is RUNNING"

  return 0
}

function ccloud::validate_ccloud_ksqldb_endpoint_ready() {
  KSQLDB_ENDPOINT=$1

  STATUS=$(confluent ksql cluster list -o json | jq -r 'map(select(.endpoint == "'"$KSQLDB_ENDPOINT"'")) | .[].status' | grep UP)
  if [[ "$STATUS" == "" ]]; then
    return 1
  fi

  return 0
}

function ccloud::validate_ccloud_cluster_ready() {
  confluent kafka topic list &>/dev/null
  return $?
}

function ccloud::validate_topic_exists() {
  topic=$1

  confluent kafka topic describe $topic &>/dev/null
  return $?
}

function ccloud::validate_subject_exists() {
  subject=$1
  sr_url=$2
  sr_credentials=$3

  curl --silent -u $sr_credentials $sr_url/subjects/$subject/versions/latest | jq -r ".subject" | grep $subject > /dev/null
  return $?
}

function ccloud::login_cli(){
  URL=$1
  EMAIL=$2
  PASSWORD=$3

  ccloud::validate_expect_installed

  echo -e "\n# Login"
  OUTPUT=$(
  expect <<END
    log_user 1
    spawn confluent login --url $URL --prompt -vvvv
    expect "Email: "
    send "$EMAIL\r";
    expect "Password: "
    send "$PASSWORD\r";
    expect "Logged in as "
    set result $expect_out(buffer)
END
  )
  echo "$OUTPUT"
  if [[ ! "$OUTPUT" =~ "Logged in as" ]]; then
    echo "Failed to log into your cluster. Please check all parameters and run again."
  fi

  return 0
}

function ccloud::get_service_account() {

  [ -z "$1" ] && {
    echo "ccloud::get_service_account expects one parameter (API Key)"
    exit 1
  }

  [ $# -gt 1 ] && echo "WARN: ccloud::get_service_account function expects one parameter, received two"

  local key="$1"

  serviceAccount=$(confluent api-key list -o json | jq -r -c 'map(select((.api_key == "'"$key"'"))) | .[].owner_resource_id')
  if [[ "$serviceAccount" == "" ]]; then
    echo "ERROR: Could not associate key $key to a service account. Verify your credentials, ensure the API key has a set resource type, and try again."
    exit 1
  fi
  if ! [[ "$serviceAccount" =~ ^sa-[a-z0-9]+$ ]]; then
    echo "ERROR: $serviceAccount value is not a valid value for a service account. Verify your credentials, ensure the API key has a set resource type, and try again."
    exit 1
  fi

  echo "$serviceAccount"

  return 0
}

function ccloud::create_acls_connector() {
  serviceAccount=$1

  confluent kafka acl create --allow --service-account $serviceAccount --operations DESCRIBE --cluster-scope
  confluent kafka acl create --allow --service-account $serviceAccount --operations CREATE,WRITE --prefix --topic dlq-lcc
  confluent kafka acl create --allow --service-account $serviceAccount --operations READ --prefix --consumer-group connect-lcc

  return 0
}

function ccloud::create_acls_control_center() {
  serviceAccount=$1

  echo "Confluent Control Center: creating _confluent-command and ACLs for service account $serviceAccount"
  confluent kafka topic create _confluent-command --partitions 1

  confluent kafka acl create --allow --service-account $serviceAccount --operations WRITE,READ,CREATE --topic _confluent --prefix

  confluent kafka acl create --allow --service-account $serviceAccount --operations READ,WRITE,CREATE --consumer-group _confluent --prefix

  return 0
}

function ccloud::create_acls_replicator() {
  serviceAccount=$1
  topic=$2

  confluent kafka acl create --allow --service-account $serviceAccount --operations CREATE,WRITE,READ,DESCRIBE,DESCRIBE_CONFIGS,ALTER-CONFIGS,DESCRIBE --topic $topic

  return 0
}

function ccloud::create_acls_connect_topics() {
  serviceAccount=$1

  echo "Connect: creating topics and ACLs for service account $serviceAccount"

  TOPIC=connect-demo-configs
  confluent kafka topic create $TOPIC --partitions 1 --config "cleanup.policy=compact"
  confluent kafka acl create --allow --service-account $serviceAccount --operations WRITE,READ --topic $TOPIC --prefix

  TOPIC=connect-demo-offsets
  confluent kafka topic create $TOPIC --partitions 6 --config "cleanup.policy=compact"
  confluent kafka acl create --allow --service-account $serviceAccount --operations WRITE,READ --topic $TOPIC --prefix

  TOPIC=connect-demo-statuses

  confluent kafka topic create $TOPIC --partitions 3 --config "cleanup.policy=compact"
  confluent kafka acl create --allow --service-account $serviceAccount --operations WRITE,READ  --topic $TOPIC --prefix

  for TOPIC in _confluent-monitoring _confluent-command ; do
    confluent kafka topic create $TOPIC --partitions 1 &>/dev/null
    confluent kafka acl create --allow --service-account $serviceAccount --operations WRITE,READ  --topic $TOPIC --prefix
  done

  confluent kafka acl create --allow --service-account $serviceAccount --operations READ --consumer-group connect-cloud

  echo "Connectors: creating topics and ACLs for service account $serviceAccount"
  confluent kafka acl create --allow --service-account $serviceAccount --operations READ --consumer-group connect-replicator
  confluent kafka acl create --allow --service-account $serviceAccount --operations DESCRIBE --cluster-scope

  return 0
}

function ccloud::validate_ccloud_stack_up() {
  CLOUD_KEY=$1
  CCLOUD_CONFIG_FILE=$2
  enable_ksqldb=$3

  if [ -z "$enable_ksqldb" ]; then
    enable_ksqldb=true
  fi

  ccloud::validate_environment_set || exit 1
  ccloud::set_kafka_cluster_use_from_api_key "$CLOUD_KEY" || exit 1
  ccloud::validate_schema_registry_up "$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" "$SCHEMA_REGISTRY_URL" || exit 1
  if $enable_ksqldb ; then
    ccloud::validate_ksqldb_up "$KSQLDB_ENDPOINT" || exit 1
    ccloud::validate_credentials_ksqldb "$KSQLDB_ENDPOINT" "$CCLOUD_CONFIG_FILE" "$KSQLDB_BASIC_AUTH_USER_INFO" || exit 1
  fi
}

function ccloud::validate_environment_set() {
  confluent environment list | grep '*' &>/dev/null || {
    echo "ERROR: could not determine if environment is set. Run 'confluent environment list' and set 'confluent environment use' and try again"
    exit 1
  }

  return 0
}

function ccloud::set_kafka_cluster_use_from_api_key() {
  [ -z "$1" ] && {
    echo "ccloud::set_kafka_cluster_use_from_api_key expects one parameter (API Key)"
    exit 1
  }

  [ $# -gt 1 ] && echo "WARN: ccloud::set_kafka_cluster_use_from_api_key function expects one parameter, received two"

  local key="$1"

  local kafkaCluster=$(confluent api-key list -o json | jq -r -c 'map(select((.api_key == "'"$key"'" and .resource_type == "kafka"))) | .[].resource_id')
  if [[ "$kafkaCluster" == "" ]]; then
    echo "ERROR: Could not associate key $key to a Confluent Cloud Kafka cluster. Verify your credentials, ensure the API key has a set resource type, and try again."
    exit 1
  fi

  confluent kafka cluster use $kafkaCluster
  local endpoint=$(confluent kafka cluster describe $kafkaCluster -o json | jq -r ".endpoint" | cut -c 12-)
  echo -e "\nAssociated key $key to Confluent Cloud Kafka cluster $kafkaCluster at $endpoint"

  return 0
}

# Deprecated 10/28/2020, use ccloud::set_kafka_cluster_use_from_api_key
function ccloud::set_kafka_cluster_use() {
  echo "WARN: set_kafka_cluster_use is deprecated, use ccloud::set_kafka_cluster_use_from_api_key"
  ccloud::set_kafka_cluster_use_from_api_key "$@"
}

#
# ccloud-stack documentation:
# https://docs.confluent.io/platform/current/tutorials/examples/ccloud/docs/ccloud-stack.html
#
function ccloud::create_ccloud_stack() {
  #ccloud::validate_version_cli $CLI_MIN_VERSION || exit 1
  QUIET="${QUIET:-false}"
  REPLICATION_FACTOR=${REPLICATION_FACTOR:-3}
  enable_ksqldb=${1:-false}
  EXAMPLE=${EXAMPLE:-ccloud-stack-function}
  CHECK_CREDIT_CARD="${CHECK_CREDIT_CARD:-false}"

  # Check if credit card is on file, which is required for cluster creation
  if $CHECK_CREDIT_CARD && [[ $(confluent admin payment describe) =~ "not found" ]]; then
    echo "ERROR: No credit card on file. Add a payment method and try again."
    echo "If you are using a cloud provider's Marketplace, see documentation for a workaround: https://docs.confluent.io/platform/current/tutorials/examples/ccloud/docs/ccloud-stack.html#running-with-marketplace"
    exit 1
  fi

  # VINC: added
  if [[ -z "$CLUSTER_CREDS" ]]
  then
    if [[ -z "$SERVICE_ACCOUNT_ID" ]]; then
      # Service Account is not received so it will be created
      local RANDOM_NUM=$((1 + RANDOM % 1000000))
      SERVICE_NAME=${SERVICE_NAME:-"pg-app-$RANDOM_NUM"}
      SERVICE_ACCOUNT_ID=$(ccloud::create_service_account $SERVICE_NAME)
    fi

    if [[ "$SERVICE_NAME" == "" ]]; then
      echo "ERROR: SERVICE_NAME is not defined. If you are providing the SERVICE_ACCOUNT_ID to this function please also provide the SERVICE_NAME"
      exit 1
    fi

    echo "Creating Confluent Cloud stack for service account $SERVICE_NAME, ID: $SERVICE_ACCOUNT_ID."
  fi

  if [[ -z "$ENVIRONMENT" ]];

  then
    # Environment is not received so it will be created
    ENVIRONMENT_NAME=${ENVIRONMENT_NAME:-"pg-$SERVICE_ACCOUNT_ID-$EXAMPLE"}
    ENVIRONMENT=$(ccloud::create_and_use_environment $ENVIRONMENT_NAME)
    (($? != 0)) && { echo "$ENVIRONMENT"; exit 1; }
  else
    confluent environment use $ENVIRONMENT || exit 1
  fi

  CLUSTER_NAME=${CLUSTER_NAME:-"pg-cluster-$SERVICE_ACCOUNT_ID"}
  CLUSTER_CLOUD="${CLUSTER_CLOUD:-aws}"
  CLUSTER_REGION="${CLUSTER_REGION:-us-west-2}"
  CLUSTER_TYPE="${CLUSTER_TYPE:-basic}"
  CLUSTER=$(ccloud::maybe_create_and_use_cluster "$CLUSTER_NAME" $CLUSTER_CLOUD $CLUSTER_REGION $CLUSTER_TYPE)
  (($? != 0)) && { echo "$CLUSTER"; exit 1; }
  if [[ "$CLUSTER" == "" ]] ; then
    echo "Kafka cluster id is empty"
    echo "ERROR: Could not create cluster. Please troubleshoot."
    exit 1
  fi

  BOOTSTRAP_SERVERS=$(confluent kafka cluster describe $CLUSTER -o json | jq -r ".endpoint" | cut -c 12-)
  NEED_ACLS=0
  # VINC: added
  if [[ -z "$CLUSTER_CREDS" ]]
  then
    CLUSTER_CREDS=$(ccloud::maybe_create_credentials_resource $SERVICE_ACCOUNT_ID $CLUSTER)
    NEED_ACLS=1
  fi

  MAX_WAIT=720
  echo ""
  echo "Waiting up to $MAX_WAIT seconds for Confluent Cloud cluster to be ready"
  ccloud::retry $MAX_WAIT ccloud::validate_ccloud_cluster_ready || exit 1

  # VINC: added
  if [[ $NEED_ACLS -eq 1 ]]
  then
    # Estimating another 80s wait still sometimes required
    WARMUP_TIME=${WARMUP_TIME:-80}
    echo "Sleeping an additional ${WARMUP_TIME} seconds to ensure propagation of all metadata"
    sleep $WARMUP_TIME

    ccloud::create_acls_all_resources_full_access $SERVICE_ACCOUNT_ID
  fi

  SCHEMA_REGISTRY_GEO="${SCHEMA_REGISTRY_GEO:-us}"
  SCHEMA_REGISTRY=$(ccloud::enable_schema_registry $CLUSTER_CLOUD $SCHEMA_REGISTRY_GEO)
  SCHEMA_REGISTRY_ENDPOINT=$(confluent schema-registry cluster describe -o json | jq -r ".endpoint_url")
  # VINC: added
  if [[ -z "$SCHEMA_REGISTRY_CREDS" ]]
  then
    if [[ -z "$SERVICE_ACCOUNT_ID" ]]; then
      # Service Account is not received so it will be created
      local RANDOM_NUM=$((1 + RANDOM % 1000000))
      SERVICE_NAME=${SERVICE_NAME:-"pg-app-$RANDOM_NUM"}
      SERVICE_ACCOUNT_ID=$(ccloud::create_service_account $SERVICE_NAME)
    fi
    SCHEMA_REGISTRY_CREDS=$(ccloud::maybe_create_credentials_resource $SERVICE_ACCOUNT_ID $SCHEMA_REGISTRY)
  fi

  # VINC
  set +e
  #log "Adding ResourceOwner RBAC role for all subjects"
  confluent iam rbac role-binding create --principal User:$SERVICE_ACCOUNT_ID --role ResourceOwner --environment $ENVIRONMENT --schema-registry-cluster $SCHEMA_REGISTRY --resource Subject:* 2>/dev/null

  if $enable_ksqldb ; then
    KSQLDB_NAME=${KSQLDB_NAME:-"demo-ksqldb-$SERVICE_ACCOUNT_ID"}
    KSQLDB=$(ccloud::maybe_create_ksqldb_app "$KSQLDB_NAME" $CLUSTER "$CLUSTER_CREDS")
    KSQLDB_ENDPOINT=$(confluent ksql cluster describe $KSQLDB -o json | jq -r ".endpoint")
    KSQLDB_CREDS=$(ccloud::maybe_create_credentials_resource $SERVICE_ACCOUNT_ID $KSQLDB)
    confluent ksql cluster configure-acls $KSQLDB
  fi

  CLOUD_API_KEY=`echo $CLUSTER_CREDS | awk -F: '{print $1}'`
  CLOUD_API_SECRET=`echo $CLUSTER_CREDS | awk -F: '{print $2}'`
  # FIX THIS: added by me
  confluent api-key store "$CLOUD_API_KEY" "$CLOUD_API_SECRET" --resource ${CLUSTER} --force
  confluent api-key use $CLOUD_API_KEY --resource ${CLUSTER}

  if [[ -z "$SKIP_CONFIG_FILE_WRITE" ]]; then
    if [[ -z "$CCLOUD_CONFIG_FILE" ]]; then
      CCLOUD_CONFIG_FILE="/tmp/tmp.config"
    fi

    cat <<EOF > $CCLOUD_CONFIG_FILE
# --------------------------------------
# Confluent Cloud connection information
# --------------------------------------
# ENVIRONMENT ID: ${ENVIRONMENT}
# SERVICE ACCOUNT ID: ${SERVICE_ACCOUNT_ID}
# KAFKA CLUSTER ID: ${CLUSTER}
# SCHEMA REGISTRY CLUSTER ID: ${SCHEMA_REGISTRY}
EOF
    if $enable_ksqldb ; then
      cat <<EOF >> $CCLOUD_CONFIG_FILE
# KSQLDB APP ID: ${KSQLDB}
EOF
    fi
    cat <<EOF >> $CCLOUD_CONFIG_FILE
# --------------------------------------
sasl.mechanism=PLAIN
security.protocol=SASL_SSL
bootstrap.servers=${BOOTSTRAP_SERVERS}
sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='${CLOUD_API_KEY}' password='${CLOUD_API_SECRET}';
basic.auth.credentials.source=USER_INFO
schema.registry.url=${SCHEMA_REGISTRY_ENDPOINT}
basic.auth.user.info=`echo $SCHEMA_REGISTRY_CREDS | awk -F: '{print $1}'`:`echo $SCHEMA_REGISTRY_CREDS | awk -F: '{print $2}'`
replication.factor=${REPLICATION_FACTOR}
EOF
    if $enable_ksqldb ; then
      cat <<EOF >> $CCLOUD_CONFIG_FILE
ksql.endpoint=${KSQLDB_ENDPOINT}
ksql.basic.auth.user.info=`echo $KSQLDB_CREDS | awk -F: '{print $1}'`:`echo $KSQLDB_CREDS | awk -F: '{print $2}'`
EOF
    fi

    echo
    echo "Client configuration file saved to: $CCLOUD_CONFIG_FILE"
  fi

  return 0
}

function ccloud::destroy_ccloud_stack() {
  if [ $# -eq 0 ];then
    echo "ccloud::destroy_ccloud_stack requires a single parameter, the service account id."
    exit 1
  fi

  SERVICE_ACCOUNT_ID=$1
  ENVIRONMENT=${ENVIRONMENT:-$(ccloud::get_environment_id_from_service_id $SERVICE_ACCOUNT_ID)}

  confluent environment use $ENVIRONMENT || exit 1

  PRESERVE_ENVIRONMENT="${PRESERVE_ENVIRONMENT:-false}"

  ENVIRONMENT_NAME_PREFIX=${ENVIRONMENT_NAME_PREFIX:-"pg-$SERVICE_ACCOUNT_ID"}
  CLUSTER_NAME=${CLUSTER_NAME:-"pg-cluster-$SERVICE_ACCOUNT_ID"}
  CCLOUD_CONFIG_FILE=${CCLOUD_CONFIG_FILE:-"/tmp/tmp.config"}
  KSQLDB_NAME=${KSQLDB_NAME:-"demo-ksqldb-$SERVICE_ACCOUNT_ID"}

  # Setting default QUIET=false to surface potential errors
  QUIET="${QUIET:-false}"
  [[ $QUIET == "true" ]] &&

    local REDIRECT_TO="/dev/null" ||
    local REDIRECT_TO="/dev/tty"

  echo "Destroying Confluent Cloud stack associated to service account id $SERVICE_ACCOUNT_ID"

  # Delete associated ACLs
  ccloud::delete_acls_ccloud_stack $SERVICE_ACCOUNT_ID

  ksqldb_id_found=$(confluent ksql cluster list -o json | jq -r 'map(select(.name == "'"$KSQLDB_NAME"'")) | .[].id')
  if [[ $ksqldb_id_found != "" ]]; then
    echo "Deleting KSQLDB: $KSQLDB_NAME : $ksqldb_id_found"
    confluent ksql cluster delete $ksqldb_id_found &> "$REDIRECT_TO"
  fi

  # Delete connectors associated to this Kafka cluster, otherwise cluster deletion fails
  local cluster_id=$(confluent kafka cluster list -o json | jq -r 'map(select(.name == "'"$CLUSTER_NAME"'")) | .[].id')
  confluent connect cluster list --cluster $cluster_id -o json | jq -r '.[].id' | xargs -I{} confluent connect cluster delete {} --force

  echo "Deleting CLUSTER: $CLUSTER_NAME : $cluster_id"
  confluent kafka cluster delete $cluster_id &> "$REDIRECT_TO"

  # Delete API keys associated to the service account
  confluent api-key list --service-account $SERVICE_ACCOUNT_ID -o json | jq -r '.[].api_key' | xargs -I{} confluent api-key delete {} --force

  # Delete service account
  confluent iam service-account delete $SERVICE_ACCOUNT_ID --force &>"$REDIRECT_TO"

  if [[ $PRESERVE_ENVIRONMENT == "false" ]]; then
    local environment_id=$(confluent environment list -o json | jq -r 'map(select(.name | startswith("'"$ENVIRONMENT_NAME_PREFIX"'"))) | .[].id')
    if [[ "$environment_id" == "" ]]; then
      echo "WARNING: Could not find environment with name that starts with $ENVIRONMENT_NAME_PREFIX (did you create this ccloud-stack reusing an existing environment?)"
    else
      echo "Deleting ENVIRONMENT: prefix $ENVIRONMENT_NAME_PREFIX : $environment_id"
      confluent environment delete $environment_id &> "$REDIRECT_TO"
    fi
  fi

  rm -f $CCLOUD_CONFIG_FILE

  return 0
}

# Overview:
#
# This code reads a local Confluent Cloud configuration file
# and writes delta configuration files into ./delta_configs for
# Confluent Platform components and clients connecting to Confluent Cloud.
#
# Confluent Platform Components:
# - Confluent Schema Registry
# - KSQL Data Generator
# - ksqlDB server
# - Confluent Replicator (executable)
# - Confluent Control Center
# - Confluent Metrics Reporter
# - Confluent REST Proxy
# - Kafka Connect
# - Kafka connector
# - Kafka command line tools
#
# Kafka Clients:
# - Java (Producer/Consumer)
# - Java (Streams)
# - librdkafka config
# - Python
# - .NET
# - Go
# - Node.js (https://github.com/Blizzard/node-rdkafka)
# - C++
#
# Documentation for using this script:
#
#   https://docs.confluent.io/current/cloud/connect/auto-generate-configs.html
#
# Arguments:
#
#   CCLOUD_CONFIG_FILE, defaults to ~/.ccloud/config
#
# Example CCLOUD_CONFIG_FILE at ~/.ccloud/config
#
#   $ cat $HOME/.ccloud/config
#
#   bootstrap.servers=<BROKER ENDPOINT>
#   security.protocol=SASL_SSL
#   sasl.mechanism=PLAIN
#   sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='<API KEY>' password='<API SECRET>';
#
# If you are using Confluent Cloud Schema Registry, add the following configuration parameters
#
#   basic.auth.credentials.source=USER_INFO
#   basic.auth.user.info=<SR API KEY>:<SR API SECRET>
#   schema.registry.url=https://<SR ENDPOINT>
#
# If you are using Confluent Cloud ksqlDB, add the following configuration parameters
#
#   ksql.endpoint=<ksqlDB ENDPOINT>
#   ksql.basic.auth.user.info=<ksqlDB API KEY>:<ksqlDB API SECRET>
#
function ccloud::generate_configs() {
  CCLOUD_CONFIG_FILE=$1
  if [[ -z "$CCLOUD_CONFIG_FILE" ]]; then
    CCLOUD_CONFIG_FILE=~/.ccloud/config
  fi
  if [[ ! -f "$CCLOUD_CONFIG_FILE" ]]; then
    echo "File $CCLOUD_CONFIG_FILE is not found.  Please create this properties file to connect to your Confluent Cloud cluster and then try again"
    echo "See https://docs.confluent.io/current/cloud/connect/auto-generate-configs.html for more information"
    return 1
  fi

  echo -e "\nGenerating component configurations from $CCLOUD_CONFIG_FILE"
  echo -e "\n(If you want to run any of these components to talk to Confluent Cloud, these are the configurations to add to the properties file for each component)"

  # Set permissions
  PERM=600
  if ls --version 2>/dev/null | grep -q 'coreutils' ; then
    # GNU binutils
    PERM=$(stat -c "%a" $CCLOUD_CONFIG_FILE)
  else
    # BSD
    PERM=$(stat -f "%OLp" $CCLOUD_CONFIG_FILE)
  fi

  # Make destination
  DEST="/tmp/delta_configs"
  mkdir -p $DEST

  # Glean parameters from the Confluent Cloud configuration file

  # Kafka cluster
  BOOTSTRAP_SERVERS=$( grep "^bootstrap.server" $CCLOUD_CONFIG_FILE | awk -F'=' '{print $2;}' )
  BOOTSTRAP_SERVERS=${BOOTSTRAP_SERVERS/\\/}
  SASL_JAAS_CONFIG=$( grep "^sasl.jaas.config" $CCLOUD_CONFIG_FILE | cut -d'=' -f2- )
  SASL_JAAS_CONFIG_PROPERTY_FORMAT=${SASL_JAAS_CONFIG/username\\=/username=}
  SASL_JAAS_CONFIG_PROPERTY_FORMAT=${SASL_JAAS_CONFIG_PROPERTY_FORMAT/password\\=/password=}
  CLOUD_KEY=$( echo $SASL_JAAS_CONFIG | awk '{print $3}' | awk -F"'" '$0=$2' )
  CLOUD_SECRET=$( echo $SASL_JAAS_CONFIG | awk '{print $4}' | awk -F"'" '$0=$2' )

  # Schema Registry
  BASIC_AUTH_CREDENTIALS_SOURCE=$( grep "^basic.auth.credentials.source" $CCLOUD_CONFIG_FILE | awk -F'=' '{print $2;}' )
  SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO=$( grep "^basic.auth.user.info" $CCLOUD_CONFIG_FILE | awk -F'=' '{print $2;}' )
  SCHEMA_REGISTRY_URL=$( grep "^schema.registry.url" $CCLOUD_CONFIG_FILE | awk -F'=' '{print $2;}' )

  # ksqlDB
  KSQLDB_ENDPOINT=$( grep "^ksql.endpoint" $CCLOUD_CONFIG_FILE | awk -F'=' '{print $2;}' )
  KSQLDB_BASIC_AUTH_USER_INFO=$( grep "^ksql.basic.auth.user.info" $CCLOUD_CONFIG_FILE | awk -F'=' '{print $2;}' )

  # Build configuration file with Confluent Cloud connection parameters and
  # Confluent Monitoring Interceptors for Streams Monitoring in Confluent Control Center
  INTERCEPTORS_CONFIG_FILE=$DEST/interceptors-ccloud.config
  rm -f $INTERCEPTORS_CONFIG_FILE
  echo "# Configuration derived from $CCLOUD_CONFIG_FILE" > $INTERCEPTORS_CONFIG_FILE
  while read -r line
  do
    # Skip lines that are commented out
    if [[ ! -z $line && ${line:0:1} == '#' ]]; then
      continue
    fi
    # Skip lines that contain just whitespace
    if [[ -z "${line// }" ]]; then
      continue
    fi
    if [[ ${line:0:9} == 'bootstrap' ]]; then
      line=${line/\\/}
    fi
    echo $line >> $INTERCEPTORS_CONFIG_FILE
  done < "$CCLOUD_CONFIG_FILE"
  echo -e "\n# Confluent Monitoring Interceptor specific configuration" >> $INTERCEPTORS_CONFIG_FILE
  while read -r line
  do
    # Skip lines that are commented out
    if [[ ! -z $line && ${line:0:1} == '#' ]]; then
      continue
    fi
    # Skip lines that contain just whitespace
    if [[ -z "${line// }" ]]; then
      continue
    fi
    if [[ ${line:0:9} == 'bootstrap' ]]; then
      line=${line/\\/}
    fi
    if [[ ${line:0:4} == 'sasl' ||
          ${line:0:3} == 'ssl' ||
          ${line:0:8} == 'security' ||
          ${line:0:9} == 'bootstrap' ]]; then
      echo "confluent.monitoring.interceptor.$line" >> $INTERCEPTORS_CONFIG_FILE
    fi
  done < "$CCLOUD_CONFIG_FILE"
  chmod $PERM $INTERCEPTORS_CONFIG_FILE

  echo -e "\nConfluent Platform Components:"

  # Confluent Schema Registry instance (local) for Confluent Cloud
  SR_CONFIG_DELTA=$DEST/schema-registry-ccloud.delta
  echo "$SR_CONFIG_DELTA"
  rm -f $SR_CONFIG_DELTA
  while read -r line
  do
    if [[ ! -z $line && ${line:0:1} != '#' ]]; then
      if [[ ${line:0:29} != 'basic.auth.credentials.source' && ${line:0:15} != 'schema.registry' ]]; then
        echo "kafkastore.$line" >> $SR_CONFIG_DELTA
      fi
    fi
  done < "$CCLOUD_CONFIG_FILE"
  chmod $PERM $SR_CONFIG_DELTA

  # Confluent Replicator (executable) for Confluent Cloud
  REPLICATOR_PRODUCER_DELTA=$DEST/replicator-to-ccloud-producer.delta
  echo "$REPLICATOR_PRODUCER_DELTA"
  rm -f $REPLICATOR_PRODUCER_DELTA
  cp $INTERCEPTORS_CONFIG_FILE $REPLICATOR_PRODUCER_DELTA
  echo -e "\n# Confluent Replicator (executable) specific configuration" >> $REPLICATOR_PRODUCER_DELTA
  echo "interceptor.classes=io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor" >> $REPLICATOR_PRODUCER_DELTA
  REPLICATOR_SASL_JAAS_CONFIG=$SASL_JAAS_CONFIG
  REPLICATOR_SASL_JAAS_CONFIG=${REPLICATOR_SASL_JAAS_CONFIG//\\=/=}
  REPLICATOR_SASL_JAAS_CONFIG=${REPLICATOR_SASL_JAAS_CONFIG//\"/\\\"}
  chmod $PERM $REPLICATOR_PRODUCER_DELTA

  # ksqlDB Server runs locally and connects to Confluent Cloud
  KSQLDB_SERVER_DELTA=$DEST/ksqldb-server-ccloud.delta
  echo "$KSQLDB_SERVER_DELTA"
  rm -f $KSQLDB_SERVER_DELTA
  cp $INTERCEPTORS_CONFIG_FILE $KSQLDB_SERVER_DELTA
  echo -e "\n# ksqlDB Server specific configuration" >> $KSQLDB_SERVER_DELTA
  echo "producer.interceptor.classes=io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor" >> $KSQLDB_SERVER_DELTA
  echo "consumer.interceptor.classes=io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor" >> $KSQLDB_SERVER_DELTA
  echo "ksql.streams.producer.retries=2147483647" >> $KSQLDB_SERVER_DELTA
  echo "ksql.streams.producer.confluent.batch.expiry.ms=9223372036854775807" >> $KSQLDB_SERVER_DELTA
  echo "ksql.streams.producer.request.timeout.ms=300000" >> $KSQLDB_SERVER_DELTA
  echo "ksql.streams.producer.max.block.ms=9223372036854775807" >> $KSQLDB_SERVER_DELTA
  echo "ksql.streams.replication.factor=3" >> $KSQLDB_SERVER_DELTA
  echo "ksql.internal.topic.replicas=3" >> $KSQLDB_SERVER_DELTA
  echo "ksql.sink.replicas=3" >> $KSQLDB_SERVER_DELTA
  echo -e "\n# Confluent Schema Registry configuration for ksqlDB Server" >> $KSQLDB_SERVER_DELTA
  while read -r line
  do
    if [[ ${line:0:29} == 'basic.auth.credentials.source' ]]; then
      echo "ksql.schema.registry.$line" >> $KSQLDB_SERVER_DELTA
    elif [[ ${line:0:15} == 'schema.registry' ]]; then
      echo "ksql.$line" >> $KSQLDB_SERVER_DELTA
    fi
  done < $CCLOUD_CONFIG_FILE
  chmod $PERM $KSQLDB_SERVER_DELTA

  # KSQL DataGen for Confluent Cloud
  KSQL_DATAGEN_DELTA=$DEST/ksql-datagen.delta
  echo "$KSQL_DATAGEN_DELTA"
  rm -f $KSQL_DATAGEN_DELTA
  cp $INTERCEPTORS_CONFIG_FILE $KSQL_DATAGEN_DELTA
  echo -e "\n# KSQL DataGen specific configuration" >> $KSQL_DATAGEN_DELTA
  echo "interceptor.classes=io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor" >> $KSQL_DATAGEN_DELTA
  echo -e "\n# Confluent Schema Registry configuration for KSQL DataGen" >> $KSQL_DATAGEN_DELTA
  while read -r line
  do
    if [[ ${line:0:29} == 'basic.auth.credentials.source' ]]; then
      echo "ksql.schema.registry.$line" >> $KSQL_DATAGEN_DELTA
    elif [[ ${line:0:15} == 'schema.registry' ]]; then
      echo "ksql.$line" >> $KSQL_DATAGEN_DELTA
    fi
  done < $CCLOUD_CONFIG_FILE
  chmod $PERM $KSQL_DATAGEN_DELTA

  # Confluent Control Center runs locally, monitors Confluent Cloud, and uses Confluent Cloud cluster as the backstore
  C3_DELTA=$DEST/control-center-ccloud.delta
  echo "$C3_DELTA"
  rm -f $C3_DELTA
  echo -e "\n# Confluent Control Center specific configuration" >> $C3_DELTA
  while read -r line
    do
    if [[ ! -z $line && ${line:0:1} != '#' ]]; then
      if [[ ${line:0:9} == 'bootstrap' ]]; then
        line=${line/\\/}
        echo "$line" >> $C3_DELTA
      fi
      if [[ ${line:0:4} == 'sasl' || ${line:0:3} == 'ssl' || ${line:0:8} == 'security' ]]; then
        echo "confluent.controlcenter.streams.$line" >> $C3_DELTA
      fi
    fi
  done < "$CCLOUD_CONFIG_FILE"
  # max.message.bytes is enforced to 8MB in Confluent Cloud
  echo "confluent.metrics.topic.max.message.bytes=8388608" >> $C3_DELTA
  echo -e "\n# Confluent Schema Registry configuration for Confluent Control Center" >> $C3_DELTA
  while read -r line
  do
    if [[ ${line:0:29} == 'basic.auth.credentials.source' ]]; then
      echo "confluent.controlcenter.schema.registry.$line" >> $C3_DELTA
    elif [[ ${line:0:15} == 'schema.registry' ]]; then
      echo "confluent.controlcenter.$line" >> $C3_DELTA
    fi
  done < $CCLOUD_CONFIG_FILE
  chmod $PERM $C3_DELTA

  # Confluent Metrics Reporter to Confluent Cloud
  METRICS_REPORTER_DELTA=$DEST/metrics-reporter.delta
  echo "$METRICS_REPORTER_DELTA"
  rm -f $METRICS_REPORTER_DELTA
  echo "metric.reporters=io.confluent.metrics.reporter.ConfluentMetricsReporter" >> $METRICS_REPORTER_DELTA
  echo "confluent.metrics.reporter.topic.replicas=3" >> $METRICS_REPORTER_DELTA
  while read -r line
    do
    if [[ ! -z $line && ${line:0:1} != '#' ]]; then
      if [[ ${line:0:9} == 'bootstrap' || ${line:0:4} == 'sasl' || ${line:0:3} == 'ssl' || ${line:0:8} == 'security' ]]; then
        echo "confluent.metrics.reporter.$line" >> $METRICS_REPORTER_DELTA
      fi
    fi
  done < "$CCLOUD_CONFIG_FILE"
  chmod $PERM $METRICS_REPORTER_DELTA

  # Confluent REST Proxy to Confluent Cloud
  REST_PROXY_DELTA=$DEST/rest-proxy.delta
  echo "$REST_PROXY_DELTA"
  rm -f $REST_PROXY_DELTA
  while read -r line
    do
    if [[ ! -z $line && ${line:0:1} != '#' ]]; then
      if [[ ${line:0:9} == 'bootstrap' || ${line:0:4} == 'sasl' || ${line:0:3} == 'ssl' || ${line:0:8} == 'security' ]]; then
        echo "$line" >> $REST_PROXY_DELTA
        echo "client.$line" >> $REST_PROXY_DELTA
      fi
    fi
  done < "$CCLOUD_CONFIG_FILE"
  echo -e "\n# Confluent Schema Registry configuration for REST Proxy" >> $REST_PROXY_DELTA
  while read -r line
  do
    if [[ ${line:0:29} == 'basic.auth.credentials.source' || ${line:0:36} == 'schema.registry.basic.auth.user.info' ]]; then
      echo "client.$line" >> $REST_PROXY_DELTA
    elif [[ ${line:0:19} == 'schema.registry.url' ]]; then
      echo "$line" >> $REST_PROXY_DELTA
    fi
  done < $CCLOUD_CONFIG_FILE
  chmod $PERM $REST_PROXY_DELTA

  # Kafka Connect runs locally and connects to Confluent Cloud
  CONNECT_DELTA=$DEST/connect-ccloud.delta
  echo "$CONNECT_DELTA"
  rm -f $CONNECT_DELTA
  cat <<EOF > $CONNECT_DELTA
# Configuration for embedded admin client
replication.factor=3
config.storage.replication.factor=3
offset.storage.replication.factor=3
status.storage.replication.factor=3

EOF
  while read -r line
    do
    if [[ ! -z $line && ${line:0:1} != '#' ]]; then
      if [[ ${line:0:9} == 'bootstrap' ]]; then
        line=${line/\\/}
        echo "$line" >> $CONNECT_DELTA
      fi
      if [[ ${line:0:4} == 'sasl' || ${line:0:3} == 'ssl' || ${line:0:8} == 'security' ]]; then
        echo "$line" >> $CONNECT_DELTA
      fi
    fi
  done < "$CCLOUD_CONFIG_FILE"

  for prefix in "producer" "consumer" "producer.confluent.monitoring.interceptor" "consumer.confluent.monitoring.interceptor" ; do

  echo -e "\n# Configuration for embedded $prefix" >> $CONNECT_DELTA
  while read -r line
    do
    if [[ ! -z $line && ${line:0:1} != '#' ]]; then
      if [[ ${line:0:9} == 'bootstrap' ]]; then
        line=${line/\\/}
      fi
      if [[ ${line:0:4} == 'sasl' || ${line:0:3} == 'ssl' || ${line:0:8} == 'security' ]]; then
        echo "${prefix}.$line" >> $CONNECT_DELTA
      fi
    fi
  done < "$CCLOUD_CONFIG_FILE"

  done

  cat <<EOF >> $CONNECT_DELTA

# Confluent Schema Registry for Kafka Connect
value.converter=io.confluent.connect.avro.AvroConverter
value.converter.basic.auth.credentials.source=$BASIC_AUTH_CREDENTIALS_SOURCE
value.converter.schema.registry.basic.auth.user.info=$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO
value.converter.schema.registry.url=$SCHEMA_REGISTRY_URL
EOF
  chmod $PERM $CONNECT_DELTA

  # Kafka connector
  CONNECTOR_DELTA=$DEST/connector-ccloud.delta
  echo "$CONNECTOR_DELTA"
  rm -f $CONNECTOR_DELTA
  cat <<EOF >> $CONNECTOR_DELTA
// Confluent Schema Registry for Kafka connectors
value.converter=io.confluent.connect.avro.AvroConverter
value.converter.basic.auth.credentials.source=$BASIC_AUTH_CREDENTIALS_SOURCE
value.converter.schema.registry.basic.auth.user.info=$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO
value.converter.schema.registry.url=$SCHEMA_REGISTRY_URL
EOF
  chmod $PERM $CONNECTOR_DELTA

  # AK command line tools
  AK_TOOLS_DELTA=$DEST/ak-tools-ccloud.delta
  echo "$AK_TOOLS_DELTA"
  rm -f $AK_TOOLS_DELTA
  cp $CCLOUD_CONFIG_FILE $AK_TOOLS_DELTA
  chmod $PERM $AK_TOOLS_DELTA

  echo -e "\nKafka Clients:"

  # Java (Producer/Consumer)
  JAVA_PC_CONFIG=$DEST/java_producer_consumer.delta
  echo "$JAVA_PC_CONFIG"
  rm -f $JAVA_PC_CONFIG

  cat <<EOF >> $JAVA_PC_CONFIG
import java.util.Properties;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ConsumerConfig;
import org.apache.kafka.common.config.SaslConfigs;

Properties props = new Properties();

// Basic Confluent Cloud Connectivity
props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "$BOOTSTRAP_SERVERS");
props.put(ProducerConfig.REPLICATION_FACTOR_CONFIG, 3);
props.put(ProducerConfig.SECURITY_PROTOCOL_CONFIG, "SASL_SSL");
props.put(SaslConfigs.SASL_MECHANISM, "PLAIN");
props.put(SaslConfigs.SASL_JAAS_CONFIG, "$SASL_JAAS_CONFIG");

// Confluent Schema Registry for Java
props.put("basic.auth.credentials.source", "$BASIC_AUTH_CREDENTIALS_SOURCE");
props.put("schema.registry.basic.auth.user.info", "$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO");
props.put("schema.registry.url", "$SCHEMA_REGISTRY_URL");

// Optimize Performance for Confluent Cloud
props.put(ProducerConfig.RETRIES_CONFIG, 2147483647);
props.put("producer.confluent.batch.expiry.ms", 9223372036854775807);
props.put(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG, 300000);
props.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, 9223372036854775807);

// Required for Streams Monitoring in Confluent Control Center
props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor");
props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, confluent.monitoring.interceptor.bootstrap.servers, "$BOOTSTRAP_SERVERS");
props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + ProducerConfig.SECURITY_PROTOCOL_CONFIG, "SASL_SSL");
props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_MECHANISM, "PLAIN");
props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_JAAS_CONFIG, "$SASL_JAAS_CONFIG");
props.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG, "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor");
props.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, confluent.monitoring.interceptor.bootstrap.servers, "$BOOTSTRAP_SERVERS");
props.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + ProducerConfig.SECURITY_PROTOCOL_CONFIG, "SASL_SSL");
props.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_MECHANISM, "PLAIN");
props.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_JAAS_CONFIG, "$SASL_JAAS_CONFIG");

// .... additional configuration settings
EOF
  chmod $PERM $JAVA_PC_CONFIG

  # Java (Streams)
  JAVA_STREAMS_CONFIG=$DEST/java_streams.delta
  echo "$JAVA_STREAMS_CONFIG"
  rm -f $JAVA_STREAMS_CONFIG

  cat <<EOF >> $JAVA_STREAMS_CONFIG
import java.util.Properties;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ConsumerConfig;
import org.apache.kafka.common.config.SaslConfigs;
import org.apache.kafka.streams.StreamsConfig;

Properties props = new Properties();

// Basic Confluent Cloud Connectivity
props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "$BOOTSTRAP_SERVERS");
props.put(StreamsConfig.REPLICATION_FACTOR_CONFIG, 3);
props.put(StreamsConfig.SECURITY_PROTOCOL_CONFIG, "SASL_SSL");
props.put(SaslConfigs.SASL_MECHANISM, "PLAIN");
props.put(SaslConfigs.SASL_JAAS_CONFIG, "$SASL_JAAS_CONFIG");

// Confluent Schema Registry for Java
props.put("basic.auth.credentials.source", "$BASIC_AUTH_CREDENTIALS_SOURCE");
props.put("schema.registry.basic.auth.user.info", "$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO");
props.put("schema.registry.url", "$SCHEMA_REGISTRY_URL");

// Optimize Performance for Confluent Cloud
props.put(StreamsConfig.producerPrefix(ProducerConfig.RETRIES_CONFIG), 2147483647);
props.put("producer.confluent.batch.expiry.ms", 9223372036854775807);
props.put(StreamsConfig.producerPrefix(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG), 300000);
props.put(StreamsConfig.producerPrefix(ProducerConfig.MAX_BLOCK_MS_CONFIG), 9223372036854775807);

// Required for Streams Monitoring in Confluent Control Center
props.put(StreamsConfig.PRODUCER_PREFIX + ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor");
props.put(StreamsConfig.PRODUCER_PREFIX + ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, confluent.monitoring.interceptor.bootstrap.servers, "$BOOTSTRAP_SERVERS");
props.put(StreamsConfig.PRODUCER_PREFIX + ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + StreamsConfig.SECURITY_PROTOCOL_CONFIG, "SASL_SSL");
props.put(StreamsConfig.PRODUCER_PREFIX + ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_MECHANISM, "PLAIN");
props.put(StreamsConfig.PRODUCER_PREFIX + ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_JAAS_CONFIG, "$SASL_JAAS_CONFIG");
props.put(StreamsConfig.CONSUMER_PREFIX + ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG, "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor");
props.put(StreamsConfig.CONSUMER_PREFIX + ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, confluent.monitoring.interceptor.bootstrap.servers, "$BOOTSTRAP_SERVERS");
props.put(StreamsConfig.CONSUMER_PREFIX + ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + StreamsConfig.SECURITY_PROTOCOL_CONFIG, "SASL_SSL");
props.put(StreamsConfig.CONSUMER_PREFIX + ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_MECHANISM, "PLAIN");
props.put(StreamsConfig.CONSUMER_PREFIX + ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_JAAS_CONFIG, "$SASL_JAAS_CONFIG");

// .... additional configuration settings
EOF
  chmod $PERM $JAVA_STREAMS_CONFIG

  # librdkafka
  LIBRDKAFKA_CONFIG=$DEST/librdkafka.delta
  echo "$LIBRDKAFKA_CONFIG"
  rm -f $LIBRDKAFKA_CONFIG

  cat <<EOF >> $LIBRDKAFKA_CONFIG
bootstrap.servers="$BOOTSTRAP_SERVERS"
security.protocol=SASL_SSL
sasl.mechanisms=PLAIN
sasl.username="$CLOUD_KEY"
sasl.password="$CLOUD_SECRET"
schema.registry.url="$SCHEMA_REGISTRY_URL"
basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO"
EOF
  chmod $PERM $LIBRDKAFKA_CONFIG

  # Python
  PYTHON_CONFIG=$DEST/python.delta
  echo "$PYTHON_CONFIG"
  rm -f $PYTHON_CONFIG

  cat <<EOF >> $PYTHON_CONFIG
from confluent_kafka import Producer, Consumer, KafkaError

producer = Producer({
           'bootstrap.servers': '$BOOTSTRAP_SERVERS',
           'broker.version.fallback': '0.10.0.0',
           'api.version.fallback.ms': 0,
           'sasl.mechanisms': 'PLAIN',
           'security.protocol': 'SASL_SSL',
           'sasl.username': '$CLOUD_KEY',
           'sasl.password': '$CLOUD_SECRET',
           // 'ssl.ca.location': '/usr/local/etc/openssl/cert.pem', // varies by distro
           'plugin.library.paths': 'monitoring-interceptor',
           // .... additional configuration settings
})

consumer = Consumer({
           'bootstrap.servers': '$BOOTSTRAP_SERVERS',
           'broker.version.fallback': '0.10.0.0',
           'api.version.fallback.ms': 0,
           'sasl.mechanisms': 'PLAIN',
           'security.protocol': 'SASL_SSL',
           'sasl.username': '$CLOUD_KEY',
           'sasl.password': '$CLOUD_SECRET',
           // 'ssl.ca.location': '/usr/local/etc/openssl/cert.pem', // varies by distro
           'plugin.library.paths': 'monitoring-interceptor',
           // .... additional configuration settings
})
EOF
  chmod $PERM $PYTHON_CONFIG

  # .NET

  DOTNET_CONFIG=$DEST/dotnet.delta
  echo "$DOTNET_CONFIG"
  rm -f $DOTNET_CONFIG

  cat <<EOF >> $DOTNET_CONFIG
using Confluent.Kafka;

var producerConfig = new Dictionary<string, object>
{
    { "bootstrap.servers", "$BOOTSTRAP_SERVERS" },
    { "broker.version.fallback", "0.10.0.0" },
    { "api.version.fallback.ms", 0 },
    { "sasl.mechanisms", "PLAIN" },
    { "security.protocol", "SASL_SSL" },
    { "sasl.username", "$CLOUD_KEY" },
    { "sasl.password", "$CLOUD_SECRET" },
    // { "ssl.ca.location", "/usr/local/etc/openssl/cert.pem" }, // varies by distro
    { “plugin.library.paths”, “monitoring-interceptor”},
    // .... additional configuration settings
};

var consumerConfig = new Dictionary<string, object>
{
    { "bootstrap.servers", "$BOOTSTRAP_SERVERS" },
    { "broker.version.fallback", "0.10.0.0" },
    { "api.version.fallback.ms", 0 },
    { "sasl.mechanisms", "PLAIN" },
    { "security.protocol", "SASL_SSL" },
    { "sasl.username", "$CLOUD_KEY" },
    { "sasl.password", "$CLOUD_SECRET" },
    // { "ssl.ca.location", "/usr/local/etc/openssl/cert.pem" }, // varies by distro
    { “plugin.library.paths”, “monitoring-interceptor”},
    // .... additional configuration settings
};
EOF
  chmod $PERM $DOTNET_CONFIG

  # Go
  GO_CONFIG=$DEST/go.delta
  echo "$GO_CONFIG"
  rm -f $GO_CONFIG

  cat <<EOF >> $GO_CONFIG
import (
  "github.com/confluentinc/confluent-kafka-go/kafka"

producer, err := kafka.NewProducer(&kafka.ConfigMap{
           "bootstrap.servers": "$BOOTSTRAP_SERVERS",
          "broker.version.fallback": "0.10.0.0",
          "api.version.fallback.ms": 0,
          "sasl.mechanisms": "PLAIN",
          "security.protocol": "SASL_SSL",
          "sasl.username": "$CLOUD_KEY",
          "sasl.password": "$CLOUD_SECRET",
                 // "ssl.ca.location": "/usr/local/etc/openssl/cert.pem", // varies by distro
                 "plugin.library.paths": "monitoring-interceptor",
                 // .... additional configuration settings
                 })

consumer, err := kafka.NewConsumer(&kafka.ConfigMap{
     "bootstrap.servers": "$BOOTSTRAP_SERVERS",
       "broker.version.fallback": "0.10.0.0",
       "api.version.fallback.ms": 0,
       "sasl.mechanisms": "PLAIN",
       "security.protocol": "SASL_SSL",
       "sasl.username": "$CLOUD_KEY",
       "sasl.password": "$CLOUD_SECRET",
                 // "ssl.ca.location": "/usr/local/etc/openssl/cert.pem", // varies by distro
       "session.timeout.ms": 6000,
                 "plugin.library.paths": "monitoring-interceptor",
                 // .... additional configuration settings
                 })
EOF
  chmod $PERM $GO_CONFIG

  # Node.js
  NODE_CONFIG=$DEST/node.delta
  echo "$NODE_CONFIG"
  rm -f $NODE_CONFIG

  cat <<EOF >> $NODE_CONFIG
var Kafka = require('node-rdkafka');

var producer = new Kafka.Producer({
    'metadata.broker.list': '$BOOTSTRAP_SERVERS',
    'sasl.mechanisms': 'PLAIN',
    'security.protocol': 'SASL_SSL',
    'sasl.username': '$CLOUD_KEY',
    'sasl.password': '$CLOUD_SECRET',
     // 'ssl.ca.location': '/usr/local/etc/openssl/cert.pem', // varies by distro
    'plugin.library.paths': 'monitoring-interceptor',
    // .... additional configuration settings
  });

var consumer = Kafka.KafkaConsumer.createReadStream({
    'metadata.broker.list': '$BOOTSTRAP_SERVERS',
    'sasl.mechanisms': 'PLAIN',
    'security.protocol': 'SASL_SSL',
    'sasl.username': '$CLOUD_KEY',
    'sasl.password': '$CLOUD_SECRET',
     // 'ssl.ca.location': '/usr/local/etc/openssl/cert.pem', // varies by distro
    'plugin.library.paths': 'monitoring-interceptor',
    // .... additional configuration settings
  }, {}, {
    topics: '<topic name>',
    waitInterval: 0,
    objectMode: false
});
EOF
  chmod $PERM $NODE_CONFIG

  # C++
  CPP_CONFIG=$DEST/cpp.delta
  echo "$CPP_CONFIG"
  rm -f $CPP_CONFIG

  cat <<EOF >> $CPP_CONFIG
#include <librdkafka/rdkafkacpp.h>

RdKafka::Conf *producerConfig = RdKafka::Conf::create(RdKafka::Conf::CONF_GLOBAL);
if (producerConfig->set("metadata.broker.list", "$BOOTSTRAP_SERVERS", errstr) != RdKafka::Conf::CONF_OK ||
    producerConfig->set("sasl.mechanisms", "PLAIN", errstr) != RdKafka::Conf::CONF_OK ||
    producerConfig->set("security.protocol", "SASL_SSL", errstr) != RdKafka::Conf::CONF_OK ||
    producerConfig->set("sasl.username", "$CLOUD_KEY", errstr) != RdKafka::Conf::CONF_OK ||
    producerConfig->set("sasl.password", "$CLOUD_SECRET", errstr) != RdKafka::Conf::CONF_OK ||
    // producerConfig->set("ssl.ca.location", "/usr/local/etc/openssl/cert.pem", errstr) != RdKafka::Conf::CONF_OK || // varies by distro
    producerConfig->set("plugin.library.paths", "monitoring-interceptor", errstr) != RdKafka::Conf::CONF_OK ||
    // .... additional configuration settings
   ) {
        std::cerr << "Configuration failed: " << errstr << std::endl;
        exit(1);
}
RdKafka::Producer *producer = RdKafka::Producer::create(producerConfig, errstr);

RdKafka::Conf *consumerConfig = RdKafka::Conf::create(RdKafka::Conf::CONF_GLOBAL);
if (consumerConfig->set("metadata.broker.list", "$BOOTSTRAP_SERVERS", errstr) != RdKafka::Conf::CONF_OK ||
    consumerConfig->set("sasl.mechanisms", "PLAIN", errstr) != RdKafka::Conf::CONF_OK ||
    consumerConfig->set("security.protocol", "SASL_SSL", errstr) != RdKafka::Conf::CONF_OK ||
    consumerConfig->set("sasl.username", "$CLOUD_KEY", errstr) != RdKafka::Conf::CONF_OK ||
    consumerConfig->set("sasl.password", "$CLOUD_SECRET", errstr) != RdKafka::Conf::CONF_OK ||
    // consumerConfig->set("ssl.ca.location", "/usr/local/etc/openssl/cert.pem", errstr) != RdKafka::Conf::CONF_OK || // varies by distro
    consumerConfig->set("plugin.library.paths", "monitoring-interceptor", errstr) != RdKafka::Conf::CONF_OK ||
    // .... additional configuration settings
   ) {
        std::cerr << "Configuration failed: " << errstr << std::endl;
        exit(1);
}
RdKafka::Consumer *consumer = RdKafka::Consumer::create(consumerConfig, errstr);
EOF
  chmod $PERM $CPP_CONFIG

  # ENV
  ENV_CONFIG=$DEST/env.delta
  echo "$ENV_CONFIG"
  rm -f $ENV_CONFIG

  cat <<EOF >> $ENV_CONFIG
export BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS"
export SASL_JAAS_CONFIG="$SASL_JAAS_CONFIG"
export SASL_JAAS_CONFIG_PROPERTY_FORMAT="$SASL_JAAS_CONFIG_PROPERTY_FORMAT"
export REPLICATOR_SASL_JAAS_CONFIG="$REPLICATOR_SASL_JAAS_CONFIG"
export BASIC_AUTH_CREDENTIALS_SOURCE="$BASIC_AUTH_CREDENTIALS_SOURCE"
export SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO"
export SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL"
export CLOUD_KEY="$CLOUD_KEY"
export CLOUD_SECRET="$CLOUD_SECRET"
export KSQLDB_ENDPOINT="$KSQLDB_ENDPOINT"
export KSQLDB_BASIC_AUTH_USER_INFO="$KSQLDB_BASIC_AUTH_USER_INFO"
EOF
  chmod $PERM $ENV_CONFIG

  return 0
}

# These are some duplicate functions from

#  helper.sh to decouple the script files.  In

#  the future we can work to remove this

#  duplication if necessary
function ccloud::retry() {
    local -r -i max_wait="$1"; shift
    local -r cmd="$@"

    local -i sleep_interval=5
    local -i curr_wait=0

    until $cmd
    do
        if (( curr_wait >= max_wait ))
        then
            echo "ERROR: Failed after $curr_wait seconds. Please troubleshoot and run again."
            return 1
        else
            printf "."
            curr_wait=$((curr_wait+sleep_interval))
            sleep $sleep_interval
        fi
    done
    printf "\n"
}
function ccloud::version_gt() {

  test "$(printf '%s\n' "$@" | sort -V | head -n 1)" != "$1";
}


function check_arm64_support() {

  DIR="$1"
  DOCKER_COMPOSE_FILE="$2"
  set +e
  if [ `uname -m` = "arm64" ]
  then
    test=$(echo "$DOCKER_COMPOSE_FILE" | awk -F"/" '{ print $(NF-2)"/"$(NF-1) }')
    grep "${test}" ${DIR}/../../scripts/arm64-support-none.txt > /dev/null
    if [ $? = 0 ]
    then
        logerror "🖥️ This example is not working with ARM64 !"
        log "Do you want to start test anyway ?"
        check_if_continue
    fi

    grep "${test}" ${DIR}/../../scripts/arm64-support-with-emulation.txt > /dev/null
    if [ $? = 0 ]
    then
        logwarn "🖥️ This example is working with ARM64 but requires emulation."
    fi

    log "🖥️ This example should work natively with ARM64."
  fi
  set -e
}

function playground() {
  if [[ $(type -f playground 2>&1) =~ "not found" ]]
  then
    ../../scripts/cli/playground "$@"
  else
    $(which playground) "$@"
  fi
}

# src/lib/validations/validate_dir_exists.sh
validate_dir_exists() {
  [[ -d "$1" ]] || echo "must be an existing directory"
}

# src/lib/validations/validate_editor_exists.sh
validate_editor_exists() {
  local cmd="$1"
  if [[ $(type $cmd 2>&1) =~ "not found" ]]
  then
    echo "this script requires $cmd. Please install $cmd and run again."
  fi
}

# src/lib/validations/validate_file_exists.sh
validate_file_exists() {
  [[ -f "$1" ]] || echo "must be an existing file"
}

# src/lib/validations/validate_file_exists_with_trick.sh
validate_file_exists_with_trick() {
  file="$1"

  real_file=$file
  if [[ $file == *"@"* ]]
  then
    real_file=$(echo "$file" | cut -d "@" -f 2)
  fi

  [[ -f "$real_file" ]] || echo "$real_file must be an existing file"
}

# src/lib/validations/validate_integer.sh
validate_integer() {
  [[ "$1" =~ ^[0-9]+$ ]] || echo "must be an integer"
}

# src/lib/validations/validate_minimal_cp_version.sh
validate_minimal_cp_version() {
  version="$1"
  if ! version_gt $version "4.9.99"
  then
      echo "CP version (--tag) must be > 5.0.0"
  fi
}

# src/lib/validations/validate_not_empty.sh
validate_not_empty() {
  [[ -z "$1" ]] && echo "must not be empty"
}

# :command.command_functions
# :command.function
playground_get_connector_list_command() {
  # src/get_connector_list_command.sh
  get_connector_list
}

# :command.function
playground_get_kafka_region_list_command() {
  # src/get_kafka_region_list_command.sh
  confluent kafka region list
}

# :command.function
playground_get_topic_list_command() {
  # src/get_topic_list_command.sh
  skip_connect_internal_topics="${args[--skip-connect-internal-topics]}"

  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi

  if [[ "$environment" == "environment" ]]
  then
    confluent kafka topic list | grep -v "^_" | grep -v "Name" | grep -v "\-\-\-"
  else
    # trick to be faster
    docker exec broker ls /var/lib/kafka/data > /dev/null 2>&1
    if [ $? -eq 0 ]
    then
      if [[ -n "$skip_connect_internal_topics" ]]
      then
        docker exec broker ls /var/lib/kafka/data | grep -v "checkpoint" | grep -v "meta.properties" | grep -v "connect-" | grep -v "^_" | sed 's/[^-]*$//' | sed 's/.$//' | sort | uniq
      else
        docker exec broker ls /var/lib/kafka/data | grep -v "checkpoint" | grep -v "meta.properties" | grep -v "^_" | sed 's/[^-]*$//' | sed 's/.$//' | sort | uniq
      fi
    fi
  fi
}

# :command.function
playground_get_examples_list_with_fzf_command() {
  # src/get_examples_list_with_fzf_command.sh
  without_repro="${args[--without-repro]}"
  sink_only="${args[--sink-only]}"
  ccloud_only="${args[--ccloud-only]}"
  cur="${args[cur]}"

  if [[ -n "$without_repro" ]] && [[ -n "$sink_only" ]]
  then
      get_examples_list_with_fzf_without_repro_sink_only "$cur"
      return
  fi

  if [[ -n "$without_repro" ]]
  then
      get_examples_list_with_fzf_without_repro "$cur"
      return
  fi

  if [[ -n "$ccloud_only" ]]
  then
      get_examples_list_with_fzf_ccloud_only "$cur"
      return
  fi

  get_examples_list_with_fzf "$cur"
}

# :command.function
playground_get_zip_or_jar_with_fzf_command() {
  # src/get_zip_or_jar_with_fzf_command.sh
  cur="${args[cur]}"
  type="${args[--type]}"

  get_zip_or_jar_with_fzf "$cur" "$type"
}

# :command.function
playground_get_any_file_with_fzf_command() {
  # src/get_any_file_with_fzf_command.sh
  cur="${args[cur]}"

  get_any_files_with_fzf "$cur"
}

# :command.function
playground_bashly_reload_command() {
  # src/bashly_reload_command.sh
  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  root_folder=$(echo ${dir1%/*})

  cd $root_folder/scripts/cli
  bashly generate
  rm -f $root_folder/scripts/cli/completions.bash
  bashly add completions_script
  cd - > /dev/null
}

# :command.function
playground_run_command() {
  # src/run_command.sh
  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

  root_folder=${DIR_CLI}/../..

  test_file="${args[--file]}"
  open="${args[--open]}"
  tag="${args[--tag]}"
  connector_tag="${args[--connector-tag]}"
  connector_zip="${args[--connector-zip]}"
  connector_jar="${args[--connector-jar]}"
  connector_jar="${args[--connector-jar]}"
  enable_ksqldb="${args[--enable-ksqldb]}"
  enable_c3="${args[--enable-control-center]}"
  enable_conduktor="${args[--enable-conduktor]}"
  enable_multiple_brokers="${args[--enable-multiple-brokers]}"
  enable_multiple_connect_workers="${args[--enable-multiple-connect-workers]}"
  enable_jmx_grafana="${args[--enable-jmx-grafana]}"
  enable_kcat="${args[--enable-kcat]}"
  enable_sr_maven_plugin_app="${args[--enable-sr-maven-plugin-app]}"
  enable_sql_datagen="${args[--enable-sql-datagen]}"

  if [ "$test_file" = "" ]
  then
    logerror "ERROR: test_file is not provided as argument!"
    exit 1
  fi

  if [[ $test_file == *"@"* ]]
  then
    test_file=$(echo "$test_file" | cut -d "@" -f 2)
  fi

  if [ ! -f "$test_file" ]
  then
    logerror "ERROR: test_file $test_file does not exist!"
    exit 1
  fi

  if [[ "$test_file" != *".sh" ]]
  then
    logerror "ERROR: test_file $test_file is not a .sh file!"
    exit 1
  fi

  test_file_directory="$(dirname "${test_file}")"
  filename=$(basename -- "$test_file")
  extension="${filename##*.}"

  base1="${test_file_directory##*/}" # connect-cdc-oracle12-source
  dir1="${test_file_directory%/*}" #connect
  dir2="${dir1##*/}/$base1" # connect/connect-cdc-oracle12-source
  final_dir=$(echo $dir2 | tr '/' '-') # connect-connect-cdc-oracle12-source

  flag_list=""
  if [[ -n "$tag" ]]
  then
    flag_list="--tag=$tag"
    export TAG=$tag
  fi

  if [[ -n "$connector_tag" ]]
  then
    flag_list="$flag_list --connector-tag=$connector_tag"
    export CONNECTOR_TAG=$connector_tag
  fi

  if [[ -n "$connector_zip" ]]
  then
    if [[ $connector_zip == *"@"* ]]
    then
      connector_zip=$(echo "$connector_zip" | cut -d "@" -f 2)
    fi
    flag_list="$flag_list --connector-zip=$connector_zip"
    export CONNECTOR_ZIP=$connector_zip
  fi

  if [[ -n "$connector_jar" ]]
  then
    if [[ $connector_jar == *"@"* ]]
    then
      connector_jar=$(echo "$connector_jar" | cut -d "@" -f 2)
    fi
    flag_list="$flag_list --connector-jar=$connector_jar"
    export CONNECTOR_JAR=$connector_jar
  fi

  if [[ -n "$enable_ksqldb" ]]
  then
    flag_list="$flag_list --enable-ksqldb"
    export ENABLE_KSQLDB=true
  fi

  if [[ -n "$enable_c3" ]]
  then
    flag_list="$flag_list --enable-control-center"
    export ENABLE_CONTROL_CENTER=true
  fi

  if [[ -n "$enable_conduktor" ]]
  then
    flag_list="$flag_list --enable-conduktor"
    export ENABLE_CONDUKTOR=true
  fi

  if [[ -n "$enable_multiple_brokers" ]]
  then
    flag_list="$flag_list --enable-multiple-broker"
    export ENABLE_KAFKA_NODES=true
  fi

  if [[ -n "$enable_multiple_connect_workers" ]]
  then
    flag_list="$flag_list --enable-multiple-connect-workers"
    export ENABLE_CONNECT_NODES=true
  fi

  if [[ -n "$enable_jmx_grafana" ]]
  then
    flag_list="$flag_list --enable-jmx-grafana"
    export ENABLE_JMX_GRAFANA=true
  fi

  if [[ -n "$enable_kcat" ]]
  then
    flag_list="$flag_list --enable-kcat"
    export ENABLE_KCAT=true
  fi

  if [[ -n "$enable_sr_maven_plugin_app" ]]
  then
    flag_list="$flag_list --enable-sr-maven-plugin-app"
    export ENABLE_SR_MAVEN_PLUGIN_NODE=true
  fi

  if [[ -n "$enable_sql_datagen" ]]
  then
    flag_list="$flag_list --enable-sql-datagen"
    export SQL_DATAGEN=true
  fi

  if [[ -n "$open" ]]
  then
    if config_has_key "editor"
    then
      editor=$(config_get "editor")
      log "📖 Opening ${test_file} using configured editor $editor"
      $editor ${test_file}
      check_if_continue
    else
      if [[ $(type code 2>&1) =~ "not found" ]]
      then
        logerror "Could not determine an editor to use as default code is not found - you can change editor by updating config.ini"
        exit 1
      else
        log "📖 Opening ${test_file} with code (default) - you can change editor by updating config.ini"
        code ${test_file}
        check_if_continue
      fi
    fi
  fi

  if [ "$flag_list" != "" ]
  then
    log "🚀 Running example with flags"
    log "⛳ Flags used are $flag_list"
  else
    log "🚀 Running example without any flags"
  fi
  set +e
  playground container kill-all
  set -e
  echo "playground run -f $test_file $flag_list ${other_args[*]}" > /tmp/playground-run
  log "####################################################"
  log "🚀 Executing $filename in dir $test_file_directory"
  log "####################################################"
  SECONDS=0
  cd $test_file_directory
  trap 'rm /tmp/playground-run-command-used;echo "";sleep 3;set +e;playground connector status;playground connector versions' EXIT
  touch /tmp/playground-run-command-used
  bash $filename ${other_args[*]}
  ret=$?
  ELAPSED="took: $((($SECONDS / 60) % 60))min $(($SECONDS % 60))sec"
  let ELAPSED_TOTAL+=$SECONDS
  if [ $ret -eq 0 ]
  then
      log "####################################################"
      log "✅ RESULT: SUCCESS for $filename ($ELAPSED - $CUMULATED)"
      log "####################################################"
  else
      logerror "####################################################"
      logerror "🔥 RESULT: FAILURE for $filename ($ELAPSED - $CUMULATED)"
      logerror "####################################################"

      display_docker_container_error_log
  fi
}

# :command.function
playground_re_run_command() {
  # src/re_run_command.sh
  if [ ! -f /tmp/playground-run ]
  then
    logerror "File containing re-run command /tmp/playground-run does not exist!"
    logerror "Make sure to use <playground run> command !"
    exit 1
  fi

  tag="${args[--tag]}"
  connector_tag="${args[--connector-tag]}"
  connector_zip="${args[--connector-zip]}"
  connector_jar="${args[--connector-jar]}"
  connector_jar="${args[--connector-jar]}"
  enable_ksqldb="${args[--enable-ksqldb]}"
  enable_c3="${args[--enable-control-center]}"
  enable_conduktor="${args[--enable-conduktor]}"
  enable_multiple_brokers="${args[--enable-multiple-brokers]}"
  enable_multiple_connect_workers="${args[--enable-multiple-connect-workers]}"
  enable_jmx_grafana="${args[--enable-jmx-grafana]}"
  enable_kcat="${args[--enable-kcat]}"
  enable_sr_maven_plugin_app="${args[--enable-sr-maven-plugin-app]}"
  enable_sql_datagen="${args[--enable-sql-datagen]}"

  flag_list=""
  if [[ -n "$tag" ]]
  then
    flag_list="--tag=$tag"
  fi

  if [[ -n "$connector_tag" ]]
  then
    flag_list="$flag_list --connector-tag=$connector_tag"
  fi

  if [[ -n "$connector_zip" ]]
  then
    if [[ $connector_zip == *"@"* ]]
    then
      connector_zip=$(echo "$connector_zip" | cut -d "@" -f 2)
    fi
    flag_list="$flag_list --connector-zip=$connector_zip"
  fi

  if [[ -n "$connector_jar" ]]
  then
    if [[ $connector_jar == *"@"* ]]
    then
      connector_jar=$(echo "$connector_jar" | cut -d "@" -f 2)
    fi
    flag_list="$flag_list --connector-jar=$connector_jar"
  fi

  if [[ -n "$enable_ksqldb" ]]
  then
    flag_list="$flag_list --enable-ksqldb"
  fi

  if [[ -n "$enable_c3" ]]
  then
    flag_list="$flag_list --enable-control-center"
  fi

  if [[ -n "$enable_conduktor" ]]
  then
    flag_list="$flag_list --enable-conduktor"
  fi

  if [[ -n "$enable_multiple_brokers" ]]
  then
    flag_list="$flag_list --enable-multiple-broker"
  fi

  if [[ -n "$enable_multiple_connect_workers" ]]
  then
    flag_list="$flag_list --enable-multiple-connect-workers"
  fi

  if [[ -n "$enable_jmx_grafana" ]]
  then
    flag_list="$flag_list --enable-jmx-grafana"
  fi

  if [[ -n "$enable_kcat" ]]
  then
    flag_list="$flag_list --enable-kcat"
  fi

  if [[ -n "$enable_sr_maven_plugin_app" ]]
  then
    flag_list="$flag_list --enable-sr-maven-plugin-app"
  fi

  if [[ -n "$enable_sql_datagen" ]]
  then
    flag_list="$flag_list --enable-sql-datagen"
  fi

  if [ "$flag_list" != "" ]
  then
    test_file=$(cat /tmp/playground-run | awk '{ print $4}')

    if [ ! -f $test_file ]
    then

      logerror "File $test_file retrieved from /tmp/playground-run does not exist!"
      logerror "Make sure to use <playground run> command !"
      exit 1
    fi

    log "🚀 Running example again with new flags"
    log "⛳ Flags used are $flag_list"
    playground run -f $test_file $flag_list ${other_args[*]}
  else
    log "🚀 Running example again with same flags as before"
    cat /tmp/playground-run
    bash /tmp/playground-run
  fi
}

# :command.function
playground_run_ccloud_command() {
  # src/run_ccloud_command.sh
  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

  root_folder=${DIR_CLI}/../..

  test_file="${args[--file]}"
  open="${args[--open]}"
  tag="${args[--tag]}"
  connector_tag="${args[--connector-tag]}"
  connector_zip="${args[--connector-zip]}"
  connector_jar="${args[--connector-jar]}"
  connector_jar="${args[--connector-jar]}"
  enable_c3="${args[--enable-control-center]}"
  enable_conduktor="${args[--enable-conduktor]}"
  enable_kcat="${args[--enable-kcat]}"

  cluster_cloud="${args[--cluster-cloud]}"
  cluster_region="${args[--cluster-region]}"
  cluster_environment="${args[--cluster-environment]}"
  cluster_name="${args[--cluster-name]}"
  cluster_creds="${args[--cluster-creds]}"
  cluster_schema_registry_creds="${args[--cluster-schema-registry-creds]}"

  if [ "$test_file" = "" ]
  then
    logerror "ERROR: test_file is not provided as argument!"
    exit 1
  fi

  if [[ $test_file == *"@"* ]]
  then
    test_file=$(echo "$test_file" | cut -d "@" -f 2)
  fi

  if [ ! -f "$test_file" ]
  then
    logerror "ERROR: test_file $test_file does not exist!"
    exit 1
  fi

  if [[ "$test_file" != *".sh" ]]
  then
    logerror "ERROR: test_file $test_file is not a .sh file!"
    exit 1
  fi

  test_file_directory="$(dirname "${test_file}")"
  filename=$(basename -- "$test_file")
  extension="${filename##*.}"

  base1="${test_file_directory##*/}" # connect-cdc-oracle12-source
  dir1="${test_file_directory%/*}" #connect
  dir2="${dir1##*/}/$base1" # connect/connect-cdc-oracle12-source
  final_dir=$(echo $dir2 | tr '/' '-') # connect-connect-cdc-oracle12-source
  flag_list=""
  if [[ -n "$tag" ]]
  then
    flag_list="--tag=$tag"
    export TAG=$tag
  fi

  if [[ -n "$connector_tag" ]]
  then
    flag_list="$flag_list --connector-tag=$connector_tag"
    export CONNECTOR_TAG=$connector_tag
  fi

  if [[ -n "$connector_zip" ]]
  then
    if [[ $connector_zip == *"@"* ]]
    then
      connector_zip=$(echo "$connector_zip" | cut -d "@" -f 2)
    fi
    flag_list="$flag_list --connector-zip=$connector_zip"
    export CONNECTOR_ZIP=$connector_zip
  fi

  if [[ -n "$connector_jar" ]]
  then
    if [[ $connector_jar == *"@"* ]]
    then
      connector_jar=$(echo "$connector_jar" | cut -d "@" -f 2)
    fi
    flag_list="$flag_list --connector-jar=$connector_jar"
    export CONNECTOR_JAR=$connector_jar
  fi

  if [[ -n "$enable_c3" ]]
  then
    flag_list="$flag_list --enable-control-center"
    export ENABLE_CONTROL_CENTER=true
  fi

  if [[ -n "$enable_conduktor" ]]
  then
    flag_list="$flag_list --enable-conduktor"
    export ENABLE_CONDUKTOR=true
  fi

  if [[ -n "$enable_kcat" ]]
  then
    flag_list="$flag_list --enable-kcat"
    export ENABLE_KCAT=true
  fi

  if [[ -n "$cluster_cloud" ]]
  then
    flag_list="$flag_list --cluster-cloud $cluster_cloud"
    export CLUSTER_CLOUD=$cluster_cloud
  else
    if [ -z "$CLUSTER_CLOUD" ]
    then
      export CLUSTER_CLOUD="aws"
    fi
  fi

  if [[ -n "$cluster_region" ]]
  then
    flag_list="$flag_list --cluster-region $cluster_region"
    export CLUSTER_REGION=$cluster_region
  else
    if [ -z "$CLUSTER_REGION" ]
    then
      export CLUSTER_REGION="eu-west-2"
    fi
  fi

  if [[ -n "$cluster_environment" ]]
  then
    flag_list="$flag_list --cluster-environment $cluster_environment"
    export ENVIRONMENT=$cluster_environment
  fi

  if [[ -n "$cluster_name" ]]
  then
    flag_list="$flag_list --cluster-name $cluster_name"
    export CLUSTER_NAME=$cluster_name
  fi

  if [[ -n "$cluster_creds" ]]
  then
    flag_list="$flag_list --cluster-creds $cluster_creds"
    export CLUSTER_CREDS=$cluster_creds
  fi

  if [[ -n "$cluster_schema_registry_creds" ]]
  then
    flag_list="$flag_list --cluster-schema-registry-creds $cluster_schema_registry_creds"
    export SCHEMA_REGISTRY_CREDS=$cluster_schema_registry_creds
  fi

  if [[ -n "$open" ]]
  then
    if config_has_key "editor"
    then
      editor=$(config_get "editor")
      log "📖 Opening ${test_file} using configured editor $editor"
      $editor ${test_file}
      check_if_continue
    else
      if [[ $(type code 2>&1) =~ "not found" ]]
      then
        logerror "Could not determine an editor to use as default code is not found - you can change editor by updating config.ini"
        exit 1
      else
        log "📖 Opening ${test_file} with code (default) - you can change editor by updating config.ini"
        code ${test_file}
        check_if_continue
      fi
    fi
  fi

  if [ "$flag_list" != "" ]
  then
    log "🚀⛅ Running ccloud example with flags"
    log "⛳ Flags used are $flag_list"
  else
    log "🚀⛅ Running ccloud example without any flags"
  fi
  set +e
  playground container kill-all
  set -e
  echo "playground run -f $test_file $flag_list ${other_args[*]}" > /tmp/playground-run
  log "####################################################"
  log "🚀 Executing $filename in dir $test_file_directory"
  log "####################################################"
  SECONDS=0
  cd $test_file_directory
  trap 'rm /tmp/playground-run-command-used;echo "";sleep 3;set +e;playground connector status;playground connector versions' EXIT
  touch /tmp/playground-run-command-used
  bash $filename ${other_args[*]}
  ret=$?
  ELAPSED="took: $((($SECONDS / 60) % 60))min $(($SECONDS % 60))sec"
  let ELAPSED_TOTAL+=$SECONDS
  if [ $ret -eq 0 ]
  then
      log "####################################################"
      log "✅ RESULT: SUCCESS for $filename ($ELAPSED - $CUMULATED)"
      log "####################################################"
  else
      logerror "####################################################"
      logerror "🔥 RESULT: FAILURE for $filename ($ELAPSED - $CUMULATED)"
      logerror "####################################################"

      display_docker_container_error_log
  fi
}

# :command.function
playground_open_command() {
  # src/open_command.sh
  test_file="${args[--file]}"

  if [[ -n "$test_file" ]]
  then
    if [[ $test_file == *"@"* ]]
    then
      test_file=$(echo "$test_file" | cut -d "@" -f 2)
    fi
  else
    if [ ! -f /tmp/playground-run ]
    then
      logerror "File containing run command /tmp/playground-run does not exist!"
      logerror "Make sure to use <playground run> command !"
      exit 1
    fi

    test_file=$(cat /tmp/playground-run | awk '{ print $4}')

    if [ ! -f $test_file ]
    then

      logerror "File $test_file retrieved from /tmp/playground-run does not exist!"
      logerror "Make sure to use <playground run> command !"
      exit 1
    fi
  fi

  if config_has_key "editor"
  then
    editor=$(config_get "editor")
    log "📖 Opening ${test_file} using configured editor $editor"
    $editor ${test_file}
  else
    if [[ $(type code 2>&1) =~ "not found" ]]
    then
      logerror "Could not determine an editor to use as default code is not found - you can change editor by updating config.ini"
      exit 1
    else
      log "📖 Opening ${test_file} with code (default) - you can change editor by updating config.ini"
      code ${test_file}
    fi
  fi
}

# :command.function
playground_stop_command() {
  # src/stop_command.sh
  if [ ! -f /tmp/playground-run ]
  then
    logerror "File containing run command /tmp/playground-run does not exist!"
    logerror "Make sure to use <playground run> command !"
    exit 1
  fi

  test_file=$(cat /tmp/playground-run | awk '{ print $4}')

  if [ ! -f $test_file ]
  then

    logerror "File $test_file retrieved from /tmp/playground-run does not exist!"
    logerror "Make sure to use <playground run> command !"
    exit 1
  fi
  filename=$(basename -- "$test_file")
  test_file_directory="$(dirname "${test_file}")"
  cd ${test_file_directory}

  if [ ! -f $test_file_directory/stop.sh ]
  then

    logerror "File stop.sh in directory $test_file_directory does not exist"
    exit 1
  fi

  log "🛑 Stopping example $filename in dir $test_file_directory"
  bash stop.sh
}

# :command.function
playground_bootstrap_reproduction_model_command() {
  # src/bootstrap_reproduction_model_command.sh
  IGNORE_CHECK_FOR_DOCKER_COMPOSE=true

  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  root_folder=$(echo ${dir1%/*})

  test_file="${args[--file]}"
  description="${args[--description]}"
  producer="${args[--producer]}"
  nb_producers="${args[--nb-producers]}"
  add_custom_smt="${args[--custom-smt]}"
  sink_file="${args[--pipeline]}"
  schema_file_key="${args[--producer-schema-key]}"
  schema_file_value="${args[--producer-schema-value]}"

  tag="${args[--tag]}"
  connector_tag="${args[--connector-tag]}"
  connector_zip="${args[--connector-zip]}"
  connector_jar="${args[--connector-jar]}"
  connector_jar="${args[--connector-jar]}"
  enable_ksqldb="${args[--enable-ksqldb]}"
  enable_c3="${args[--enable-control-center]}"
  enable_conduktor="${args[--enable-conduktor]}"
  enable_multiple_brokers="${args[--enable-multiple-brokers]}"
  enable_multiple_connect_workers="${args[--enable-multiple-connect-workers]}"
  enable_jmx_grafana="${args[--enable-jmx-grafana]}"
  enable_kcat="${args[--enable-kcat]}"
  enable_sr_maven_plugin_app="${args[--enable-sr-maven-plugin-app]}"
  enable_sql_datagen="${args[--enable-sql-datagen]}"

  if [[ $test_file == *"@"* ]]
  then
    test_file=$(echo "$test_file" | cut -d "@" -f 2)
  fi

  if [[ "$test_file" != *".sh" ]]
  then
    logerror "test_file $test_file is not a .sh file!"
    exit 1
  fi

  if [[ "$(dirname $test_file)" != /* ]]
  then
    logerror "do not use relative path for test file!"
    exit 1
  fi

  if [ "$description" = "" ]
  then
    logerror "description is not provided as argument!"
    exit 1
  fi

  if [ "$nb_producers" == "" ]
  then
    nb_producers=1
  fi

  if [[ -n "$schema_file_key" ]]
  then
    if [ "$producer" == "none" ]
    then
      logerror "--producer-schema-key is set but not --producer"
      exit 1
    fi

    if [[ "$producer" != *"with-key" ]]
    then
      logerror "--producer-schema-key is set but --producer is not set with <with-key>"
      exit 1
    fi
  fi

  if [[ -n "$schema_file_value" ]]
  then
    if [ "$producer" == "none" ]
    then
      logerror "--producer-schema-value is set but not --producer"
      exit 1
    fi
  fi

  test_file_directory="$(dirname "${test_file}")"
  cd ${test_file_directory}

  # determining the docker-compose file from from test_file
  docker_compose_file=$(grep "environment" "$test_file" | grep DIR | grep start.sh | cut -d "/" -f 7 | cut -d '"' -f 1 | tail -n1 | xargs)
  docker_compose_file="${test_file_directory}/${docker_compose_file}"
  description_kebab_case="${description// /-}"
  description_kebab_case=$(echo "$description_kebab_case" | tr '[:upper:]' '[:lower:]')

  if [ "${docker_compose_file}" != "" ] && [ ! -f "${docker_compose_file}" ]
  then
    docker_compose_file=""
    logwarn "📁 Could not determine docker-compose override file from $test_file !"
  fi

  topic_name="customer-$producer"
  topic_name=$(echo $topic_name | tr '-' '_')
  filename=$(basename -- "$test_file")
  extension="${filename##*.}"
  filename="${filename%.*}"

  base1="${test_file_directory##*/}" # connect-cdc-oracle12-source
  dir1="${test_file_directory%/*}" #connect
  dir2="${dir1##*/}/$base1" # connect/connect-cdc-oracle12-source
  final_dir=$(echo $dir2 | tr '/' '-') # connect-connect-cdc-oracle12-source

  if [[ -n "$sink_file" ]]
  then
    if [[ "$base1" != *source ]]
    then
      logerror "example <$base1> must be source connector example when building a pipeline !"
      exit 1
    fi
  fi

  if [ "$producer" != "none" ]
  then
    if [[ "$base1" != *sink ]]
    then
      logerror "example <$base1> must be sink connector example when using a java producer !"
      exit 1
    fi
  fi

  if [ ! -z "$OUTPUT_FOLDER" ]
  then
    output_folder="$OUTPUT_FOLDER"
    log "📂 Output folder is $output_folder (set with OUTPUT_FOLDER environment variable)"
  else
    output_folder="reproduction-models"
    log "📂 Output folder is default $output_folder (you can change it by setting OUTPUT_FOLDER environment variable)"
  fi

  repro_dir=$root_folder/$output_folder/$final_dir
  mkdir -p $repro_dir

  repro_test_file="$repro_dir/$filename-repro-$description_kebab_case.$extension"

  if [ "${docker_compose_file}" != "" ] && [ -f "${docker_compose_file}" ]
  then
    filename=$(basename -- "${docker_compose_file}")
    extension="${filename##*.}"
    filename="${filename%.*}"

    docker_compose_test_file="$repro_dir/$filename.repro-$description_kebab_case.$extension"
    log "✨ Creating file $docker_compose_test_file"
    rm -f $docker_compose_test_file
    cp ${docker_compose_file} $docker_compose_test_file

    docker_compose_test_file_name=$(basename -- "$docker_compose_test_file")
  fi

  log "✨ Creating file $repro_test_file"
  rm -f $repro_test_file
  if [ "${docker_compose_file}" != "" ]
  then
    filename=$(basename -- "${docker_compose_file}")
    sed -e "s|$filename|$docker_compose_test_file_name|g" \
      $test_file > $repro_test_file
  else
    cp $test_file $repro_test_file
  fi

  for file in README.md docker-compose*.yml keyfile.json stop.sh .gitignore sql-datagen
  do
    if [ -f $file ]
    then
      cd $repro_dir > /dev/null
      ln -sf ../../$dir2/$file .
      cd - > /dev/null
    fi
  done

  if [ "$producer" != "none" ]
  then
    tmp_dir=$(mktemp -d -t ci-XXXXXXXXXX)
    case "${producer}" in
      avro)
        echo "               \"key.converter\": \"org.apache.kafka.connect.storage.StringConverter\"," > $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.avro.AvroConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter
      ;;
      avro-with-key)
        echo "               \"key.converter\": \"io.confluent.connect.avro.AvroConverter\"," > $tmp_dir/key_converter
        echo "               \"key.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.avro.AvroConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter
      ;;
      json-schema)
        echo "               \"key.converter\": \"org.apache.kafka.connect.storage.StringConverter\"," > $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.json.JsonSchemaConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter
      ;;
      json-schema-with-key)
        echo "               \"key.converter\": \"io.confluent.connect.json.JsonSchemaConverter\"," > $tmp_dir/key_converter
        echo "               \"key.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.json.JsonSchemaConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter
      ;;
      protobuf)
        echo "               \"key.converter\": \"org.apache.kafka.connect.storage.StringConverter\"," > $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.protobuf.ProtobufConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter
      ;;
      protobuf-with-key)
        echo "               \"key.converter\": \"io.confluent.connect.protobuf.ProtobufConverter\"," > $tmp_dir/key_converter
        echo "               \"key.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.protobuf.ProtobufConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter
      ;;
      none)
      ;;
      *)
        logerror "producer name not valid ! Should be one of avro, avro-with-key, json-schema, json-schema-with-key, protobuf or protobuf-with-key"
        exit 1
      ;;
    esac
    original_topic_name=$(grep "\"topics\"" $repro_test_file | cut -d "\"" -f 4 | head -1)
    if [ "$original_topic_name" != "" ]
    then
      tmp=$(echo $original_topic_name | tr '-' '\-')
      sed -e "s|$tmp|$topic_name|g" \
          $repro_test_file > /tmp/tmp

      mv /tmp/tmp $repro_test_file
      # log "✨ Replacing topic $original_topic_name with $topic_name"
    fi

    for((i=1;i<=$nb_producers;i++)); do
      # looks like there is a maximum size for hostname in docker (container init caused: sethostname: invalid argument: unknown)
      producer_hostname=""
      producer_hostname="producer-repro-$description_kebab_case"
      producer_hostname=${producer_hostname:0:21}
      if [ $nb_producers -eq 1 ]
      then
        producer_hostname="${producer_hostname}"
      else
        producer_hostname="${producer_hostname}$i"
      fi

      rm -rf $producer_hostname
      mkdir -p $repro_dir/$producer_hostname/
      cp -Ra ${test_file_directory}/../../other/schema-format-$producer/producer/* $repro_dir/$producer_hostname/

      if [[ -n "$schema_file_key" ]]
      then
        if config_has_key "editor"
        then
          editor=$(config_get "editor")
          log "✨ Copy and paste the schema you want to use for the key, save and close the file to continue"
          if [ "$editor" = "code" ]
          then
            code --wait $tmp_dir/key_schema
          else
            $editor $tmp_dir/key_schema
          fi
        else
          if [[ $(type code 2>&1) =~ "not found" ]]
          then
            logerror "Could not determine an editor to use as default code is not found - you can change editor by updating config.ini"
            exit 1
          else
            log "✨ Copy and paste the schema you want to use for the key, save and close the file to continue"
            code --wait $tmp_dir/key_schema
          fi
        fi

        case "${producer}" in
          avro-with-key)
            original_namespace=$(cat $tmp_dir/key_schema | jq -r .namespace)
            if [ "$original_namespace" != "null" ]
            then
              sed -e "s|$original_namespace|com.github.vdesabou|g" \
                  $tmp_dir/key_schema  > /tmp/tmp

              mv /tmp/tmp $tmp_dir/key_schema
              log "✨ Replacing namespace $original_namespace with com.github.vdesabou"
            else
              # need to add namespace
              cp $tmp_dir/key_schema /tmp/tmp
              line=2
              { head -n $(($line-1)) /tmp/tmp; echo "    \"namespace\": \"com.github.vdesabou\","; tail -n +$line /tmp/tmp; } > $tmp_dir/key_schema
            fi
            # replace record name with MyKey
            jq '.name = "MyKey"' $tmp_dir/key_schema > /tmp/tmp
            mv /tmp/tmp $tmp_dir/key_schema

            cp $tmp_dir/key_schema $repro_dir/$producer_hostname/src/main/resources/schema/mykey.avsc
          ;;
          json-schema-with-key)
            # replace title name with ID
            jq '.title = "ID"' $tmp_dir/key_schema > /tmp/tmp
            mv /tmp/tmp $tmp_dir/key_schema

            cp $tmp_dir/key_schema $repro_dir/$producer_hostname/src/main/resources/schema/Id.json
          ;;
          protobuf-with-key)
            original_package=$(grep "package " $tmp_dir/key_schema | cut -d " " -f 2 | cut -d ";" -f 1 | head -1)
            if [ "$original_package" != "" ]
            then
              sed -e "s|$original_package|com.github.vdesabou|g" \
                  $tmp_dir/key_schema  > /tmp/tmp

              mv /tmp/tmp $tmp_dir/key_schema
              log "✨ Replacing package $original_package with com.github.vdesabou"
            else
              # need to add package
              cp $tmp_dir/key_schema /tmp/tmp
              line=2
              { head -n $(($line-1)) /tmp/tmp; echo "package com.github.vdesabou;"; tail -n +$line /tmp/tmp; } > $tmp_dir/key_schema
            fi

            original_java_outer_classname=$(grep "java_outer_classname" $tmp_dir/key_schema | cut -d "\"" -f 2 | cut -d "\"" -f 1 | head -1)
            if [ "$original_java_outer_classname" != "" ]
            then
              sed -e "s|$original_java_outer_classname|IdImpl|g" \
                  $tmp_dir/key_schema  > /tmp/tmp

              mv /tmp/tmp $tmp_dir/key_schema
              log "✨ Replacing java_outer_classname $original_java_outer_classname with IdImpl"
            else
              # need to add java_outer_classname
              cp $tmp_dir/key_schema /tmp/tmp
              line=3
              { head -n $(($line-1)) /tmp/tmp; echo "option java_outer_classname = \"IdImpl\";"; tail -n +$line /tmp/tmp; } > $tmp_dir/key_schema
            fi

            cp $tmp_dir/key_schema $repro_dir/$producer_hostname/src/main/resources/schema/Id.proto
          ;;

          none)
          ;;
          *)
            logerror "producer name not valid ! Should be one of avro, avro-with-key, json-schema, json-schema-with-key, protobuf or protobuf-with-key"
            exit 1
          ;;
        esac
      fi

      if [[ -n "$schema_file_value" ]]
      then
        if config_has_key "editor"
        then
          editor=$(config_get "editor")
          log "✨ Copy and paste the schema you want to use for the value, save and close the file to continue"
          if [ "$editor" = "code" ]
          then
            code --wait $tmp_dir/value_schema
          else
            $editor $tmp_dir/value_schema
          fi
        else
          if [[ $(type code 2>&1) =~ "not found" ]]
          then
            logerror "Could not determine an editor to use as default code is not found - you can change editor by updating config.ini"
            exit 1
          else
            log "✨ Copy and paste the schema you want to use for the value, save and close the file to continue"
            code --wait $tmp_dir/value_schema
          fi
        fi

        case "${producer}" in
          avro|avro-with-key)
            original_namespace=$(cat $tmp_dir/value_schema | jq -r .namespace)
            if [ "$original_namespace" != "null" ]
            then
              sed -e "s|$original_namespace|com.github.vdesabou|g" \
                  $tmp_dir/value_schema  > /tmp/tmp

              mv /tmp/tmp $tmp_dir/value_schema
              log "✨ Replacing namespace $original_namespace with com.github.vdesabou"
            else
              # need to add namespace
              cp $tmp_dir/value_schema /tmp/tmp
              line=2
              { head -n $(($line-1)) /tmp/tmp; echo "    \"namespace\": \"com.github.vdesabou\","; tail -n +$line /tmp/tmp; } > $tmp_dir/value_schema
            fi
            # replace record name with Customer
            jq '.name = "Customer"' $tmp_dir/value_schema > /tmp/tmp
            mv /tmp/tmp $tmp_dir/value_schema

            cp $tmp_dir/value_schema $repro_dir/$producer_hostname/src/main/resources/schema/customer.avsc
          ;;
          json-schema|json-schema-with-key)
            # replace title name with Customer
            jq '.title = "Customer"' $tmp_dir/value_schema > /tmp/tmp
            mv /tmp/tmp $tmp_dir/value_schema

            cp $tmp_dir/value_schema $repro_dir/$producer_hostname/src/main/resources/schema/Customer.json
          ;;
          protobuf|protobuf-with-key)
            original_package=$(grep "package " $tmp_dir/value_schema | cut -d " " -f 2 | cut -d ";" -f 1 | head -1)
            if [ "$original_package" != "" ]
            then
              sed -e "s|$original_package|com.github.vdesabou|g" \
                  $tmp_dir/value_schema  > /tmp/tmp

              mv /tmp/tmp $tmp_dir/value_schema
              log "✨ Replacing package $original_package with com.github.vdesabou"
            else
              # need to add package
              cp $tmp_dir/value_schema /tmp/tmp
              line=2
              { head -n $(($line-1)) /tmp/tmp; echo "package com.github.vdesabou;"; tail -n +$line /tmp/tmp; } > $tmp_dir/value_schema
            fi

            original_java_outer_classname=$(grep "java_outer_classname" $tmp_dir/value_schema | cut -d "\"" -f 2 | cut -d "\"" -f 1 | head -1)
            if [ "$original_java_outer_classname" != "" ]
            then
              sed -e "s|$original_java_outer_classname|CustomerImpl|g" \
                  $tmp_dir/value_schema  > /tmp/tmp

              mv /tmp/tmp $tmp_dir/value_schema
              log "✨ Replacing java_outer_classname $original_java_outer_classname with CustomerImpl"
            else
              # need to add java_outer_classname
              cp $tmp_dir/value_schema /tmp/tmp
              line=3
              { head -n $(($line-1)) /tmp/tmp; echo "option java_outer_classname = \"CustomerImpl\";"; tail -n +$line /tmp/tmp; } > $tmp_dir/value_schema
            fi

            cp $tmp_dir/value_schema $repro_dir/$producer_hostname/src/main/resources/schema/Customer.proto
          ;;

          none)
          ;;
          *)
            logerror "producer name not valid ! Should be one of avro, avro-with-key, json-schema, json-schema-with-key, protobuf or protobuf-with-key"
            exit 1
          ;;
        esac
      fi

      # update docker compose with producer container
      if [[ "$dir1" = *connect ]]
      then
        get_producer_heredoc
      fi

      if [[ "$dir1" = *ccloud ]]
      then
        get_producer_ccloud_heredoc
      fi
    done

    if [ "${docker_compose_file}" != "" ]
    then
      cp $docker_compose_test_file $tmp_dir/tmp_file
      line=$(grep -n 'services:' $docker_compose_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/producer; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $docker_compose_test_file

    else

      logwarn "As docker-compose override file could not be determined, you will need to add this manually:"
      cat $tmp_dir/producer
    fi

    for((i=1;i<=$nb_producers;i++)); do
      log "✨ Adding Java $producer producer in $repro_dir/$producer_hostname"
      producer_hostname=""
      producer_hostname="producer-repro-$description_kebab_case"
      producer_hostname=${producer_hostname:0:21}

      if [ $nb_producers -eq 1 ]
      then
        producer_hostname="${producer_hostname}"
      else
        producer_hostname="${producer_hostname}$i"
      fi

      list="$list $producer_hostname"

    done
    get_producer_build_heredoc
    # log "✨ Adding command to build jar for $producer_hostname to $repro_test_file"
    cp $repro_test_file $tmp_dir/tmp_file
    line=$(grep -n '${DIR}/../../environment' $repro_test_file | cut -d ":" -f 1 | tail -n1)

    { head -n $(($line-1)) $tmp_dir/tmp_file; cat $tmp_dir/build_producer; tail -n +$line $tmp_dir/tmp_file; } > $repro_test_file

    kafka_cli_producer_error=0
    kafka_cli_producer_eof=0
    line_kafka_cli_producer=$(egrep -n "kafka-console-producer|kafka-avro-console-producer|kafka-json-schema-console-producer|kafka-protobuf-console-producer" $repro_test_file | cut -d ":" -f 1 | tail -n1)
    if [ $? != 0 ]
    then
        logwarn "Could not find kafka cli producer!"
        kafka_cli_producer_error=1
    fi
    set +e
    egrep "kafka-console-producer|kafka-avro-console-producer|kafka-json-schema-console-producer|kafka-protobuf-console-producer" $repro_test_file | grep EOF > /dev/null
    if [ $? = 0 ]
    then
        kafka_cli_producer_eof=1

        sed -n "$line_kafka_cli_producer,$(($line_kafka_cli_producer + 10))p" $repro_test_file > /tmp/tmp
        tmp=$(grep -n "^EOF" /tmp/tmp | cut -d ":" -f 1 | tail -n1)
        if [ $tmp == "" ]
        then
          logwarn "Could not determine EOF for kafka cli producer!"
          kafka_cli_producer_error=1
        fi
        line_kafka_cli_producer_end=$(($line_kafka_cli_producer + $tmp))
    fi
    set -e
    if [ $kafka_cli_producer_error = 1 ]
    then
      get_producer_fixthis_heredoc
    fi

    for((i=1;i<=$nb_producers;i++)); do
      producer_hostname=""
      producer_hostname="producer-repro-$description_kebab_case"
      producer_hostname=${producer_hostname:0:21}

      if [ $nb_producers -eq 1 ]
      then
        producer_hostname="${producer_hostname}"
      else
        producer_hostname="${producer_hostname}$i"
      fi
      get_producer_run_heredoc
    done
    if [ $kafka_cli_producer_error = 1 ]
    then
      get_producer_fixthis_heredoc
    fi
    # log "✨ Adding command to run producer to $repro_test_file"
    cp $repro_test_file $tmp_dir/tmp_file

    if [ $kafka_cli_producer_error == 1 ]
    then
        { head -n $(($line-1)) $tmp_dir/tmp_file; cat $tmp_dir/java_producer; tail -n +$line $tmp_dir/tmp_file; } > $repro_test_file
    else
      if [ $kafka_cli_producer_eof == 0 ]
      then
        line_kafka_cli_producer_end=$(($line_kafka_cli_producer + 1))
      fi
      { head -n $(($line_kafka_cli_producer - 2)) $tmp_dir/tmp_file; cat $tmp_dir/java_producer; tail -n +$line_kafka_cli_producer_end $tmp_dir/tmp_file; } > $repro_test_file
    fi

    # deal with converters

    sink_key_converter=$(grep "\"key.converter\"" $repro_test_file | cut -d '"' -f 4)
    if [ "$sink_key_converter" == "" ]
    then
      log "💱 Sink connector is using default key.converter, i.e org.apache.kafka.connect.storage.StringConverter"
    else
      if [ "$sink_key_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
      then
        # check schemas.enable
        sink_key_json_converter_schemas_enable=$(grep "\"key.converter.schemas.enable\"" $repro_test_file | cut -d '"' -f 4)
        if [ "$sink_key_json_converter_schemas_enable" == "" ]
        then
          log "💱 Sink connector is using key.converter $sink_key_converter with schemas.enable=true"
        else
          log "💱 Sink connector is using key.converter $sink_key_converter with schemas.enable=$sink_key_json_converter_schemas_enable"
        fi
      else
        log "💱 Sink connector is using key.converter $sink_key_converter"
      fi
    fi

    sink_value_converter=$(grep "\"value.converter\"" $repro_test_file | cut -d '"' -f 4)
    if [ "$sink_value_converter" == "" ]
    then
      log "💱 Sink connector is using default value.converter, i.e io.confluent.connect.avro.AvroConverter"
    else
      if [ "$sink_value_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
      then
        # check schemas.enable
        sink_value_json_converter_schemas_enable=$(grep "\"value.converter.schemas.enable\"" $repro_test_file | cut -d '"' -f 4)
        if [ "$sink_value_json_converter_schemas_enable" == "" ]
        then
          log "💱 Sink connector is using value.converter $sink_value_converter with schemas.enable=true"
        else
          log "💱 Sink connector is using value.converter $sink_value_converter with schemas.enable=$sink_value_json_converter_schemas_enable"
        fi
      else
        log "💱 Sink connector is using value.converter $sink_value_converter"
      fi
    fi

    if [ "$sink_value_converter" == "" ]
    then
      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $repro_test_file; cat $tmp_dir/value_converter; tail -n +$(($line+1)) $repro_test_file; } > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file
    else
      # remove existing value.converter
      grep -vwE "\"value.converter" $repro_test_file > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file

      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $repro_test_file; cat $tmp_dir/value_converter; tail -n +$(($line+1)) $repro_test_file; } > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file
    fi
    log "🔮 Changing Sink connector value.converter to use same as producer:"
    cat $tmp_dir/value_converter

    if [ "$sink_key_converter" == "" ]
    then
      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $repro_test_file; cat $tmp_dir/key_converter; tail -n +$(($line+1)) $repro_test_file; } > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file
    else
      # remove existing key.converter
      grep -vwE "\"key.converter" $repro_test_file > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file

      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $repro_test_file; cat $tmp_dir/key_converter; tail -n +$(($line+1)) $repro_test_file; } > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file
    fi
    log "🔮 Changing Sink connector key.converter to use same as producer:"
    cat $tmp_dir/key_converter
  fi

  if [[ -n "$add_custom_smt" ]]
  then
    custom_smt_name=""
    custom_smt_name="MyCustomSMT-$description_kebab_case"
    custom_smt_name=${custom_smt_name:0:18}
    mkdir -p $repro_dir/$custom_smt_name/
    cp -Ra ../../other/custom-smt/MyCustomSMT/* $repro_dir/$custom_smt_name/

    tmp_dir=$(mktemp -d -t ci-XXXXXXXXXX)

    get_custom_smt_build_heredoc
    # log "✨ Adding command to build jar for $custom_smt_name to $repro_test_file"
    cp $repro_test_file $tmp_dir/tmp_file
    line=$(grep -n '${DIR}/../../environment' $repro_test_file | cut -d ":" -f 1 | tail -n1)

    { head -n $(($line-1)) $tmp_dir/tmp_file; cat $tmp_dir/build_custom_smt; tail -n +$line $tmp_dir/tmp_file; } > $repro_test_file

    connector_paths=$(grep "CONNECT_PLUGIN_PATH" "${docker_compose_file}" | grep -v "KSQL_CONNECT_PLUGIN_PATH" | cut -d ":" -f 2  | tr -s " " | head -1)
    if [ "$connector_paths" == "" ]
    then
      logerror "not a connector test"
      exit 1
    else
      #  Loop on all connectors in CONNECT_PLUGIN_PATH and install custom SMT jar in lib folder
      my_array_connector_tag=($(echo $CONNECTOR_TAG | tr "," "\n"))
      for connector_path in ${connector_paths//,/ }
      do
        echo "log \"📂 Copying custom jar to connector folder $connector_path/lib/\"" >> $tmp_dir/build_custom_docker_cp_smt
        echo "docker cp $repro_dir/$custom_smt_name/target/MyCustomSMT-1.0.0-SNAPSHOT-jar-with-dependencies.jar connect:$connector_path/lib/" >> $tmp_dir/build_custom_docker_cp_smt
      done
      echo "log \"♻️ Restart connect worker to load\"" >> $tmp_dir/build_custom_docker_cp_smt
      echo "docker restart connect" >> $tmp_dir/build_custom_docker_cp_smt
      echo "sleep 45" >> $tmp_dir/build_custom_docker_cp_smt
    fi

    cp $repro_test_file $tmp_dir/tmp_file
    line=$(grep -n '${DIR}/../../environment' $repro_test_file | cut -d ":" -f 1 | tail -n1)

    { head -n $(($line+2)) $tmp_dir/tmp_file; cat $tmp_dir/build_custom_docker_cp_smt; tail -n +$(($line+2)) $tmp_dir/tmp_file; } > $repro_test_file

    existing_transforms=$(grep "\"transforms\"" $repro_test_file | cut -d '"' -f 4)
    if [ "$existing_transforms" == "" ]
    then
      echo "              \"transforms\": \"MyCustomSMT\"," >> $tmp_dir/build_custom_smt_json_config
      echo "              \"transforms.MyCustomSMT.type\": \"com.github.vdesabou.kafka.connect.transforms.MyCustomSMT\"," >> $tmp_dir/build_custom_smt_json_config

      cp $repro_test_file $tmp_dir/tmp_file
      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/build_custom_smt_json_config; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $repro_test_file
    else
      log "🤖 Connector is using existing transforms $existing_transforms, the new custom SMT will be added to the list."

      # remove existing transforms
      grep -vwE "\"transforms\"" $repro_test_file > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file

      echo "              \"transforms\": \"MyCustomSMT,$existing_transforms\"," >> $tmp_dir/build_custom_smt_json_config
      echo "              \"transforms.MyCustomSMT.type\": \"com.github.vdesabou.kafka.connect.transforms.MyCustomSMT\"," >> $tmp_dir/build_custom_smt_json_config

      cp $repro_test_file $tmp_dir/tmp_file
      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/build_custom_smt_json_config; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $repro_test_file
    fi

  fi
  if [[ -n "$sink_file" ]]
  then
    tmp_dir=$(mktemp -d -t ci-XXXXXXXXXX)

    if [[ $sink_file == *"@"* ]]
    then
      sink_file=$(echo "$sink_file" | cut -d "@" -f 2)
    fi
    test_sink_file_directory="$(dirname "${sink_file}")"

    # docker-compose part
    # determining the docker-compose file from from test_file
    docker_compose_sink_file=$(grep "environment" "$sink_file" | grep DIR | grep start.sh | cut -d "/" -f 7 | cut -d '"' -f 1 | tail -n1 | xargs)
    docker_compose_sink_file="${test_sink_file_directory}/${docker_compose_sink_file}"
    cp $docker_compose_test_file /tmp/1.yml
    cp $docker_compose_sink_file /tmp/2.yml
    yq ". *= load(\"/tmp/1.yml\")" /tmp/2.yml > $docker_compose_test_file

    connector_paths=$(grep "CONNECT_PLUGIN_PATH" "${docker_compose_file}" | grep -v "KSQL_CONNECT_PLUGIN_PATH" | cut -d ":" -f 2  | tr -s " " | head -1)
    sink_connector_paths=$(grep "CONNECT_PLUGIN_PATH" "${docker_compose_sink_file}" | grep -v "KSQL_CONNECT_PLUGIN_PATH" | cut -d ":" -f 2  | tr -s " " | head -1)
    if [ "$sink_connector_paths" == "" ]
    then
      logerror "cannot find CONNECT_PLUGIN_PATH in  ${docker_compose_sink_file}"
      exit 1
    else
      tmp_new_connector_paths="$connector_paths,$sink_connector_paths"
      new_connector_paths=$(echo "$tmp_new_connector_paths" | sed 's/ //g')
      cp $docker_compose_test_file /tmp/1.yml

      yq -i ".services.connect.environment.CONNECT_PLUGIN_PATH = \"$new_connector_paths\"" /tmp/1.yml
      cp /tmp/1.yml $docker_compose_test_file
    fi


    # sh part

    line_final_source=$(grep -n 'source ${DIR}/../../scripts/utils.sh' $repro_test_file | cut -d ":" -f 1 | tail -n1)
    line_final_environment=$(grep -n '${DIR}/../../environment' $repro_test_file | cut -d ":" -f 1 | tail -n1)
    line_sink_source=$(grep -n 'source ${DIR}/../../scripts/utils.sh' $sink_file | cut -d ":" -f 1 | tail -n1)

    line_sink_environment=$(grep -n '${DIR}/../../environment' $sink_file | cut -d ":" -f 1 | tail -n1)

    # get converter info
    source_key_converter=$(grep "\"key.converter\"" $repro_test_file | cut -d '"' -f 4)
    if [ "$source_key_converter" == "" ]
    then
      log "💱 Source connector is using default key.converter, i.e org.apache.kafka.connect.storage.StringConverter"
    else
      if [ "$source_key_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
      then
        # check schemas.enable
        source_key_json_converter_schemas_enable=$(grep "\"key.converter.schemas.enable\"" $repro_test_file | cut -d '"' -f 4)
        if [ "$source_key_json_converter_schemas_enable" == "" ]
        then
          log "💱 Source connector is using key.converter $source_key_converter with schemas.enable=true"
        else
          log "💱 Source connector is using key.converter $source_key_converter with schemas.enable=$source_key_json_converter_schemas_enable"
        fi
      else
        log "💱 Source connector is using key.converter $source_key_converter"
      fi
    fi

    source_value_converter=$(grep "\"value.converter\"" $repro_test_file | cut -d '"' -f 4)
    if [ "$source_value_converter" == "" ]
    then
      log "💱 Source connector is using default value.converter, i.e io.confluent.connect.avro.AvroConverter"
    else
      if [ "$source_value_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
      then
        # check schemas.enable
        source_value_json_converter_schemas_enable=$(grep "\"value.converter.schemas.enable\"" $repro_test_file | cut -d '"' -f 4)
        if [ "$source_value_json_converter_schemas_enable" == "" ]
        then
          log "💱 Source connector is using value.converter $source_value_converter with schemas.enable=true"
        else
          log "💱 Source connector is using value.converter $source_value_converter with schemas.enable=$source_value_json_converter_schemas_enable"
        fi
      else
        log "💱 Source connector is using value.converter $source_value_converter"
      fi
    fi

    sink_key_converter=$(grep "\"key.converter\"" $sink_file | cut -d '"' -f 4)
    if [ "$sink_key_converter" == "" ]
    then
      log "💱 Sink connector is using default key.converter, i.e org.apache.kafka.connect.storage.StringConverter"
    else
      if [ "$sink_key_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
      then
        # check schemas.enable
        sink_key_json_converter_schemas_enable=$(grep "\"key.converter.schemas.enable\"" $sink_file | cut -d '"' -f 4)
        if [ "$sink_key_json_converter_schemas_enable" == "" ]
        then
          log "💱 Sink connector is using key.converter $sink_key_converter with schemas.enable=true"
        else
          log "💱 Sink connector is using key.converter $sink_key_converter with schemas.enable=$sink_key_json_converter_schemas_enable"
        fi
      else
        log "💱 Sink connector is using key.converter $sink_key_converter"
      fi
    fi

    sink_value_converter=$(grep "\"value.converter\"" $sink_file | cut -d '"' -f 4)
    if [ "$sink_value_converter" == "" ]
    then
      log "💱 Sink connector is using default value.converter, i.e io.confluent.connect.avro.AvroConverter"
    else
      if [ "$sink_value_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
      then
        # check schemas.enable
        sink_value_json_converter_schemas_enable=$(grep "\"value.converter.schemas.enable\"" $sink_file | cut -d '"' -f 4)
        if [ "$sink_value_json_converter_schemas_enable" == "" ]
        then
          log "💱 Sink connector is using value.converter $sink_value_converter with schemas.enable=true"
        else
          log "💱 Sink connector is using value.converter $sink_value_converter with schemas.enable=$sink_value_json_converter_schemas_enable"
        fi
      else
        log "💱 Sink connector is using value.converter $sink_value_converter"
      fi
    fi

    sed -n "$(($line_sink_source+1)),$(($line_sink_environment-1))p" $sink_file > $tmp_dir/pre_sink
    cp $repro_test_file $tmp_dir/tmp_file

    { head -n $(($line_final_environment-1)) $tmp_dir/tmp_file; cat $tmp_dir/pre_sink; tail -n +$line_final_environment $tmp_dir/tmp_file; } > $repro_test_file

    sed -n "$(($line_sink_environment+1)),$ p" $sink_file > $tmp_dir/tmp_file

    # deal with converters
    set +e
    if [ "$source_value_converter" == "" ] && [ "$sink_value_converter" == "" ]
    then
      # do nothing
      :
    else
      grep "\"value.converter" $repro_test_file > $tmp_dir/source_value_converter
      if [ "$sink_value_converter" == "" ]
      then
        line=$(grep -n 'connector.class' $tmp_dir/tmp_file | cut -d ":" -f 1 | tail -n1)

        { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/source_value_converter; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $tmp_dir/tmp_file2
        cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file
      else
        # remove existing value.converter
        grep -vwE "\"value.converter" $tmp_dir/tmp_file > $tmp_dir/tmp_file2
        cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file

        line=$(grep -n 'connector.class' $tmp_dir/tmp_file | cut -d ":" -f 1 | tail -n1)

        { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/source_value_converter; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $tmp_dir/tmp_file2
        cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file
      fi
      log "🔮 Changing Sink connector value.converter to use same as source:"
      cat $tmp_dir/source_value_converter
    fi
    if [ "$source_key_converter" == "" ] && [ "$sink_key_converter" == "" ]
    then
      # do nothing
      :
    else
      grep "\"key.converter" $repro_test_file > $tmp_dir/source_key_converter
      if [ "$sink_key_converter" == "" ]
      then
        line=$(grep -n 'connector.class' $tmp_dir/tmp_file | cut -d ":" -f 1 | tail -n1)

        { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/source_key_converter; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $tmp_dir/tmp_file2
        cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file
      else
        # remove existing key.converter
        grep -vwE "\"key.converter" $tmp_dir/tmp_file > $tmp_dir/tmp_file2
        cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file

        line=$(grep -n 'connector.class' $tmp_dir/tmp_file | cut -d ":" -f 1 | tail -n1)

        { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/source_key_converter; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $tmp_dir/tmp_file2
        cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file
      fi
      log "🔮 Changing Sink connector key.converter to use same as source:"
      cat $tmp_dir/source_key_converter
    fi
    set -e
    # need to remove cli which produces and change topic
    kafka_cli_producer_error=0
    kafka_cli_producer_eof=0
    line_kafka_cli_producer=$(egrep -n "kafka-console-producer|kafka-avro-console-producer|kafka-json-schema-console-producer|kafka-protobuf-console-producer" $tmp_dir/tmp_file | cut -d ":" -f 1 | tail -n1)
    if [ $? != 0 ]
    then
        logwarn "Could not find kafka cli producer!"
        kafka_cli_producer_error=1
    fi
    set +e
    egrep "kafka-console-producer|kafka-avro-console-producer|kafka-json-schema-console-producer|kafka-protobuf-console-producer" $tmp_dir/tmp_file | grep EOF > /dev/null
    if [ $? = 0 ]
    then
        kafka_cli_producer_eof=1

        sed -n "$line_kafka_cli_producer,$(($line_kafka_cli_producer + 10))p" $tmp_dir/tmp_file > /tmp/tmp
        tmp=$(grep -n "^EOF" /tmp/tmp | cut -d ":" -f 1 | tail -n1)
        if [ $tmp == "" ]
        then
          logwarn "Could not determine EOF for kafka cli producer!"
          kafka_cli_producer_error=1
        fi
        line_kafka_cli_producer_end=$(($line_kafka_cli_producer + $tmp))
    fi

    if [ $kafka_cli_producer_error == 0 ]
    then
      if [ $kafka_cli_producer_eof == 0 ]
      then
        line_kafka_cli_producer_end=$(($line_kafka_cli_producer + 1))
      fi
      { head -n $(($line_kafka_cli_producer - 2)) $tmp_dir/tmp_file; tail -n +$line_kafka_cli_producer_end $tmp_dir/tmp_file; } >  $tmp_dir/tmp_file2
      cat  $tmp_dir/tmp_file2 >> $repro_test_file
    fi
    set -e

    awk -F'--topic ' '{print $2}' $repro_test_file > $tmp_dir/tmp
    sed '/^$/d' $tmp_dir/tmp > $tmp_dir/tmp2
    original_topic_name=$(head -1 $tmp_dir/tmp2 | cut -d " " -f1)

    if [ "$original_topic_name" != "" ]
    then
      cp $repro_test_file $tmp_dir/tmp_file
      line=$(grep -n '"topics"' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      echo "              \"topics\": \"$original_topic_name\"," > $tmp_dir/topic_line
      { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/topic_line; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $repro_test_file
    else

      logwarn "Could not find original topic name! "
      logwarn "You would need to change topics config for sink by yourself."
    fi
  fi

  chmod u+x $repro_test_file
  repro_test_filename=$(basename -- "$repro_test_file")

  log "🌟 Command to run generated example"
  echo "playground run -f $repro_dir/$repro_test_filename"
  echo "playground run -f $repro_dir/$repro_test_filename" > /tmp/playground-run

  if config_has_key "editor"
  then
    editor=$(config_get "editor")
    log "📖 Opening ${repro_test_filename} using configured editor $editor"
    $editor $repro_dir/$repro_test_filename
  else
    if [[ $(type code 2>&1) =~ "not found" ]]
    then
      logerror "Could not determine an editor to use as default code is not found - you can change editor by updating config.ini"
      exit 1
    else
      log "📖 Opening ${repro_test_filename} with code (default) - you can change editor by updating config.ini"
      code $repro_dir/$repro_test_filename
    fi
  fi

  # run command specifics:

  flag_list=""
  if [[ -n "$tag" ]]
  then
    flag_list="--tag=$tag"
  fi

  if [[ -n "$connector_tag" ]]
  then
    flag_list="$flag_list --connector-tag=$connector_tag"
  fi

  if [[ -n "$connector_zip" ]]
  then
    if [[ $connector_zip == *"@"* ]]
    then
      connector_zip=$(echo "$connector_zip" | cut -d "@" -f 2)
    fi
    flag_list="$flag_list --connector-zip=$connector_zip"
  fi

  if [[ -n "$connector_jar" ]]
  then
    if [[ $connector_jar == *"@"* ]]
    then
      connector_jar=$(echo "$connector_jar" | cut -d "@" -f 2)
    fi
    flag_list="$flag_list --connector-jar=$connector_jar"
  fi

  if [[ -n "$enable_ksqldb" ]]
  then
    flag_list="$flag_list --enable-ksqldb"
  fi

  if [[ -n "$enable_c3" ]]
  then
    flag_list="$flag_list --enable-control-center"
  fi

  if [[ -n "$enable_conduktor" ]]
  then
    flag_list="$flag_list --enable-conduktor"
  fi

  if [[ -n "$enable_multiple_brokers" ]]
  then
    flag_list="$flag_list --enable-multiple-broker"
  fi

  if [[ -n "$enable_multiple_connect_workers" ]]
  then
    flag_list="$flag_list --enable-multiple-connect-workers"
  fi

  if [[ -n "$enable_jmx_grafana" ]]
  then
    flag_list="$flag_list --enable-jmx-grafana"
  fi

  if [[ -n "$enable_kcat" ]]
  then
    flag_list="$flag_list --enable-kcat"
  fi

  if [[ -n "$enable_sr_maven_plugin_app" ]]
  then
    flag_list="$flag_list --enable-sr-maven-plugin-app"
  fi

  if [[ -n "$enable_sql_datagen" ]]
  then
    flag_list="$flag_list --enable-sql-datagen"
  fi

  log "🕹️ Ready? Run it now?"
  check_if_continue
  playground run -f $repro_dir/$repro_test_filename $flag_list ${other_args[*]}
}

# :command.function
playground_get_properties_command() {
  # src/get_properties_command.sh
  container="${args[--container]}"

  log "Displaying properties file for $container"
  # see heredocs.sh
  get_properties_command_heredoc "$container"
}

# :command.function
playground_get_all_schemas_command() {
  # src/get_all_schemas_command.sh
  open="${args[--open]}"

  function get_all_schemas() {
    ret=$(get_sr_url_and_security)

    sr_url=$(echo "$ret" | cut -d "@" -f 1)
    sr_security=$(echo "$ret" | cut -d "@" -f 2)

    # Get a list of all subjects in the schema registry
    subjects=$(curl $sr_security -s "${sr_url}/subjects")

    if [[ -n "$open" ]]
    then
      echo "Displaying all subjects 🔰 and versions 💯"
    else
      log "Displaying all subjects 🔰 and versions 💯"
    fi
    for subject in $(echo "${subjects}" | jq -r '.[]'); do
      versions=$(curl $sr_security -s "${sr_url}/subjects/${subject}/versions")

      for version in $(echo "${versions}" | jq -r '.[]')
      do
        schema_type=$(curl $sr_security -s "${sr_url}/subjects/${subject}/versions/${version}"  | jq -r .schemaType)
        case "${schema_type}" in
          JSON|null)
            schema=$(curl $sr_security -s "${sr_url}/subjects/${subject}/versions/${version}/schema" | jq .)
          ;;
          PROTOBUF)
            schema=$(curl $sr_security -s "${sr_url}/subjects/${subject}/versions/${version}/schema")
          ;;
        esac

        if [[ -n "$open" ]]
        then
          echo "🔰 ${subject} 💯 ${version}"
        else
          log "🔰 ${subject} 💯 ${version}"
        fi
        echo "${schema}"
      done
    done
  }

  if [[ -n "$open" ]]
  then
    filename="/tmp/get-all-schemas-`date '+%Y-%m-%d-%H-%M-%S'`.log"
    log "Opening $filename with editor $editor"
    get_all_schemas > "$filename" 2>&1
    if [ $? -eq 0 ]
    then
      if config_has_key "editor"
      then
        editor=$(config_get "editor")
        log "📖 Opening ${filename} using configured editor $editor"
        $editor $filename
      else
        if [[ $(type code 2>&1) =~ "not found" ]]
        then
          logerror "Could not determine an editor to use as default code is not found - you can change editor by updating config.ini"
          exit 1
        else
          log "📖 Opening ${filename} with code (default) - you can change editor by updating config.ini"
          code $filename
        fi
      fi
    else
      logerror "Failed to get schemas"
    fi
  else

    get_all_schemas
  fi
}

# :command.function
playground_enable_remote_debugging_command() {
  # src/enable_remote_debugging_command.sh
  IGNORE_CHECK_FOR_DOCKER_COMPOSE=true

  container="${args[--container]}"

  log "Enable remote debugging for $container"

  # For ccloud case
  if [ -f /tmp/delta_configs/env.delta ]
  then
       source /tmp/delta_configs/env.delta
  fi

  # keep CONNECT TAG
  export CONNECT_TAG=$(docker inspect -f '{{.Config.Image}}' connect | cut -d ":" -f 2)

  if [ ! -f /tmp/playground-command ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1
  fi

  # see heredocs.sh
  get_remote_debugging_command_heredoc "$container"

  bash /tmp/playground-command-debugging

  log "If you use Visual Studio Code:"
  log "Edit .vscode/launch.json with"

  log "
  {
      \"version\": \"0.2.0\",
      \"configurations\": [

          {
              \"type\": \"java\",
              \"name\": \"Debug $component container\",
              \"request\": \"attach\",
              \"hostName\": \"127.0.0.1\",
              \"port\": 5005,
              \"timeout\": 30000
          }
      ]
  }
  "

  log "See https://kafka-docker-playground.io/#/reusables?id=✨-remote-debugging"
}

# :command.function
playground_log_level_get_command() {
  # src/log_level_get_command.sh
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  package="${args[--package]}"

  if [[ -n "$package" ]]
  then
    log "🧬 Get log level for package $package"
    curl $security -s "$connect_url/admin/loggers/$package"
  else
    log "🧬 Get log level for all packages"
    curl $security -s "$connect_url/admin/loggers" | jq .
  fi
}

# :command.function
playground_log_level_set_command() {
  # src/log_level_set_command.sh
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  package="${args[--package]}"
  level="${args[--level]}"

  current_level=$(curl $security -s "$connect_url/admin/loggers/$package" | jq -r '.level')

  if [ "$current_level" != "$level" ]
  then
      log "🧬 Set log level for package $package to $level"
      curl $security -s --request PUT \
      --url "$connect_url/admin/loggers/$package" \
      --header 'Accept: application/json' \
      --header 'Content-Type: application/json' \
      --data "{
      \"level\": \"$level\"
      }" | jq .

      playground log-level get -p "$package"
  else
      log "🧬⏭️ Skipping as log level for package $package was already set to $level"
  fi
}

# :command.function
playground_get_jmx_metrics_command() {
  # src/get_jmx_metrics_command.sh
  IGNORE_CHECK_FOR_DOCKER_COMPOSE=true

  component="${args[--component]}"
  domain="${args[--domain]}"

  case "${component}" in
    zookeeper|broker|schema-registry|connect)
    ;;
    *)
      logerror "ERROR: component name not valid ! Should be one of zookeeper, broker, schema-registry or connect"
      exit 1
    ;;
  esac

  get_jmx_metrics "$component" "$domain"
}

# :command.function
playground_container_recreate_command() {
  # src/container_recreate_command.sh
  IGNORE_CHECK_FOR_DOCKER_COMPOSE=true

  # keep CONNECT TAG
  export CONNECT_TAG=$(docker inspect -f '{{.Config.Image}}' connect | cut -d ":" -f 2)

  if [ ! -f /tmp/playground-command ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1
  fi

  bash /tmp/playground-command
}

# :command.function
playground_container_get_ip_addresses_command() {
  # src/container_get_ip_addresses_command.sh
  log "Get IP address of running containers"
  docker inspect -f '{{.Name}} - {{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' $(docker ps -aq)
}

# :command.function
playground_container_kill_all_command() {
  # src/container_kill_all_command.sh
  log "💀 Kill all docker containers"
  docker rm -f $(docker ps -qa) > /dev/null 2>&1
}

# :command.function
playground_container_logs_command() {
  # src/container_logs_command.sh
  container="${args[--container]}"
  open="${args[--open]}"
  log="${args[--wait-for-log]}"
  max_wait="${args[--max-wait]}"

  if [[ -n "$open" ]]
  then
    filename="/tmp/${container}-`date '+%Y-%m-%d-%H-%M-%S'`.log"
    log "Opening $filename with editor $editor"
    docker container logs "$container" > "$filename" 2>&1
    if [ $? -eq 0 ]
    then
      if config_has_key "editor"
      then
        editor=$(config_get "editor")
        log "📖 Opening ${filename} using configured editor $editor"
        $editor $filename
      else
        if [[ $(type code 2>&1) =~ "not found" ]]
        then
          logerror "Could not determine an editor to use as default code is not found - you can change editor by updating config.ini"
          exit 1
        else
          log "📖 Opening ${filename} with code (default) - you can change editor by updating config.ini"
          code $filename
        fi
      fi
    else
      logerror "Failed to get logs using container logs $container"
    fi
  elif [[ -n "$log" ]]
  then
    wait_for_log "$log" "$container" "$max_wait"
  else

    docker container logs --tail=200 -f "$container"
  fi
}

# :command.function
playground_container_ssh_command() {
  # src/container_ssh_command.sh
  container="${args[--container]}"
  shell="${args[--shell]}"

  docker exec -it "$container" "$shell"
}

# :command.function
playground_container_exec_command() {
  # src/container_exec_command.sh
  container="${args[--container]}"
  command="${args[--command]}"
  root="${args[--root]}"
  shell="${args[--shell]}"

  if [[ -n "$root" ]]
  then
    log "Executing command as root in container $container with $shell"
    docker exec --privileged --user root $container $shell -c "$command"
  else
    log "Executing command in container $container with $shell"
    docker exec $container $shell -c "$command"
  fi

}

# :command.function
playground_container_restart_command() {
  # src/container_restart_command.sh
  container="${args[--container]}"

  log "Restarting docker container ${container}"
  docker restart ${container}
}

# :command.function
playground_container_pause_command() {
  # src/container_pause_command.sh
  container="${args[--container]}"

  log "Pausing docker container ${container}"
  docker pause ${container}
}

# :command.function
playground_container_resume_command() {
  # src/container_resume_command.sh
  container="${args[--container]}"

  log "Resuming docker container ${container}"
  docker unpause ${container}
}

# :command.function
playground_container_kill_command() {
  # src/container_kill_command.sh
  container="${args[--container]}"

  log "Killing docker container ${container}"
  docker kill ${container}
}

# :command.function
playground_topic_get_number_records_command() {
  # src/topic_get_number_records_command.sh
  topic="${args[--topic]}"

  ret=$(get_security_broker "--command-config")

  container=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  if [[ ! -n "$topic" ]]
  then
      log "✨ --topic flag was not provided, applying command to all topics"
      topic=$(playground get-topic-list --skip-connect-internal-topics)
      if [ "$topic" == "" ]
      then
          logerror "❌ No topic found !"
          exit 1
      fi
  fi

  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi

  items=($topic)
  for topic in ${items[@]}
  do
      log "💯 Get number of records in a topic $topic"
      if [[ "$environment" == "environment" ]]
      then
          if [ ! -f /tmp/delta_configs/librdkafka.delta ]
          then
              logerror "ERROR: /tmp/delta_configs/librdkafka.delta has not been generated"
              exit 1
          fi
          docker run -it --network=host \
              -v /tmp/delta_configs/librdkafka.delta:/tmp/configuration/ccloud.properties \
              confluentinc/cp-kcat:latest kcat \
                  -F /tmp/configuration/ccloud.properties \
                  -C -t $topic \
                  -e -q \
                  | grep -v "Reading configuration from file" | wc -l | tr -d ' '
      else
          docker exec $container kafka-run-class kafka.tools.GetOffsetShell --broker-list broker:9092 $security --topic $topic --time -1 | awk -F ":" '{sum += $3} END {print sum}'
      fi
  done
}

# :command.function
playground_topic_display_consumer_offsets_command() {
  # src/topic_display_consumer_offsets_command.sh
  ret=$(get_security_broker "--consumer.config")

  container=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi

  log "Display content of __consumer_offsets topic, press crtl-c to stop..."
  if [[ "$environment" == "environment" ]]
  then
      if [ -f /tmp/delta_configs/env.delta ]
      then
          source /tmp/delta_configs/env.delta
      else
          logerror "ERROR: /tmp/delta_configs/env.delta has not been generated"
          exit 1
      fi
      if [ ! -f /tmp/delta_configs/ak-tools-ccloud.delta ]
      then
          logerror "ERROR: /tmp/delta_configs/ak-tools-ccloud.delta has not been generated"
          exit 1
      fi

      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
      dir1=$(echo ${DIR_CLI%/*})
      root_folder=$(echo ${dir1%/*})
      IGNORE_CHECK_FOR_DOCKER_COMPOSE=true
      source $root_folder/scripts/utils.sh

      docker run --rm -v /tmp/delta_configs/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SASL_JAAS_CONFIG="$SASL_JAAS_CONFIG" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-topics --describe --topic $topic --bootstrap-server $BOOTSTRAP_SERVERS --command-config /tmp/configuration/ccloud.properties
  else
      docker exec -i $container kafka-console-consumer --bootstrap-server broker:9092 --topic __consumer_offsets --from-beginning --formatter "kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter" $security | grep -v "_confluent-controlcenter"
  fi

}

# :command.function
playground_topic_describe_command() {
  # src/topic_describe_command.sh
  topic="${args[--topic]}"

  ret=$(get_security_broker "--command-config")

  container=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  if [[ ! -n "$topic" ]]
  then
      log "✨ --topic flag was not provided, applying command to all topics"
      topic=$(playground get-topic-list --skip-connect-internal-topics)
      if [ "$topic" == "" ]
      then
          logerror "❌ No topic found !"
          exit 1
      fi
  fi

  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi

  items=($topic)
  for topic in ${items[@]}
  do
      log "🔎 Describing topic $topic"
      if [[ "$environment" == "environment" ]]
      then
          if [ -f /tmp/delta_configs/env.delta ]
          then
              source /tmp/delta_configs/env.delta
          else
              logerror "ERROR: /tmp/delta_configs/env.delta has not been generated"
              exit 1
          fi
          if [ ! -f /tmp/delta_configs/ak-tools-ccloud.delta ]
          then
              logerror "ERROR: /tmp/delta_configs/ak-tools-ccloud.delta has not been generated"
              exit 1
          fi

          DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
          dir1=$(echo ${DIR_CLI%/*})
          root_folder=$(echo ${dir1%/*})
          IGNORE_CHECK_FOR_DOCKER_COMPOSE=true
          source $root_folder/scripts/utils.sh

          docker run --rm -v /tmp/delta_configs/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-topics --describe --topic $topic --bootstrap-server $BOOTSTRAP_SERVERS --command-config /tmp/configuration/ccloud.properties
      else
          docker exec $container kafka-topics --describe --topic $topic --bootstrap-server broker:9092 $security
      fi
  done
}

# :command.function
playground_topic_consume_command() {
  # src/topic_consume_command.sh
  topic="${args[--topic]}"
  max_messages="${args[--max-messages]}"
  grep_string="${args[--grep]}"
  min_expected_messages="${args[--min-expected-messages]}"

  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi

  ret=$(get_sr_url_and_security)

  sr_url=$(echo "$ret" | cut -d "@" -f 1)
  sr_security=$(echo "$ret" | cut -d "@" -f 2)

  bootstrap_server="broker:9092"
  container="connect"
  sr_url_cli="http://schema-registry:8081"
  security=""
  if [[ "$environment" == *"ssl"* ]]
  then
      sr_url_cli="https://schema-registry:8081"
      security="--property schema.registry.ssl.truststore.location=/etc/kafka/secrets/kafka.client.truststore.jks --property schema.registry.ssl.truststore.password=confluent --property schema.registry.ssl.keystore.location=/etc/kafka/secrets/kafka.client.keystore.jks --property schema.registry.ssl.keystore.password=confluent --consumer.config /etc/kafka/secrets/client_without_interceptors.config"
  elif [[ "$environment" == "rbac-sasl-plain" ]]
  then
      sr_url_cli="http://schema-registry:8081"
      security="--property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info=clientAvroCli:clientAvroCli --consumer.config /etc/kafka/secrets/client_without_interceptors.config"
  elif [[ "$environment" == "kerberos" ]]
  then
      container="client"
      sr_url_cli="http://schema-registry:8081"
      security="--consumer.config /etc/kafka/consumer.properties"

      docker exec -i client kinit -k -t /var/lib/secret/kafka-connect.key connect
  elif [[ "$environment" == "environment" ]]
  then
    if [ -f /tmp/delta_configs/env.delta ]
    then
        source /tmp/delta_configs/env.delta
    else
        logerror "ERROR: /tmp/delta_configs/env.delta has not been generated"
        exit 1
    fi
    if [ ! -f /tmp/delta_configs/ak-tools-ccloud.delta ]
    then
        logerror "ERROR: /tmp/delta_configs/ak-tools-ccloud.delta has not been generated"
        exit 1
    fi
    DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
    dir1=$(echo ${DIR_CLI%/*})
    root_folder=$(echo ${dir1%/*})
    IGNORE_CHECK_FOR_DOCKER_COMPOSE=true
    source $root_folder/scripts/utils.sh
  fi

  if [[ ! -n "$topic" ]]
  then
      if [[ -n "$min_expected_messages" ]]
      then
        logerror "--min-expected-messages was provided without specifying --topic"
        exit 1
      fi
      log "✨ --topic flag was not provided, applying command to all topics"
      topic=$(playground get-topic-list --skip-connect-internal-topics)
      if [ "$topic" == "" ]
      then
          logerror "❌ No topic found !"
          exit 1
      fi
  fi

  items=($topic)
  for topic in ${items[@]}
  do
    if [[ -n "$min_expected_messages" ]]
    then
      nb_messages=$(playground topic get-number-records -t $topic | tail -1)
      if [ $nb_messages -lt $min_expected_messages ]
      then
        logerror "❌ --min-expected-messages is set with $min_expected_messages but topic $topic contains $nb_messages messages"
        exit 1
      fi
    else
      nb_messages=$(playground topic get-number-records -t $topic | tail -1)
    fi

    if [[ -n "$max_messages" ]]
    then
      log "✨ Display content of topic $topic, it contains $nb_messages messages, but displaying only --max-messages=$max_messages"
      nb_messages=$max_messages
    else
      log "✨ Display content of topic $topic, it contains $nb_messages messages"
    fi

    key_type=""
    version=$(curl $sr_security -s "${sr_url}/subjects/${topic}-key/versions/1" | jq -r .version)
    if [ "$version" != "null" ]
    then
      schema_type=$(curl $sr_security -s "${sr_url}/subjects/${topic}-key/versions/1"  | jq -r .schemaType)
      case "${schema_type}" in
        JSON)
          key_type="json-schema"
        ;;
        PROTOBUF)
          key_type="protobuf"
        ;;
        null)
          key_type="avro"
        ;;
      esac
    fi

    if [ "$key_type" != "" ]
    then
      log "🔮🔰 topic is using $key_type for key"
    else
      log "🔮🙅 topic is not using any schema for key"
    fi

    value_type=""
    version=$(curl $sr_security -s "${sr_url}/subjects/${topic}-value/versions/1" | jq -r .version)
    if [ "$version" != "null" ]
    then
      schema_type=$(curl $sr_security -s "${sr_url}/subjects/${topic}-value/versions/1"  | jq -r .schemaType)
      case "${schema_type}" in
        JSON)
          value_type="json-schema"
        ;;
        PROTOBUF)
          value_type="protobuf"
        ;;
        null)
          value_type="avro"
        ;;
      esac
    fi

    if [ "$value_type" != "" ]
    then
      log "🔮🔰 topic is using $value_type for value"
    else
      log "🔮🙅 topic is not using any schema for value"
    fi

    type=""
    tmp_dir=$(mktemp -d -t ci-XXXXXXXXXX)
    fifo_path="$tmp_dir/kafka_output_fifo"
    mkfifo "$fifo_path"
    case "${value_type}" in
      avro|protobuf|json-schema)
          if [ "$key_type" == "avro" ] || [ "$key_type" == "protobuf" ] || [ "$key_type" == "json-schema" ]
          then
              if [[ "$environment" == "environment" ]]
              then
                docker run --rm -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/etc/kafka/tools-log4j.properties" -e value_type=$value_type -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" -e SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-$value_type-console-consumer --bootstrap-server $BOOTSTRAP_SERVERS --topic $topic --consumer-property ssl.endpoint.identification.algorithm=https --consumer-property sasl.mechanism=PLAIN --consumer-property security.protocol=SASL_SSL --consumer-property sasl.jaas.config="$SASL_JAAS_CONFIG" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" --property schema.registry.url=$SCHEMA_REGISTRY_URL --property print.partition=true --property print.offset=true --property print.headers=true --property print.timestamp=true --property print.key=true --property key.separator="|" --skip-message-on-error $security --from-beginning --max-messages $nb_messages > "$fifo_path" 2>&1 &
              else
                docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/etc/kafka/tools-log4j.properties" $container kafka-$value_type-console-consumer -bootstrap-server $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic --property print.partition=true --property print.offset=true --property print.headers=true --property print.timestamp=true --property print.key=true --property key.separator="|" --skip-message-on-error $security --from-beginning --max-messages $nb_messages > "$fifo_path" 2>&1 &
              fi
          else
              if [[ "$environment" == "environment" ]]
              then
                docker run --rm -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/etc/kafka/tools-log4j.properties" -e value_type=$value_type -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" -e SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-$value_type-console-consumer --bootstrap-server $BOOTSTRAP_SERVERS --topic $topic --consumer-property ssl.endpoint.identification.algorithm=https --consumer-property sasl.mechanism=PLAIN --consumer-property security.protocol=SASL_SSL --consumer-property sasl.jaas.config="$SASL_JAAS_CONFIG" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" --property schema.registry.url=$SCHEMA_REGISTRY_URL --property print.partition=true --property print.offset=true --property print.headers=true --property print.timestamp=true --property print.key=true --property key.separator="|"  --property key.deserializer=org.apache.kafka.common.serialization.StringDeserializer --skip-message-on-error $security --from-beginning --max-messages $nb_messages > "$fifo_path" 2>&1 &
              else
                docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/etc/kafka/tools-log4j.properties" $container kafka-$value_type-console-consumer --bootstrap-server $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic --property print.partition=true --property print.offset=true --property print.headers=true --property print.timestamp=true --property print.key=true --property key.separator="|" --property key.deserializer=org.apache.kafka.common.serialization.StringDeserializer --skip-message-on-error $security --from-beginning --max-messages $nb_messages > "$fifo_path" 2>&1 &
              fi
          fi
          ;;
      *)
        if [[ "$environment" == "environment" ]]
        then
          docker run --rm -v /tmp/delta_configs/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-console-consumer --bootstrap-server $BOOTSTRAP_SERVERS --topic $topic --consumer.config  --property print.partition=true --property print.offset=true --property print.headers=true --property print.timestamp=true --property print.key=true --property key.separator="|" $security --from-beginning --max-messages $nb_messages > "$fifo_path" 2>&1 &
        else
          docker exec $container kafka-console-consumer --bootstrap-server $bootstrap_server --topic $topic --property print.partition=true --property print.offset=true --property print.headers=true --property print.timestamp=true --property print.key=true --property key.separator="|" $security --from-beginning --max-messages $nb_messages > "$fifo_path" 2>&1  &
        fi
      ;;
    esac

    # Detect the platform (macOS or Linux) and set the date command accordingly
    if [[ "$(uname)" == "Darwin" ]]; then
      # macOS
      date_command="date -r "
    else
      # Linux
      date_command="date -d @"
    fi

    found=0
    # Loop through each line in the named pipe
    while read -r line
    do
      if [[ $line =~ "CreateTime:" ]]
      then
        # Extract the timestamp from the line
        timestamp_ms=$(echo "$line" | cut -d ":" -f 2 | cut -d "|" -f 1)
        # Convert milliseconds to seconds
        timestamp_sec=$((timestamp_ms / 1000))
        milliseconds=$((timestamp_ms % 1000))
        readable_date="$(${date_command}${timestamp_sec} "+%Y-%m-%d %H:%M:%S.${milliseconds}")"
        line_with_date=$(echo "$line" | sed -E "s/CreateTime:[0-9]{13}/CreateTime: ${readable_date}/")
        echo "$line_with_date"
      elif [[ $line =~ "Processed a total of" ]]
      then
        continue
      else
        echo "$line"
      fi
      if [[ -n "$grep_string" ]]
      then
        if [[ $line =~ "$grep_string" ]]
        then
          log "✅ found $grep_string in topic $topic"
          found=1
        fi
      fi
    done < "$fifo_path"

    if [[ -n "$grep_string" ]]
    then
      if [ $found != 1 ]
      then
        logerror "❌ could not find $grep_string in topic $topic"
        exit 1
      fi
    fi
  done
}

# :command.function
playground_topic_set_schema_compatibility_command() {
  # src/topic_set_schema_compatibility_command.sh
  topic="${args[--topic]}"
  compatibility="${args[--compatibility]}"

  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi

  ret=$(get_sr_url_and_security)

  sr_url=$(echo "$ret" | cut -d "@" -f 1)
  sr_security=$(echo "$ret" | cut -d "@" -f 2)

  if [[ ! -n "$topic" ]]
  then
      logwarn "--topic flag was not provided, applying command to all topics"
      check_if_continue
      topic=$(playground get-topic-list --skip-connect-internal-topics)
      if [ "$topic" == "" ]
      then
          logerror "❌ No topic found !"
          exit 1
      fi
  fi

  items=($topic)
  for topic in ${items[@]}
  do
    log "🛡️ Set compatibility for subject ${topic}-value to $compatibility"
    curl $sr_security -X PUT -H "Content-Type: application/vnd.schemaregistry.v1+json" --data "{\"compatibility\": \"$compatibility\"}" "${sr_url}/config/${topic}-value"
  done
}

# :command.function
playground_topic_display_schema_id_statistics_command() {
  # src/topic_display_schema_id_statistics_command.sh
  topic="${args[--topic]}"

  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
      logerror "File containing restart command /tmp/playground-command does not exist!"
      exit 1
  fi

  if [ "$environment" != "plaintext" ]
  then
      logerror "It only works when plaintext environment is used"
      exit 1
  fi

  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  root_folder=$(echo ${dir1%/*})

  sr_cli=$root_folder/scripts/cli/schema-registry-statistics
  sr_cli_version=1.3.0

  if [ ! -f $sr_cli ]
  then
      log "⏳ $sr_cli is not installed, installing it now"
      cd /tmp
      rm -f schema-registry-statistics.tar.gz
      curl -L -o schema-registry-statistics.tar.gz https://github.com/EladLeev/schema-registry-statistics/releases/download/v${sr_cli_version}/schema-registry-statistics_${sr_cli_version}_`uname -s`_`uname -m`.tar.gz
      tar xvfz schema-registry-statistics.tar.gz
      mv schema-registry-statistics $sr_cli
      rm -f chema-registry-statistics.tar.gz
      chmod u+x $sr_cli
      cd -
  fi

  if [[ ! -n "$topic" ]]
  then
      log "✨ --topic flag was not provided, applying command to all topics"
      topic=$(playground get-topic-list --skip-connect-internal-topics)
      if [ "$topic" == "" ]
      then
          logerror "❌ No topic found !"
          exit 1
      fi
  fi

  items=($topic)
  for topic in ${items[@]}
  do
      nb_messages=$(playground topic get-number-records -t $topic | tail -1)
      rm -f /tmp/results.json
      log "✨ Display statistics of topic $topic, it contains $nb_messages messages"
      output_file="/tmp/output.txt"
      $sr_cli --bootstrap localhost:29092 --topic "$topic" --group "$RANDOM" --limit $nb_messages --store true --path /tmp/results.json  > "$output_file" 2>&1 &

      pid=$!

      while true
      do
          if grep -q "Use SIGINT to stop consuming" "$output_file"
          then
              break
          fi
          sleep 1
      done

      kill -SIGINT $pid

      sleep 2
      grep "Schema ID" $output_file
      cat /tmp/results.json | jq .

      rm -f /tmp/results.json $output_file
  done
}

# :command.function
playground_connector_status_command() {
  # src/connector_status_command.sh
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  connectors=$(curl -s $security "$connect_url/connectors/" | jq -r '.[]')

  log "🧩 Displaying connector(s) status"
  if [ -z "$connectors" ]
  then
      log "💤 There are no connectors running !"
  else
      printf "%-30s %-12s %-60s %-50s\n" "Name" "Status" "Tasks" "Stack Trace"
      echo "-----------------------------------------------------------------------------------------------------------------------------"

      for connector in $connectors
      do
          status=$(curl -s $security "$connect_url/connectors/$connector/status" | jq -r '.connector.state')

          if [ "$status" == "RUNNING" ]
          then
              status="✅ RUNNING"
          elif [ "$status" == "PAUSED" ]
          then
              status="⏸️  PAUSED"
          elif [ "$status" == "FAILED" ]
          then
              status="❌ FAILED"
          else
              status="🤔 UNKNOWN"
          fi

          tasks=$(curl -s $security "$connect_url/connectors/$connector/status" | jq -r '.tasks[] | "\(.id):\(.state)[\(.worker_id)]"' | tr '\n' ',' | sed 's/,$/\n/' | sed 's/:8083//g' | sed 's/:8283//g' | sed 's/:8383//g')

          if [[ "$tasks" == *"RUNNING"* ]]
          then
              tasks="${tasks//RUNNING/🟢 RUNNING}"
          elif [[ "$tasks" == *"PAUSED"* ]]
          then
              tasks="${tasks//PAUSED/⏸️  PAUSED}"
          elif [[ "$tasks" == *"FAILED"* ]]
          then
              tasks="${tasks//FAILED/🛑 FAILED}"
          else
              tasks="🤔 N/A"
          fi

          stacktrace_connector=$(curl -s $security "$connect_url/connectors/$connector/status" | jq -r '.connector.trace | select(length > 0)')
          stacktrace_tasks=$(curl -s $security "$connect_url/connectors/$connector/status" | jq -r '.tasks[].trace | select(length > 0)')
          stacktrace=""
          if [ "$stacktrace_connector" != "" ]
          then
              stacktrace="connector: $stacktrace_connector"
          fi

          if [ "$stacktrace_tasks" != "" ]
          then
              stacktrace="$stacktrace tasks: $stacktrace_tasks"
          fi

          if [ -z "$stacktrace" ]
          then
              stacktrace="-"
          fi

          printf "%-30s %-12s %-30s %-50s\n" "$connector" "$status" "$tasks" "$stacktrace"
          echo "-------------------------------------------------------------------------------------------------------------"
      done
  fi

}

# :command.function
playground_connector_plugins_command() {
  # src/connector_plugins_command.sh
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  log "🧩 Displaying all connector plugins installed"
  curl $security -s -X GET -H "Content-Type: application/json" "$connect_url/connector-plugins" | jq -r '.[] | [.class , .version , .type] | @tsv' | column -t
}

# :command.function
playground_connector_pause_command() {
  # src/connector_pause_command.sh
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  connector="${args[--connector]}"

  if [[ ! -n "$connector" ]]
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          logerror "💤 No connector is running !"
          exit 1
      fi
  fi

  items=($connector)
  for connector in ${items[@]}
  do
      log "⏸️ Pausing connector $connector"
      curl $security -s -X PUT -H "Content-Type: application/json" "$connect_url/connectors/$connector/pause" | jq .
  done
  playground connector status
}

# :command.function
playground_connector_versions_command() {
  # src/connector_versions_command.sh
  if [ ! -f /tmp/playground-run ]
  then
      logerror "File containing re-run command /tmp/playground-run does not exist!"
      logerror "Make sure to use <playground run> command !"
      exit 1
  fi

  test_file=$(cat /tmp/playground-run | awk '{ print $4}')

  if [ ! -f $test_file ]
  then

      logerror "File $test_file retrieved from /tmp/playground-run does not exist!"
      logerror "Make sure to use <playground run> command !"
      exit 1
  fi

  # determining the docker-compose file from from test_file
  docker_compose_file=$(grep "environment" "$test_file" | grep DIR | grep start.sh | cut -d "/" -f 7 | cut -d '"' -f 1 | tail -n1 | xargs)
  test_file_directory="$(dirname "${test_file}")"
  docker_compose_file="${test_file_directory}/${docker_compose_file}"

  if [ "${docker_compose_file}" != "" ] && [ ! -f "${docker_compose_file}" ]
  then
      logwarn "Skipping as docker-compose override file could not be detemined"
      exit 0
  fi

  connector_paths=$(grep "CONNECT_PLUGIN_PATH" "${docker_compose_file}" | grep -v "KSQL_CONNECT_PLUGIN_PATH" | cut -d ":" -f 2  | tr -s " " | head -1)
  if [ "$connector_paths" == "" ]
  then
      logwarn "Skipping as it is not an example with connector"
      exit 0
  else
      my_array_connector_tag=($(echo $CONNECTOR_TAG | tr "," "\n"))
      for connector_path in ${connector_paths//,/ }
      do
          full_connector_name=$(basename "$connector_path")
          connector_name=$(echo "$full_connector_name" | cut -d'-' -f2-)

          connectors=(
          "$connector_name"
          )

          output_format="\"🔢 v\" + .version + \" - 📅 release date: \" + .release_date"

          curl -s -S 'https://api.hub.confluent.io/api/plugins?per_page=100000' | jq '. | sort_by(.release_date) | reverse | .' > /tmp/allmanis.json

          connectors_string=""
          delim=""
          for conn in "${connectors[@]}"; do
              connectors_string="$connectors_string$delim\"$conn\""
              delim=","
          done

          latest=$(jq '.[] | select(IN(.name; '"${connectors_string}"')) | '"${output_format}"'' /tmp/allmanis.json)

          rm /tmp/allmanis.json

          DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
          dir1=$(echo ${DIR_CLI%/*})
          root_folder=$(echo ${dir1%/*})

          manifest_file="$root_folder/confluent-hub/$full_connector_name/manifest.json"
          if [ -f $manifest_file ]
          then
              version=$(cat $manifest_file | jq -r '.version')
              release_date=$(cat $manifest_file | jq -r '.release_date')
          else
              logerror "file $manifest_file does not exist"
              exit 1
          fi

          current="\"🔢 v$version - 📅 release date: $release_date\""
          if [ "$current" == "$latest" ]
          then
              log "👻 Version currently used for $full_connector_name is latest"
              echo "$current"
          else
              log "🗯️ Version currently used for $full_connector_name is not latest"
              log "Current"
              echo "$current"
              log "Latest on Hub"
              echo "$latest"
          fi

      done
  fi
}

# :command.function
playground_connector_restart_command() {
  # src/connector_restart_command.sh
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  connector="${args[--connector]}"

  if [[ ! -n "$connector" ]]
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          logerror "💤 No connector is running !"
          exit 1
      fi
  fi

  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  root_folder=$(echo ${dir1%/*})
  IGNORE_CHECK_FOR_DOCKER_COMPOSE=true
  source $root_folder/scripts/utils.sh

  items=($connector)
  for connector in ${items[@]}
  do
      log "🔄 Restarting connector $connector"
      if ! version_gt $TAG_BASE "6.9.9"
      then
          task_ids=$(curl $security -s -X GET "$connect_url/connectors/$connector/tasks" | jq -r '.[].id.task')

          for task_id in $task_ids
          do
              log "🤹‍♂️ Restart task $task_id"
              curl $security -s -X POST -H "Content-Type: application/json" "$connect_url/connectors/$connector/tasks/$task_id/restart"
          done
      else
          curl $security -s -X POST -H "Content-Type: application/json" "$connect_url/connectors/$connector/restart?includeTasks=true&onlyFailed=false" | jq .
      fi
  done
  sleep 3
  playground connector status
}

# :command.function
playground_connector_resume_command() {
  # src/connector_resume_command.sh
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  connector="${args[--connector]}"

  if [[ ! -n "$connector" ]]
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          logerror "💤 No connector is running !"
          exit 1
      fi
  fi

  items=($connector)
  for connector in ${items[@]}
  do
      log "⏯️ Resuming connector $connector"
      curl $security -s -X PUT -H "Content-Type: application/json" "$connect_url/connectors/$connector/resume"  | jq .
  done
  playground connector status
}

# :command.function
playground_connector_delete_command() {
  # src/connector_delete_command.sh
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  connector="${args[--connector]}"

  if [[ ! -n "$connector" ]]
  then
      logwarn "--connector flag was not provided, applying command to all connectors"
      check_if_continue
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          logerror "💤 No connector is running !"
          exit 1
      fi
  fi

  items=($connector)
  for connector in ${items[@]}
  do
      log "❌ Deleting connector $connector"
      curl $security -s -X DELETE "$connect_url/connectors/$connector" | jq .
  done
  playground connector status
}

# :command.function
playground_connector_show_lag_command() {
  # src/connector_show_lag_command.sh
  connector="${args[--connector]}"

  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  if [[ ! -n "$connector" ]]
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          logerror "💤 No connector is running !"
          exit 1
      fi
  fi

  ret=$(get_security_broker "--command-config")

  container=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  items=($connector)
  for connector in ${items[@]}
  do
    type=$(curl -s $security "$connect_url/connectors/$connector/status" | jq -r '.type')
    if [ "$type" != "sink" ]
    then
      logwarn "⏭️ Skipping $type connector $connector, it must be a sink to show the lag"
      continue

    fi

    log "🐢 Show lag for sink connector $connector"
    docker exec $container kafka-consumer-groups --bootstrap-server broker:9092 --group connect-$connector --describe $security
  done
}

# :command.function
playground_connector_log_level_command() {
  # src/connector_log_level_command.sh
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  level="${args[--level]}"
  connector="${args[--connector]}"

  if [[ ! -n "$connector" ]]
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          logerror "💤 No connector is running !"
          exit 1
      fi
  fi

  items=($connector)
  for connector in ${items[@]}
  do
      tmp=$(curl -s $security "$connect_url/connectors/$connector" | jq -r '.config."connector.class"')
      package="${tmp%.*}"
      # log "🧬 Set log level for connector $connector to $level"
      playground log-level set -p "$package" -l $level
  done
}

# :command.parse_requirements
parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --version | -v)
        version_command
        exit
        ;;

      --help | -h)
        long_usage=yes
        playground_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v docker >/dev/null 2>&1; then
    deps['docker']="$(command -v docker | head -n1)"
  else
    printf "missing dependency: docker\n" >&2
    printf "%s\n" "visit $(blue_underlined https://docs.docker.com/get-docker) to install" >&2
    exit 1
  fi

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    get-connector-list)
      action="get-connector-list"
      shift
      playground_get_connector_list_parse_requirements "$@"
      shift $#
      ;;

    get-kafka-region-list)
      action="get-kafka-region-list"
      shift
      playground_get_kafka_region_list_parse_requirements "$@"
      shift $#
      ;;

    get-topic-list)
      action="get-topic-list"
      shift
      playground_get_topic_list_parse_requirements "$@"
      shift $#
      ;;

    get-examples-list-with-fzf)
      action="get-examples-list-with-fzf"
      shift
      playground_get_examples_list_with_fzf_parse_requirements "$@"
      shift $#
      ;;

    get-zip-or-jar-with-fzf)
      action="get-zip-or-jar-with-fzf"
      shift
      playground_get_zip_or_jar_with_fzf_parse_requirements "$@"
      shift $#
      ;;

    get-any-file-with-fzf)
      action="get-any-file-with-fzf"
      shift
      playground_get_any_file_with_fzf_parse_requirements "$@"
      shift $#
      ;;

    bashly-reload)
      action="bashly-reload"
      shift
      playground_bashly_reload_parse_requirements "$@"
      shift $#
      ;;

    run)
      action="run"
      shift
      playground_run_parse_requirements "$@"
      shift $#
      ;;

    re-run)
      action="re-run"
      shift
      playground_re_run_parse_requirements "$@"
      shift $#
      ;;

    run-ccloud)
      action="run-ccloud"
      shift
      playground_run_ccloud_parse_requirements "$@"
      shift $#
      ;;

    open)
      action="open"
      shift
      playground_open_parse_requirements "$@"
      shift $#
      ;;

    stop)
      action="stop"
      shift
      playground_stop_parse_requirements "$@"
      shift $#
      ;;

    bootstrap-reproduction-model)
      action="bootstrap-reproduction-model"
      shift
      playground_bootstrap_reproduction_model_parse_requirements "$@"
      shift $#
      ;;

    get-properties)
      action="get-properties"
      shift
      playground_get_properties_parse_requirements "$@"
      shift $#
      ;;

    get-all-schemas)
      action="get-all-schemas"
      shift
      playground_get_all_schemas_parse_requirements "$@"
      shift $#
      ;;

    enable-remote-debugging)
      action="enable-remote-debugging"
      shift
      playground_enable_remote_debugging_parse_requirements "$@"
      shift $#
      ;;

    log-level)
      action="log-level"
      shift
      playground_log_level_parse_requirements "$@"
      shift $#
      ;;

    get-jmx-metrics)
      action="get-jmx-metrics"
      shift
      playground_get_jmx_metrics_parse_requirements "$@"
      shift $#
      ;;

    container)
      action="container"
      shift
      playground_container_parse_requirements "$@"
      shift $#
      ;;

    topic)
      action="topic"
      shift
      playground_topic_parse_requirements "$@"
      shift $#
      ;;

    connector)
      action="connector"
      shift
      playground_connector_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.user_filter
  filter_error=$(filter_docker_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_get_connector_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_connector_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-connector-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_kafka_region_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_kafka_region_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v confluent >/dev/null 2>&1; then
    deps['confluent']="$(command -v confluent | head -n1)"
  else
    printf "missing dependency: confluent\n" >&2
    printf "%s\n" "visit $(blue_underlined https://docs.confluent.io/confluent-cli/current/overview.html) to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="get-kafka-region-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_topic_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_topic_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-topic-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --skip-connect-internal-topics)

        # :flag.case_no_arg
        args['--skip-connect-internal-topics']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_examples_list_with_fzf_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_examples_list_with_fzf_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-examples-list-with-fzf"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --without-repro)

        # :flag.case_no_arg
        args['--without-repro']=1
        shift
        ;;

      # :flag.case
      --sink-only)

        # :flag.case_no_arg
        args['--sink-only']=1
        shift
        ;;

      # :flag.case
      --ccloud-only)

        # :flag.case_no_arg
        args['--ccloud-only']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        if [[ -z ${args['cur']+x} ]]; then

          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_zip_or_jar_with_fzf_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_zip_or_jar_with_fzf_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-zip-or-jar-with-fzf"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --type)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--type']="$2"
          shift
          shift
        else
          printf "%s\n" "--type requires an argument: --type TYPE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        if [[ -z ${args['cur']+x} ]]; then

          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.whitelist_filter
  if [[ ${args['--type']} ]] && [[ ! ${args['--type']} =~ ^(zip|jar)$ ]]; then
    printf "%s\n" "--type must be one of: zip, jar" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_get_any_file_with_fzf_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_any_file_with_fzf_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-any-file-with-fzf"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        if [[ -z ${args['cur']+x} ]]; then

          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_bashly_reload_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_bashly_reload_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v bashly >/dev/null 2>&1; then
    deps['bashly']="$(command -v bashly | head -n1)"
  else
    printf "missing dependency: bashly\n" >&2
    printf "%s\n" "visit $(blue_underlined https://bashly.dannyb.co/installation/) to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="bashly-reload"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_run_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_run_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v fzf >/dev/null 2>&1; then
    deps['fzf']="$(command -v fzf | head -n1)"
  else
    printf "missing dependency: fzf\n" >&2
    printf "%s\n" "visit $(blue_underlined https://github.com/junegunn/fzf#installation) to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="run"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --file | -f)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--file, -f FILE" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--file']="$2"
          shift
          shift
        else
          printf "%s\n" "--file requires an argument: --file, -f FILE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --open | -o)

        # :flag.case_no_arg
        args['--open']=1
        shift
        ;;

      # :flag.case
      --tag)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_minimal_cp_version "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--tag TAG" "$(validate_minimal_cp_version "$2")" >&2
            exit 1
          fi

          args['--tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--tag requires an argument: --tag TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-tag)
        # :flag.conflicts
        if [[ -n "${args['--connector-zip']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-zip" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector-tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-tag requires an argument: --connector-tag CONNECTOR_TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-zip)
        # :flag.conflicts
        if [[ -n "${args['--connector-tag']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-tag" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--connector-zip CONNECTOR_ZIP" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--connector-zip']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-zip requires an argument: --connector-zip CONNECTOR_ZIP" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-jar)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--connector-jar CONNECTOR_JAR" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--connector-jar']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-jar requires an argument: --connector-jar CONNECTOR_JAR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --enable-ksqldb)

        # :flag.case_no_arg
        args['--enable-ksqldb']=1
        shift
        ;;

      # :flag.case
      --enable-control-center)

        # :flag.case_no_arg
        args['--enable-control-center']=1
        shift
        ;;

      # :flag.case
      --enable-conduktor)

        # :flag.case_no_arg
        args['--enable-conduktor']=1
        shift
        ;;

      # :flag.case
      --enable-multiple-brokers)

        # :flag.case_no_arg
        args['--enable-multiple-brokers']=1
        shift
        ;;

      # :flag.case
      --enable-multiple-connect-workers)

        # :flag.case_no_arg
        args['--enable-multiple-connect-workers']=1
        shift
        ;;

      # :flag.case
      --enable-jmx-grafana)

        # :flag.case_no_arg
        args['--enable-jmx-grafana']=1
        shift
        ;;

      # :flag.case
      --enable-kcat)

        # :flag.case_no_arg
        args['--enable-kcat']=1
        shift
        ;;

      # :flag.case
      --enable-sr-maven-plugin-app)

        # :flag.case_no_arg
        args['--enable-sr-maven-plugin-app']=1
        shift
        ;;

      # :flag.case
      --enable-sql-datagen)

        # :flag.case_no_arg
        args['--enable-sql-datagen']=1
        shift
        ;;

      --)
        shift
        other_args+=("$@")
        break
        ;;

      -?*)
        other_args+=("$1")
        shift
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_catch_all
        other_args+=("$1")
        shift

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--file']+x} ]]; then
    printf "missing required flag: --file, -f FILE\n" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_re_run_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_re_run_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v fzf >/dev/null 2>&1; then
    deps['fzf']="$(command -v fzf | head -n1)"
  else
    printf "missing dependency: fzf\n" >&2
    printf "%s\n" "visit $(blue_underlined https://github.com/junegunn/fzf#installation) to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="re-run"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --tag)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_minimal_cp_version "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--tag TAG" "$(validate_minimal_cp_version "$2")" >&2
            exit 1
          fi

          args['--tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--tag requires an argument: --tag TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-tag)
        # :flag.conflicts
        if [[ -n "${args['--connector-zip']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-zip" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector-tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-tag requires an argument: --connector-tag CONNECTOR_TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-zip)
        # :flag.conflicts
        if [[ -n "${args['--connector-tag']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-tag" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--connector-zip CONNECTOR_ZIP" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--connector-zip']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-zip requires an argument: --connector-zip CONNECTOR_ZIP" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-jar)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--connector-jar CONNECTOR_JAR" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--connector-jar']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-jar requires an argument: --connector-jar CONNECTOR_JAR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --enable-ksqldb)

        # :flag.case_no_arg
        args['--enable-ksqldb']=1
        shift
        ;;

      # :flag.case
      --enable-control-center)

        # :flag.case_no_arg
        args['--enable-control-center']=1
        shift
        ;;

      # :flag.case
      --enable-conduktor)

        # :flag.case_no_arg
        args['--enable-conduktor']=1
        shift
        ;;

      # :flag.case
      --enable-multiple-brokers)

        # :flag.case_no_arg
        args['--enable-multiple-brokers']=1
        shift
        ;;

      # :flag.case
      --enable-multiple-connect-workers)

        # :flag.case_no_arg
        args['--enable-multiple-connect-workers']=1
        shift
        ;;

      # :flag.case
      --enable-jmx-grafana)

        # :flag.case_no_arg
        args['--enable-jmx-grafana']=1
        shift
        ;;

      # :flag.case
      --enable-kcat)

        # :flag.case_no_arg
        args['--enable-kcat']=1
        shift
        ;;

      # :flag.case
      --enable-sr-maven-plugin-app)

        # :flag.case_no_arg
        args['--enable-sr-maven-plugin-app']=1
        shift
        ;;

      # :flag.case
      --enable-sql-datagen)

        # :flag.case_no_arg
        args['--enable-sql-datagen']=1
        shift
        ;;

      --)
        shift
        other_args+=("$@")
        break
        ;;

      -?*)
        other_args+=("$1")
        shift
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_catch_all
        other_args+=("$1")
        shift

        ;;

    esac
  done

}

# :command.parse_requirements
playground_run_ccloud_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_run_ccloud_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v fzf >/dev/null 2>&1; then
    deps['fzf']="$(command -v fzf | head -n1)"
  else
    printf "missing dependency: fzf\n" >&2
    printf "%s\n" "visit $(blue_underlined https://github.com/junegunn/fzf#installation) to install" >&2
    exit 1
  fi

  if command -v confluent >/dev/null 2>&1; then
    deps['confluent']="$(command -v confluent | head -n1)"
  else
    printf "missing dependency: confluent\n" >&2
    printf "%s\n" "visit $(blue_underlined https://docs.confluent.io/confluent-cli/current/overview.html) to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="run-ccloud"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --file | -f)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--file, -f FILE" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--file']="$2"
          shift
          shift
        else
          printf "%s\n" "--file requires an argument: --file, -f FILE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --open | -o)

        # :flag.case_no_arg
        args['--open']=1
        shift
        ;;

      # :flag.case
      --tag)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_minimal_cp_version "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--tag TAG" "$(validate_minimal_cp_version "$2")" >&2
            exit 1
          fi

          args['--tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--tag requires an argument: --tag TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-tag)
        # :flag.conflicts
        if [[ -n "${args['--connector-zip']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-zip" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector-tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-tag requires an argument: --connector-tag CONNECTOR_TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-zip)
        # :flag.conflicts
        if [[ -n "${args['--connector-tag']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-tag" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--connector-zip CONNECTOR_ZIP" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--connector-zip']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-zip requires an argument: --connector-zip CONNECTOR_ZIP" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-jar)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--connector-jar CONNECTOR_JAR" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--connector-jar']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-jar requires an argument: --connector-jar CONNECTOR_JAR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --enable-control-center)

        # :flag.case_no_arg
        args['--enable-control-center']=1
        shift
        ;;

      # :flag.case
      --enable-conduktor)

        # :flag.case_no_arg
        args['--enable-conduktor']=1
        shift
        ;;

      # :flag.case
      --enable-kcat)

        # :flag.case_no_arg
        args['--enable-kcat']=1
        shift
        ;;

      # :flag.case
      --cluster-cloud)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--cluster-cloud']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-cloud requires an argument: --cluster-cloud CLUSTER-CLOUD" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-region)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--cluster-region']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-region requires an argument: --cluster-region CLUSTER-REGION" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-environment)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--cluster-environment CLUSTER-ENVIRONMENT" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--cluster-environment']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-environment requires an argument: --cluster-environment CLUSTER-ENVIRONMENT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-name)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--cluster-name CLUSTER-NAME" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--cluster-name']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-name requires an argument: --cluster-name CLUSTER-NAME" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-creds)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--cluster-creds CLUSTER-CREDS" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--cluster-creds']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-creds requires an argument: --cluster-creds CLUSTER-CREDS" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-schema-registry-creds)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--cluster-schema-registry-creds CLUSTER-SCHEMA-REGISTRY-CREDS" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--cluster-schema-registry-creds']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-schema-registry-creds requires an argument: --cluster-schema-registry-creds CLUSTER-SCHEMA-REGISTRY-CREDS" >&2
          exit 1
        fi
        ;;

      --)
        shift
        other_args+=("$@")
        break
        ;;

      -?*)
        other_args+=("$1")
        shift
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_catch_all
        other_args+=("$1")
        shift

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--file']+x} ]]; then
    printf "missing required flag: --file, -f FILE\n" >&2
    exit 1
  fi

  # :command.whitelist_filter
  if [[ ${args['--cluster-cloud']} ]] && [[ ! ${args['--cluster-cloud']} =~ ^(aws|gcp|azure)$ ]]; then
    printf "%s\n" "--cluster-cloud must be one of: aws, gcp, azure" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_open_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_open_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v fzf >/dev/null 2>&1; then
    deps['fzf']="$(command -v fzf | head -n1)"
  else
    printf "missing dependency: fzf\n" >&2
    printf "%s\n" "visit $(blue_underlined https://github.com/junegunn/fzf#installation) to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="open"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --file | -f)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--file, -f FILE" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--file']="$2"
          shift
          shift
        else
          printf "%s\n" "--file requires an argument: --file, -f FILE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_stop_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_stop_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="stop"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_bootstrap_reproduction_model_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_bootstrap_reproduction_model_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.environment_variables_filter
  # :command.environment_variables_default
  export OUTPUT_FOLDER="${OUTPUT_FOLDER:-reproduction-models}"

  # :command.dependencies_filter
  if command -v fzf >/dev/null 2>&1; then
    deps['fzf']="$(command -v fzf | head -n1)"
  else
    printf "missing dependency: fzf\n" >&2
    printf "%s\n" "visit $(blue_underlined https://github.com/junegunn/fzf#installation) to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="bootstrap-reproduction-model"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --tag)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_minimal_cp_version "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--tag TAG" "$(validate_minimal_cp_version "$2")" >&2
            exit 1
          fi

          args['--tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--tag requires an argument: --tag TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-tag)
        # :flag.conflicts
        if [[ -n "${args['--connector-zip']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-zip" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector-tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-tag requires an argument: --connector-tag CONNECTOR_TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-zip)
        # :flag.conflicts
        if [[ -n "${args['--connector-tag']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-tag" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--connector-zip CONNECTOR_ZIP" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--connector-zip']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-zip requires an argument: --connector-zip CONNECTOR_ZIP" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-jar)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--connector-jar CONNECTOR_JAR" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--connector-jar']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-jar requires an argument: --connector-jar CONNECTOR_JAR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --enable-ksqldb)

        # :flag.case_no_arg
        args['--enable-ksqldb']=1
        shift
        ;;

      # :flag.case
      --enable-control-center)

        # :flag.case_no_arg
        args['--enable-control-center']=1
        shift
        ;;

      # :flag.case
      --enable-conduktor)

        # :flag.case_no_arg
        args['--enable-conduktor']=1
        shift
        ;;

      # :flag.case
      --enable-multiple-brokers)

        # :flag.case_no_arg
        args['--enable-multiple-brokers']=1
        shift
        ;;

      # :flag.case
      --enable-multiple-connect-workers)

        # :flag.case_no_arg
        args['--enable-multiple-connect-workers']=1
        shift
        ;;

      # :flag.case
      --enable-jmx-grafana)

        # :flag.case_no_arg
        args['--enable-jmx-grafana']=1
        shift
        ;;

      # :flag.case
      --enable-kcat)

        # :flag.case_no_arg
        args['--enable-kcat']=1
        shift
        ;;

      # :flag.case
      --enable-sr-maven-plugin-app)

        # :flag.case_no_arg
        args['--enable-sr-maven-plugin-app']=1
        shift
        ;;

      # :flag.case
      --enable-sql-datagen)

        # :flag.case_no_arg
        args['--enable-sql-datagen']=1
        shift
        ;;

      # :flag.case
      --cluster-region)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--cluster-region']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-region requires an argument: --cluster-region CLUSTER-REGION" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-environment)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--cluster-environment CLUSTER-ENVIRONMENT" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--cluster-environment']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-environment requires an argument: --cluster-environment CLUSTER-ENVIRONMENT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-name)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--cluster-name CLUSTER-NAME" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--cluster-name']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-name requires an argument: --cluster-name CLUSTER-NAME" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-creds)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--cluster-creds CLUSTER-CREDS" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--cluster-creds']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-creds requires an argument: --cluster-creds CLUSTER-CREDS" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-schema-registry-creds)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--cluster-schema-registry-creds CLUSTER-SCHEMA-REGISTRY-CREDS" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--cluster-schema-registry-creds']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-schema-registry-creds requires an argument: --cluster-schema-registry-creds CLUSTER-SCHEMA-REGISTRY-CREDS" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --file | -f)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--file, -f FILE" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--file']="$2"
          shift
          shift
        else
          printf "%s\n" "--file requires an argument: --file, -f FILE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --description | -d)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--description, -d DESCRIPTION" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--description']="$2"
          shift
          shift
        else
          printf "%s\n" "--description requires an argument: --description, -d DESCRIPTION" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --producer | -p)
        # :flag.conflicts
        if [[ -n "${args['--pipeline']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--pipeline" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--producer']="$2"
          shift
          shift
        else
          printf "%s\n" "--producer requires an argument: --producer, -p PRODUCER-TYPE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --nb-producers | -n)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_integer "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--nb-producers, -n NB-PRODUCERS" "$(validate_integer "$2")" >&2
            exit 1
          fi

          args['--nb-producers']="$2"
          shift
          shift
        else
          printf "%s\n" "--nb-producers requires an argument: --nb-producers, -n NB-PRODUCERS" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --producer-schema-key)

        # :flag.case_no_arg
        args['--producer-schema-key']=1
        shift
        ;;

      # :flag.case
      --producer-schema-value)

        # :flag.case_no_arg
        args['--producer-schema-value']=1
        shift
        ;;

      # :flag.case
      --custom-smt)

        # :flag.case_no_arg
        args['--custom-smt']=1
        shift
        ;;

      # :flag.case
      --pipeline)
        # :flag.conflicts
        if [[ -n "${args['--producer']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--producer" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--pipeline SINK_FILE" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--pipeline']="$2"
          shift
          shift
        else
          printf "%s\n" "--pipeline requires an argument: --pipeline SINK_FILE" >&2
          exit 1
        fi
        ;;

      --)
        shift
        other_args+=("$@")
        break
        ;;

      -?*)
        other_args+=("$1")
        shift
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_catch_all
        other_args+=("$1")
        shift

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--file']+x} ]]; then
    printf "missing required flag: --file, -f FILE\n" >&2
    exit 1
  fi
  if [[ -z ${args['--description']+x} ]]; then
    printf "missing required flag: --description, -d DESCRIPTION\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['--producer']:-} ]] || args['--producer']="none"
  [[ -n ${args['--nb-producers']:-} ]] || args['--nb-producers']=""

  # :command.whitelist_filter
  if [[ ${args['--producer']} ]] && [[ ! ${args['--producer']} =~ ^(none|avro|avro-with-key|protobuf|protobuf-with-key|json-schema|json-schema-with-key)$ ]]; then
    printf "%s\n" "--producer must be one of: none, avro, avro-with-key, protobuf, protobuf-with-key, json-schema, json-schema-with-key" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_get_properties_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_properties_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-properties"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_get_all_schemas_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_all_schemas_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-all-schemas"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --open | -o)

        # :flag.case_no_arg
        args['--open']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.user_filter
  filter_error=$(filter_not_mdc_environment)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_enable_remote_debugging_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_enable_remote_debugging_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="enable-remote-debugging"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_log_level_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_log_level_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    get)
      action="get"
      shift
      playground_log_level_get_parse_requirements "$@"
      shift $#
      ;;

    set)
      action="set"
      shift
      playground_log_level_set_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_log_level_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.user_filter
  filter_error=$(filter_connect_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_log_level_get_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_log_level_get_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="log-level get"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --package | -p)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--package, -p PACKAGE" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--package']="$2"
          shift
          shift
        else
          printf "%s\n" "--package requires an argument: --package, -p PACKAGE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_log_level_set_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_log_level_set_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="log-level set"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --package | -p)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--package, -p PACKAGE" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--package']="$2"
          shift
          shift
        else
          printf "%s\n" "--package requires an argument: --package, -p PACKAGE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --level | -l)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--level']="$2"
          shift
          shift
        else
          printf "%s\n" "--level requires an argument: --level, -l LEVEL" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--package']+x} ]]; then
    printf "missing required flag: --package, -p PACKAGE\n" >&2
    exit 1
  fi
  if [[ -z ${args['--level']+x} ]]; then
    printf "missing required flag: --level, -l LEVEL\n" >&2
    exit 1
  fi

  # :command.whitelist_filter
  if [[ ${args['--level']} ]] && [[ ! ${args['--level']} =~ ^(INFO|WARN|DEBUG|TRACE)$ ]]; then
    printf "%s\n" "--level must be one of: INFO, WARN, DEBUG, TRACE" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_get_jmx_metrics_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_jmx_metrics_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v java >/dev/null 2>&1; then
    deps['java']="$(command -v java | head -n1)"
  else
    printf "missing dependency: java\n" >&2
    printf "%s\n" "visit $(blue_underlined https://openjdk.org/install/) to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="get-jmx-metrics"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --component | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--component']="$2"
          shift
          shift
        else
          printf "%s\n" "--component requires an argument: --component, -c COMPONENT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --domain | -d)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--domain']="$2"
          shift
          shift
        else
          printf "%s\n" "--domain requires an argument: --domain, -d DOMAIN" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--component']:-} ]] || args['--component']="connect"

  # :command.whitelist_filter
  if [[ ${args['--component']} ]] && [[ ! ${args['--component']} =~ ^(zookeeper|broker|connect|schema-registry)$ ]]; then
    printf "%s\n" "--component must be one of: zookeeper, broker, connect, schema-registry" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_container_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    recreate)
      action="recreate"
      shift
      playground_container_recreate_parse_requirements "$@"
      shift $#
      ;;

    get-ip-addresses)
      action="get-ip-addresses"
      shift
      playground_container_get_ip_addresses_parse_requirements "$@"
      shift $#
      ;;

    kill-all)
      action="kill-all"
      shift
      playground_container_kill_all_parse_requirements "$@"
      shift $#
      ;;

    logs)
      action="logs"
      shift
      playground_container_logs_parse_requirements "$@"
      shift $#
      ;;

    ssh)
      action="ssh"
      shift
      playground_container_ssh_parse_requirements "$@"
      shift $#
      ;;

    exec)
      action="exec"
      shift
      playground_container_exec_parse_requirements "$@"
      shift $#
      ;;

    restart)
      action="restart"
      shift
      playground_container_restart_parse_requirements "$@"
      shift $#
      ;;

    pause)
      action="pause"
      shift
      playground_container_pause_parse_requirements "$@"
      shift $#
      ;;

    resume)
      action="resume"
      shift
      playground_container_resume_parse_requirements "$@"
      shift $#
      ;;

    kill)
      action="kill"
      shift
      playground_container_kill_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_container_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_container_recreate_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_recreate_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container recreate"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_container_get_ip_addresses_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_get_ip_addresses_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container get-ip-addresses"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_container_kill_all_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_kill_all_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container kill-all"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_container_logs_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_logs_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container logs"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --open | -o)
        # :flag.conflicts
        if [[ -n "${args['--wait-for-log']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--wait-for-log" >&2
          exit 1
        fi

        # :flag.case_no_arg
        args['--open']=1
        shift
        ;;

      # :flag.case
      --wait-for-log | -w)
        # :flag.conflicts
        if [[ -n "${args['--open']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--open" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--wait-for-log, -w LOG" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--wait-for-log']="$2"
          shift
          shift
        else
          printf "%s\n" "--wait-for-log requires an argument: --wait-for-log, -w LOG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --max-wait | -m)
        # :flag.conflicts
        if [[ -n "${args['--open']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--open" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_integer "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--max-wait, -m MAX_WAIT" "$(validate_integer "$2")" >&2
            exit 1
          fi

          args['--max-wait']="$2"
          shift
          shift
        else
          printf "%s\n" "--max-wait requires an argument: --max-wait, -m MAX_WAIT" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"
  [[ -n ${args['--max-wait']:-} ]] || args['--max-wait']="600"

}

# :command.parse_requirements
playground_container_ssh_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_ssh_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container ssh"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --shell | -s)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--shell']="$2"
          shift
          shift
        else
          printf "%s\n" "--shell requires an argument: --shell, -s SHELL" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"
  [[ -n ${args['--shell']:-} ]] || args['--shell']="bash"

  # :command.whitelist_filter
  if [[ ${args['--shell']} ]] && [[ ! ${args['--shell']} =~ ^(bash|sh|ksh|zsh)$ ]]; then
    printf "%s\n" "--shell must be one of: bash, sh, ksh, zsh" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_container_exec_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_exec_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container exec"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --command)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--command COMMAND" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--command']="$2"
          shift
          shift
        else
          printf "%s\n" "--command requires an argument: --command COMMAND" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --root)

        # :flag.case_no_arg
        args['--root']=1
        shift
        ;;

      # :flag.case
      --shell)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--shell']="$2"
          shift
          shift
        else
          printf "%s\n" "--shell requires an argument: --shell SHELL" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--command']+x} ]]; then
    printf "missing required flag: --command COMMAND\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"
  [[ -n ${args['--shell']:-} ]] || args['--shell']="bash"

  # :command.whitelist_filter
  if [[ ${args['--shell']} ]] && [[ ! ${args['--shell']} =~ ^(bash|sh|ksh|zsh)$ ]]; then
    printf "%s\n" "--shell must be one of: bash, sh, ksh, zsh" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_container_restart_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_restart_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container restart"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_container_pause_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_pause_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container pause"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_container_resume_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_resume_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container resume"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_container_kill_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_kill_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container kill"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_topic_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    get-number-records)
      action="get-number-records"
      shift
      playground_topic_get_number_records_parse_requirements "$@"
      shift $#
      ;;

    display-consumer-offsets)
      action="display-consumer-offsets"
      shift
      playground_topic_display_consumer_offsets_parse_requirements "$@"
      shift $#
      ;;

    describe)
      action="describe"
      shift
      playground_topic_describe_parse_requirements "$@"
      shift $#
      ;;

    consume)
      action="consume"
      shift
      playground_topic_consume_parse_requirements "$@"
      shift $#
      ;;

    set-schema-compatibility)
      action="set-schema-compatibility"
      shift
      playground_topic_set_schema_compatibility_parse_requirements "$@"
      shift $#
      ;;

    display-schema-id-statistics)
      action="display-schema-id-statistics"
      shift
      playground_topic_display_schema_id_statistics_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_topic_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.user_filter
  filter_error=$(filter_not_mdc_environment)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_topic_get_number_records_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_get_number_records_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic get-number-records"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_topic_display_consumer_offsets_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_display_consumer_offsets_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic display-consumer-offsets"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_topic_describe_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_describe_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic describe"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_topic_consume_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_consume_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic consume"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --max-messages)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_integer "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--max-messages MAX-MESSAGES" "$(validate_integer "$2")" >&2
            exit 1
          fi

          args['--max-messages']="$2"
          shift
          shift
        else
          printf "%s\n" "--max-messages requires an argument: --max-messages MAX-MESSAGES" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --min-expected-messages)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_integer "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--min-expected-messages MIN-EXPECTED-MESSAGES" "$(validate_integer "$2")" >&2
            exit 1
          fi

          args['--min-expected-messages']="$2"
          shift
          shift
        else
          printf "%s\n" "--min-expected-messages requires an argument: --min-expected-messages MIN-EXPECTED-MESSAGES" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --grep)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--grep']="$2"
          shift
          shift
        else
          printf "%s\n" "--grep requires an argument: --grep GREP" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--max-messages']:-} ]] || args['--max-messages']=""
  [[ -n ${args['--min-expected-messages']:-} ]] || args['--min-expected-messages']=""
  [[ -n ${args['--grep']:-} ]] || args['--grep']=""

  # :command.user_filter
  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_topic_set_schema_compatibility_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_set_schema_compatibility_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic set-schema-compatibility"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --compatibility)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--compatibility']="$2"
          shift
          shift
        else
          printf "%s\n" "--compatibility requires an argument: --compatibility COMPATIBILITY" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--compatibility']+x} ]]; then
    printf "missing required flag: --compatibility COMPATIBILITY\n" >&2
    exit 1
  fi

  # :command.whitelist_filter
  if [[ ${args['--compatibility']} ]] && [[ ! ${args['--compatibility']} =~ ^(BACKWARD|BACKWARD_TRANSITIVE|FORWARD|FORWARD_TRANSITIVE|FULL|FULL_TRANSITIVE|NONE)$ ]]; then
    printf "%s\n" "--compatibility must be one of: BACKWARD, BACKWARD_TRANSITIVE, FORWARD, FORWARD_TRANSITIVE, FULL, FULL_TRANSITIVE, NONE" >&2
    exit 1
  fi

  # :command.user_filter
  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_topic_display_schema_id_statistics_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_display_schema_id_statistics_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic display-schema-id-statistics"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    status)
      action="status"
      shift
      playground_connector_status_parse_requirements "$@"
      shift $#
      ;;

    plugins)
      action="plugins"
      shift
      playground_connector_plugins_parse_requirements "$@"
      shift $#
      ;;

    pause)
      action="pause"
      shift
      playground_connector_pause_parse_requirements "$@"
      shift $#
      ;;

    versions)
      action="versions"
      shift
      playground_connector_versions_parse_requirements "$@"
      shift $#
      ;;

    restart)
      action="restart"
      shift
      playground_connector_restart_parse_requirements "$@"
      shift $#
      ;;

    resume)
      action="resume"
      shift
      playground_connector_resume_parse_requirements "$@"
      shift $#
      ;;

    delete)
      action="delete"
      shift
      playground_connector_delete_parse_requirements "$@"
      shift $#
      ;;

    show-lag)
      action="show-lag"
      shift
      playground_connector_show_lag_parse_requirements "$@"
      shift $#
      ;;

    log-level)
      action="log-level"
      shift
      playground_connector_log_level_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_connector_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.user_filter
  filter_error=$(filter_not_mdc_environment)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

  filter_error=$(filter_connect_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_connector_status_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_status_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector status"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_plugins_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_plugins_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector plugins"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_pause_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_pause_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector pause"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_versions_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_versions_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector versions"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_restart_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_restart_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector restart"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_resume_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_resume_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector resume"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_delete_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_delete_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector delete"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_show_lag_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_show_lag_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector show-lag"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_log_level_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_log_level_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector log-level"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --level | -l)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--level']="$2"
          shift
          shift
        else
          printf "%s\n" "--level requires an argument: --level, -l LEVEL" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--level']+x} ]]; then
    printf "missing required flag: --level, -l LEVEL\n" >&2
    exit 1
  fi

  # :command.whitelist_filter
  if [[ ${args['--level']} ]] && [[ ! ${args['--level']} =~ ^(INFO|WARN|DEBUG|TRACE)$ ]]; then
    printf "%s\n" "--level must be one of: INFO, WARN, DEBUG, TRACE" >&2
    exit 1
  fi

}

# :command.initialize
initialize() {
  version="1.0.0"
  long_usage=''
  set -e

  # src/initialize.sh

}

# :command.run
run() {
  declare -A args=()
  declare -A deps=()
  declare -a other_args=()
  declare -a input=()
  normalize_input "$@"
  parse_requirements "${input[@]}"

  case "$action" in
    "get-connector-list") playground_get_connector_list_command ;;
    "get-kafka-region-list") playground_get_kafka_region_list_command ;;
    "get-topic-list") playground_get_topic_list_command ;;
    "get-examples-list-with-fzf") playground_get_examples_list_with_fzf_command ;;
    "get-zip-or-jar-with-fzf") playground_get_zip_or_jar_with_fzf_command ;;
    "get-any-file-with-fzf") playground_get_any_file_with_fzf_command ;;
    "bashly-reload") playground_bashly_reload_command ;;
    "run") playground_run_command ;;
    "re-run") playground_re_run_command ;;
    "run-ccloud") playground_run_ccloud_command ;;
    "open") playground_open_command ;;
    "stop") playground_stop_command ;;
    "bootstrap-reproduction-model") playground_bootstrap_reproduction_model_command ;;
    "get-properties") playground_get_properties_command ;;
    "get-all-schemas") playground_get_all_schemas_command ;;
    "enable-remote-debugging") playground_enable_remote_debugging_command ;;
    "log-level") playground_log_level_command ;;
    "log-level get") playground_log_level_get_command ;;
    "log-level set") playground_log_level_set_command ;;
    "get-jmx-metrics") playground_get_jmx_metrics_command ;;
    "container") playground_container_command ;;
    "container recreate") playground_container_recreate_command ;;
    "container get-ip-addresses") playground_container_get_ip_addresses_command ;;
    "container kill-all") playground_container_kill_all_command ;;
    "container logs") playground_container_logs_command ;;
    "container ssh") playground_container_ssh_command ;;
    "container exec") playground_container_exec_command ;;
    "container restart") playground_container_restart_command ;;
    "container pause") playground_container_pause_command ;;
    "container resume") playground_container_resume_command ;;
    "container kill") playground_container_kill_command ;;
    "topic") playground_topic_command ;;
    "topic get-number-records") playground_topic_get_number_records_command ;;
    "topic display-consumer-offsets") playground_topic_display_consumer_offsets_command ;;
    "topic describe") playground_topic_describe_command ;;
    "topic consume") playground_topic_consume_command ;;
    "topic set-schema-compatibility") playground_topic_set_schema_compatibility_command ;;
    "topic display-schema-id-statistics") playground_topic_display_schema_id_statistics_command ;;
    "connector") playground_connector_command ;;
    "connector status") playground_connector_status_command ;;
    "connector plugins") playground_connector_plugins_command ;;
    "connector pause") playground_connector_pause_command ;;
    "connector versions") playground_connector_versions_command ;;
    "connector restart") playground_connector_restart_command ;;
    "connector resume") playground_connector_resume_command ;;
    "connector delete") playground_connector_delete_command ;;
    "connector show-lag") playground_connector_show_lag_command ;;
    "connector log-level") playground_connector_log_level_command ;;
  esac
}

initialize
run "$@"
