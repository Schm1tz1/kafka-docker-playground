name: playground
version: 1.0.0
dependencies:
  docker: visit $(blue_underlined https://docs.docker.com/get-docker) to install
help: |-
  🧠 CLI for Kafka Docker Playground 🐳

  👉 Check documentation https://kafka-docker-playground.io/#/cli
filters:
- docker_running
commands:

### private commands for completion
- name: get-connector-list
  help: Return some completion for connector list
  private: true

- name: get-ccloud-connector-list
  help: Return some completion for ccloud connector list
  private: true
  dependencies:
    confluent: visit $(blue_underlined https://docs.confluent.io/confluent-cli/current/overview.html) to install

- name: get-kafka-region-list
  help: Return some completion for confluent cloud kafka cluster region list
  private: true
  dependencies:
    confluent: visit $(blue_underlined https://docs.confluent.io/confluent-cli/current/overview.html) to install

- name: get-topic-list
  help: Return some completion for topic list
  private: true
  flags:
  - long: --skip-connect-internal-topics
    required: false

- name: get-examples-list-with-fzf
  help: Return some completion for examples list
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur
  flags:
  - long: --without-repro
    required: false
  - long: --sink-only
    required: false
  - long: --ccloud-only
    required: false

- name: get-zip-or-jar-with-fzf
  help: Return some completion for zip or jar list
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur
  flags:
  - long: --type
    required: false
    arg: type
    allowed: [zip, jar]

- name: get-any-file-with-fzf
  help: Return some completion for any files
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur

- name: get-predefined-schemas
  help: Return some completion for predefined schemas
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur

- name: bashly-reload
  private: true
  dependencies:
    bashly: visit $(blue_underlined https://bashly.dannyb.co/installation/) to install

- name: run
  group: Run
  catch_all:
    label: arguments
    help: |-
      Arguments to use by example script

      Most of examples support to get required options either by using arguments or environment variables.
      
      Example with Zendesk:

      playground run -f zendesk-source<tab> <ZENDESK_URL> <ZENDESK_USERNAME> <ZENDESK_PASSWORD>
    required: false
  dependencies:
    fzf: visit $(blue_underlined https://github.com/junegunn/fzf#installation) to install
  help: |-
    🕹️ Run any example, except for Confluent Cloud (in this case use run-ccloud command)

  flags:
  - long: --file
    short: -f
    required: true
    validate: file_exists_with_trick
    arg: file
    completions:
      - $(playground get-examples-list-with-fzf "$cur")
    help: |-
      🔖 Example file to run

      ❕ It must be absolute full path

      🎓 Tip: use <tab> completion to trigger fzf completion
  - long: --open
    short: -o
    help: 📖 Opening example file with text editor set with config.ini (default is code)
  - &tag
    long: --tag
    arg: tag
    required: false
    validate: minimal_cp_version
    help: |-
      🎯 Confluent Platform (CP) version to use

      Must be greater or equal to 5.0.0
  - &connector-tag
    long: --connector-tag
    arg: connector_tag
    required: false
    help: |- 
      🔗 Connector version to use

      By default, for each connector, the latest available version on Confluent Hub is used
    conflicts: [--connector-zip]
  - &connector-zip
    long: --connector-zip
    arg: connector_zip
    required: false
    validate: file_exists_with_trick
    completions:
      - $(playground get-zip-or-jar-with-fzf --type zip "$cur")
    conflicts: [--connector-tag]
    help: |- 
      🤐 Connector zip to use

      ❕ It must be absolute full path

      🎓 Tip: use <tab> completion to trigger fzf completion 
              use folder_zip_or_jar (default: ~/Downloads) in config.ini file to configure where to search the files (current folder is always used)

  - &connector-jar
    long: --connector-jar
    arg: connector_jar
    required: false
    validate: file_exists_with_trick
    completions:
      - $(playground get-zip-or-jar-with-fzf --type jar "$cur")
    help: |-
      ♨️ Connector jar to use

      ❕ It must be absolute full path

      🎓 Tip: use <tab> completion to trigger fzf completion 
              use folder_zip_or_jar (default: ~/Downloads) in config.ini file to configure where to search the files (current folder is always used)

  - &enable-ksqldb
    long: --enable-ksqldb
    required: false
    help: |-
      🚀 Enable ksqlDB

      By default, ksqldb-server and ksqldb-cli containers are not started for every test
  - &enable-control-center
    long: --enable-control-center
    required: false
    help: |-
      💠 Enable Control Center

      By default, control-center container is not started for every test

      Control Center is reachable at http://127.0.0.1:9021
  - &enable-conduktor
    long: --enable-conduktor
    required: false
    help: |- 
      🐺 Enable Conduktor Platform

      By default, Conduktor Platform container is not started for every test

      Conduktor is reachable at http://127.0.0.1:8080/console (admin/admin)
  - &enable-multiple-brokers
    long: --enable-multiple-brokers
    required: false
    help: |- 
      3️⃣ Enable multiple brokers

      By default, there is only one broker node enabled
  - &enable-multiple-connect-workers
    long: --enable-multiple-connect-workers
    required: false
    help: |-
      🥉 Enable multiple connect node

      By default, there is only one connect node enabled

      It only works when plaintext environment is used
  - &enable-jmx-grafana
    long: --enable-jmx-grafana
    required: false
    help: |-
      Enable Grafana, Prometheus and Pyroscope

      📊 Grafana is reachable at http://127.0.0.1:3000
      🛡️ Prometheus is reachable at http://127.0.0.1:9090
      📛 Pyroscope is reachable at http://127.0.0.1:4040
  - &enable-kcat
    long: --enable-kcat
    required: false
    help: |-
      🐈‍⬛ Enable kcat

      You can use it with:

      $ docker exec kcat kcat -b broker:9092 -L
  - &enable-sr-maven-plugin-app
    long: --enable-sr-maven-plugin-app
    required: false
    help: |- 
      🔰 Enable Schema Registry Maven plugin App
  - &enable-sql-datagen
    long: --enable-sql-datagen
    required: false
    help: |-
      🌪️ Enable SQL Datagen injection

      This only works for Oracle, MySql, Postgres and Microsoft Sql Server source connector examples with JDBC and Debezium
  examples:
  - playground run -f zendesk-source<tab> --tag 7.2.1 --enable-control-center <ZENDESK_URL> <ZENDESK_USERNAME> <ZENDESK_PASSWORD>
  - playground run -f jdbc<tab> --connector-tag 10.6.0 --enable-jmx-grafana --open

- name: re-run
  group: Run
  help: |-
    ⚡ Simply re-run last example you ran with <playground run> or <playground run-ccloud>
  catch_all:
    label: arguments
    help: |-
      Arguments to use by example script

      Most of examples support to get required options either by using arguments or environment variables.
      
      Example with Zendesk:

      playground run -f zendesk-source<tab> <ZENDESK_URL> <ZENDESK_USERNAME> <ZENDESK_PASSWORD>
    required: false
  dependencies:
    fzf: visit $(blue_underlined https://github.com/junegunn/fzf#installation) to install
  flags:
    - long: --clear
      required: false
      help: |- 
        🧼 Clear any previous flags
    - *tag
    - *connector-tag
    - *connector-zip
    - *connector-jar
    - *enable-ksqldb
    - *enable-control-center
    - *enable-conduktor
    - *enable-multiple-brokers
    - *enable-multiple-connect-workers
    - *enable-jmx-grafana
    - *enable-kcat
    - *enable-sr-maven-plugin-app
    - *enable-sql-datagen
  examples:
  - playground re-run
  - playground re-run --tag=6.2.1

- name: run-ccloud
  group: Run
  catch_all:
    label: arguments
    help: |-
      Arguments to use by example script

      Most of examples support to get required options either by using arguments or environment variables.
      
      Example with Zendesk:

      playground run -f zendesk-source<tab> <ZENDESK_URL> <ZENDESK_USERNAME> <ZENDESK_PASSWORD>
    required: false
  dependencies:
    fzf: visit $(blue_underlined https://github.com/junegunn/fzf#installation) to install
    confluent: visit $(blue_underlined https://docs.confluent.io/confluent-cli/current/overview.html) to install
  help: |-
    ⛅ Run any Confluent Cloud (ccloud) example

    All you have to do is to be already logged in with confluent CLI.

    By default, a new Confluent Cloud environment with a Cluster will be created.

    You can configure the new cluster by setting:

    --cluster-cloud (or CLUSTER_CLOUD environment variable)
    --cluster-region (or CLUSTER_REGION environment variable)
    --cluster-environment (or ENVIRONMENT environment variable)

    In case you want to use your own existing cluster, you need to setup, in addition to previous ones:

    --cluster-name (or CLUSTER_NAME environment variable)
    --cluster-creds (or CLUSTER_CREDS environment variable)
    --cluster-schema-registry-creds (or SCHEMA_REGISTRY_CREDS environment variable)
    
  flags:
    - long: --file
      short: -f
      required: true
      validate: file_exists_with_trick
      arg: file
      completions:
        - $(playground get-examples-list-with-fzf --ccloud-only "$cur")
      help: |-
        🔖 Example file to run

        ❕ It must be absolute full path

        🎓 Tip: use <tab> completion to trigger fzf completion
    - long: --open
      short: -o
      help: 📖 Opening example file with text editor set with config.ini (default is code)
    - *tag
    - *connector-tag
    - *connector-zip
    - *connector-jar
    - *enable-control-center
    - *enable-conduktor
    - *enable-kcat
    - &cluster-cloud
      long: --cluster-cloud
      required: false
      arg: cluster-cloud
      allowed: [aws, gcp, azure]
      help: |-
        🌤 The cloud provider: aws, gcp or azure. Default is aws

        🎓 Tip: you can also use CLUSTER_CLOUD environment variable
    - &cluster-region
      long: --cluster-region
      required: false
      arg: cluster-region
      completions:
        - $(playground get-kafka-region-list)
      help: |-
        🗺 The Cloud region. 
        
        🎓 Tip: you can also use CLUSTER_REGION environment variable
    - &cluster-environment
      long: --cluster-environment
      required: false
      arg: cluster-environment
      validate: not_empty
      help: |-
        🌐 The environment id where want your new cluster (example: env-xxxxx)

        ℹ️ Optional, if not set, new environment will be created

        🎓 Tip: you can also use ENVIRONMENT environment variable
    - &cluster-name
      long: --cluster-name
      required: false
      validate: not_empty
      arg: cluster-name
      help: |-
        🎰 The cluster name. 
        
        ❣️ Only required if you want to use your own existing cluster

        🎓 Tip: you can also use CLUSTER_NAME environment variable
    - &cluster-creds
      long: --cluster-creds
      required: false
      validate: not_empty
      arg: cluster-creds
      help: |-
        🔒 The Kafka api key and secret to use, it should be separated with semi-colon (example: <API_KEY>:<API_KEY_SECRET>)

        ❣️ Only required if you want to use your own existing cluster

        🎓 Tip: you can also use CLUSTER_CREDS environment variable
    - &cluster-schema-registry-creds
      long: --cluster-schema-registry-creds
      required: false
      validate: not_empty
      arg: cluster-schema-registry-creds
      help: |-
        🔒 The Schema Registry api key and secret to use, it should be separated with semi-colon (example: <SR_API_KEY>:<SR_API_KEY_SECRET>)

        ℹ️ Optional, if not set, new credentials will be created

        ❣️ Only required if you want to use your own existing cluster
        
        🎓 Tip: you can also use SCHEMA_REGISTRY_CREDS environment variable
  examples:
  - playground run-ccloud mqtt<tab> --cluster-cloud aws --cluster-region eu-west-3 --enable-control-center --connector-tag 1.2.3

- name: open
  group: Run
  dependencies:
    fzf: visit $(blue_underlined https://github.com/junegunn/fzf#installation) to install
  help: |-
    👐 When --file is not provided, simply open last example you ran with <playground run> or <playground run-ccloud>

    Otherwise, open any file from the playground using --file.
  flags:
  - long: --file
    short: -f
    required: false
    validate: file_exists_with_trick
    arg: file
    completions:
      - $(playground get-any-file-with-fzf "$cur")
    help: |-
      🔎 Search any file and open it.
      
      ❕ It must be absolute full path

      🎓 Tip: use <tab> completion to trigger fzf completion

- name: stop
  group: Run
  help: |-
    🛑 Stop currently running example

- name: open-docs
  group: Run
  help: |-
    🧑‍🎓 Open Confluent documentation of currently running example
  flags:
  - long: --only-show-url
    help: |-
      🌐 Only show url

- name: bootstrap-reproduction-model
  environment_variables:
  - name: OUTPUT_FOLDER 
    help: 📁 Output folder where to generate bootstrapped files
    default: reproduction-models
  group: Bootstrap
  dependencies:
    fzf: visit $(blue_underlined https://github.com/junegunn/fzf#installation) to install
  help: |-
    🛠  Bootstrap reproduction model
    
    👉 Check documentation https://kafka-docker-playground.io/#/reusables?id=%f0%9f%9b%a0-bootstrap-reproduction-model
  catch_all:
    label: arguments
    help: |-
      Arguments to use by example script

      Most of examples support to get required options either by using arguments or environment variables.
      
      Example with Zendesk:

      playground run -f zendesk-source<tab> <ZENDESK_URL> <ZENDESK_USERNAME> <ZENDESK_PASSWORD>
    required: false
  flags:
  - *tag
  - *connector-tag
  - *connector-zip
  - *connector-jar
  - *enable-ksqldb
  - *enable-control-center
  - *enable-conduktor
  - *enable-multiple-brokers
  - *enable-multiple-connect-workers
  - *enable-jmx-grafana
  - *enable-kcat
  - *enable-sr-maven-plugin-app
  - *enable-sql-datagen
  - *cluster-region
  - *cluster-environment
  - *cluster-name
  - *cluster-creds
  - *cluster-schema-registry-creds

  - long: --file
    short: -f
    required: true
    validate: file_exists_with_trick
    arg: file
    completions:
      - $(playground get-examples-list-with-fzf --without-repro "$cur")
    help: |-
      🔖 Example file to use as basis
      
      ❕ It must be absolute full path

      🎓 Tip: use <tab> completion to trigger fzf completion

  - long: --description
    short: -d
    required: true
    validate: not_empty
    arg: description
    help: |-
      💭 Description for the reproduction model

  - long: --producer
    short: -p
    arg: producer-type
    conflicts: [--pipeline]
    default: "none"
    allowed: 
      - none
      - avro
      - avro-with-key
      - protobuf
      - protobuf-with-key
      - json-schema
      - json-schema-with-key
    help: |-
      ♨️ Java producer type to use
      
      One of avro, avro-with-key, protobuf, protobuf-with-key, json-schema, json-schema-with-key

      🎓 Tip: 'with-key' will also produce key with selected converter, otherwise LongConverter is used

  - long: --nb-producers
    short: -n
    arg: nb-producers
    validate: integer
    default: ""
    help: |-
      2️⃣ Number of java producers to generate

  - long: --producer-schema-key
    required: false
    help: |-
      🔰 Schema to use for the key

      ✨ Copy and paste the schema you want to use for the key, save and close the file to continue

  - long: --producer-schema-value
    required: false
    help: |-
      🔰 Schema to use for the value

      ✨ Copy and paste the schema you want to use for the key, save and close the file to continue

  - long: --custom-smt
    help: |-
      ⚙️ Add a custom SMT (which is a no-op)

  - long: --pipeline
    required: false
    validate: file_exists_with_trick
    arg: sink_file
    conflicts: [--producer]
    completions:
      - $(playground get-examples-list-with-fzf --without-repro --sink-only "$cur")
    help: |-
      🔖 Sink example file to use for creating a pipeline
      
      ❕ It must be absolute full path. 

      🎓 Tip: use <tab> completion to trigger fzf completion

  examples:
  - playground bootstrap-reproduction-model -f hdfs2<tab> -d "simple test"
  - playground bootstrap-reproduction-model -f /full/path/hdfs2-sink.sh -d "testing with avro producer" --producer avro --producer-schema-value myschema<tab>
  - playground bootstrap-reproduction-model -f hdfs2<tab> -d "testing with 2 protobuf producers" --producer protobuf --nb-producers 2
  - playground bootstrap-reproduction-model -f hdfs2<tab> -d "testing custom smt" --custom-smt
  - playground bootstrap-reproduction-model -f debeziumpostgres<tab> -d "create pipeline" --pipeline jdbcsink<tab>

- name: get-docker-compose
  group: Kafka
  help: |-
    🐋 Get docker-compose

- name: get-properties
  group: Kafka
  help: |-
    📝 Get properties file from a container
    
    👉 Check documentation https://kafka-docker-playground.io/#/how-to-use?id=%f0%9f%93%9d-see-properties-file

  flags:
  - &container
    long: --container
    short: -c
    required: false
    default: "connect"
    arg: container
    completions:
      - $(docker ps --format '{{.Names}}')
    help: |-
      🐳 Container name

  examples:
  - playground get-properties
  - playground get-properties --container broker
  - playground get-properties -c broker

- name: get-all-schemas
  group: Kafka
  filters:
  - not_mdc_environment
  - schema_registry_running
  help: |-
    🔰 Get all schemas versions for all subjects
  flags:
    - long: --open
      short: -o
      help: |- 
        🔖 Save output to a file and open with text editor set with config.ini (default is code)

  examples:
  - playground get-all-schemas

- name: debug
  expose: true
  group: Debug
  help: |-
    🐞 Debug commands
  commands:

  - name: enable-remote-debugging
    help: |-
      ✨ Enable java remote debugging for container
      
      👉 Check documentation https://kafka-docker-playground.io/#/reusables?id=%e2%9c%a8-remote-debugging
    flags:
      - *container
    examples:
    - playground debug enable-remote-debugging
    - playground debug enable-remote-debugging --container broker
    - playground debug enable-remote-debugging -c broker

  - name: testssl
    help: |-
      🔐 Testing TLS/SSL encryption using https://testssl.sh/

      testssl <URI>, where <URI> is:

      host|host:port|URL|URL:port   port 443 is default, URL can only contain HTTPS protocol
    args:
    - name: arguments
      help: arguments to pass to testssl, see https://testssl.sh for all options
      required: false
    examples:
    - playground debug testssl https://google.com
    - playground debug testssl pkc-xxxx.us-west-2.aws.confluent.cloud:9092

  - name: thread-dump
    help: |-
      🎯 Take a java thread dump

      🔖 It will save output to a file and open with text editor set with config.ini (default is code)
    flags:
      - *container
    examples:
    - playground debug thread-dump
    - playground debug thread-dump --container broker

  - name: heap-dump
    help: |-
      👻 Take a heap dump

      🔖 It will save output to a .hprof file. VisualVM (https://visualvm.github.io/) or MAT (https://www.eclipse.org/mat/) can be used to read the file.
    flags:
      - *container
    examples:
    - playground debug heap-dump
    - playground debug heap-dump --container broker

  - name: tcp-dump
    help: |-
      🕵️‍♂️ Take a tcp dump (sniffing network)
    flags:
      - *container
      - long: --port
        arg: port
        validate: integer
        required: false
        help: |-
          Port on which tcp dump should be done, if not set sniffing is done on every port
      - long: --duration
        arg: duration
        validate: integer
        required: false
        default: "30"
        help: |-
          Duration of the dump (default is 30 seconds).
    examples:
    - playground debug tcp-dump --container control-center --port 9021 --duration 60

  - name: block-traffic
    help: |-
      🚫 Blocking traffic using iptables
    flags:
      - *container
      - long: --destination
        arg: destination
        required: true
        help: |-
          Destination: it could be an ip address, a container name or a hostname
      - long: --port
        arg: port
        validate: integer
        required: false
        help: |-
          Port on which tcp traffic should be blocked
      - &action
        long: --action
        allowed: [start, stop]
        arg: action
        required: true
        help: |-
          🟢 start or stop
    examples:
    - playground debug block-traffic --destination google.com --action start
    - playground debug block-traffic --container broker --destination zookeeper --action start

  - name: flight-recorder
    help: |-
      🛩️ Record flight recorder

      Read more about it at https://www.baeldung.com/java-flight-recorder-monitoring

      Open the jfr file with JDK Mission Control JMC(https://jdk.java.net/jmc/)
    flags:
      - *container
      - *action
    examples:
    - playground debug flight-recorder --action start
    - playground debug flight-recorder --action stop

  - name: log-level
    help: |-
      🧬 Set log level for any package
    filters:
    - connect_running
    commands:
    - name: get
      help: Get log levels
      flags:
      - long: --package
        short: -p
        required: false
        validate: not_empty
        arg: package
        help: |-
          Package name

    - name: set
      help: Set log level for specific logger
      flags:
      - long: --package
        short: -p
        required: true
        validate: not_empty
        arg: package
        help: |-
          📦 Package name

      - &level
        long: --level
        short: -l
        arg: level
        allowed: [INFO, WARN, DEBUG, TRACE]
        required: true
        help: |-
          ❕Log level

    examples:
    - playground debug log-level get
    - playground debug log-level get -p io.confluent.connect.oracle.cdc
    - playground debug log-level get --package io.confluent.connect.oracle.cdc
    - playground debug log-level set -p io.confluent.connect.oracle.cdc.logging.LogUtils -l TRACE

- name: get-jmx-metrics
  group: Kafka
  help: |-
    🔢 Get JMX metrics from a component
    
    👉 Check documentation https://kafka-docker-playground.io/#/how-to-use?id=%f0%9f%94%a2-jmx-metrics
  dependencies:
    java: visit $(blue_underlined https://openjdk.org/install/) to install
  flags:
  - long: --component
    short: -c
    default: "connect"
    required: false
    arg: component
    allowed: [zookeeper, broker, connect, schema-registry]
    help: |-
      Component name
  - long: --open
    short: -o
    help: |- 
      🔖 Save output to a file and open with text editor set with config.ini (default is code)

  - long: --domain
    short: -d
    required: false
    arg: domain
    help: |-
      Domain name

  examples:
  - playground get-jmx-metrics --component connect
  - playground get-jmx-metrics --component connect --domain "kafka.connect kafka.consumer kafka.producer"
  - playground get-jmx-metrics -c broker

- name: container
  expose: true
  group: Container
  help: |-
    🐳 Container commands
  commands:

    - name: recreate
      group: Container
      help: |-
        💫 Recreate container(s)
        
        👉 Check documentation https://kafka-docker-playground.io/#/how-to-use?id=%e2%99%bb%ef%b8%8f-re-create-containers

    - name: get-ip-addresses
      group: Container
      help: |-
        🖥️  Get ip address of running containers
      examples:
      - playground get-ip-address-container

    - name: kill-all
      group: Container
      help: |-
        💀 Kill all containers

    - name: logs
      group: Container
      help: |-
        🕵️  Tail and follow container logs

      flags:
      - *container
      - long: --open
        short: -o
        help: |- 
          🔖 Save output to a file and open with text editor set with config.ini (default is code)
        conflicts: [--wait-for-log]
      - long: --wait-for-log
        short: -w
        arg: log
        validate: not_empty
        help: |- 
          😴 Wait until log appears
        conflicts: [--open]
      - long: --max-wait
        short: -m
        arg: max_wait
        validate: integer
        default: "600"
        help: |- 
          ⏳ Max time in seconds to wait when using --wait-for-log (default 600s)
        conflicts: [--open]

      examples:
      - playground container logs --container connect
      - playground container logs -c connect --open
      - playground container logs -c connect --wait-for-log "StackOverflowError"

    - name: ssh
      group: Container
      help: |-
        🛬 SSH into container

      flags:
      - *container

      - long: --shell
        short: -s
        required: false
        default: "bash"
        arg: shell
        allowed: 
          - bash
          - sh
          - ksh
          - zsh
        help: |-
          💾 Shell to use (default is bash)

      examples:
      - playground ssh -c connect
      - playground ssh -c connect -s sh
      - playground ssh --container connect --shell sh

    - name: exec
      group: Container
      help: |-
        🪄  Execute command in a container

      flags:
      - *container

      - long: --command
        required: true
        validate: not_empty
        arg: command
        help: |-
          📲 Command to execute

      - long: --root
        help: |-
          👑 Run command as root

      - long: --shell
        default: "bash"
        arg: shell
        allowed: 
          - bash
          - sh
          - ksh
          - zsh
        help: |-
          💾 Shell to use (default is bash)

      examples:
      - playground exec -c connect -d "date"
      - playground exec -c connect -d "whoami" --root
      - playground exec --container connect --command "whoami" --shell sh

    - name: restart
      group: Container
      help: |-
        🔁 Restart a container

      flags:
      - *container

    - name: pause
      group: Container
      help: |-
        ⏸️  Pause a container

      flags:
      - *container

    - name: resume
      group: Container
      help: |-
        ⏯️  Resume a container

      flags:
      - *container

    - name: kill
      group: Container
      help: |-
        🔫 Kill a container

      flags:
      - *container

- name: topic
  expose: true
  group: Topic
  filters:
  - not_mdc_environment
  help: |-
    🗳 Topic commands
  commands:

    - name: get-number-records
      group: Topic
      help: |-
        💯 Get number of records in a topic
      flags:
      - &topic
        long: --topic
        short: -t
        required: false
        arg: topic
        completions:
          - $(playground get-topic-list)
        help: |-
          🗳 Topic name
      examples:
      - playground get-number-records --topic a-topic
      - playground get-number-records -t a-topic

    - name: display-consumer-offsets
      group: Topic
      help: |-
        📭 Display content of __consumer_offsets topic

    - name: describe
      group: Topic
      help: |-
        🔬 Describe topic
      flags:
      - *topic

    - name: consume
      filters:
      - schema_registry_running
      group: Topic
      help: |-
        📥 Consume topic from beginning
      flags:
      - &verbose
        long: --verbose
        short: -v
        help: 🐞 Show command being ran.
      - *topic
      - long: --max-messages
        arg: max-messages
        validate: integer
        required: false
        default: "50"
        help: |-
          Max number of messages to display (default is 50)
      - long: --min-expected-messages
        arg: min-expected-messages
        validate: integer
        required: false
        default: ""
        help: |-
          Minimum expected number of messages to be present in topic, returns an error if this is not the case

          Note: --topic should be specified in this case.
      - long: --grep
        arg: grep
        required: false
        default: ""
        help: |-
          Verify that topic content contains record which contains specified string
      - long: --timeout
        arg: timeout
        validate: integer
        required: false
        default: "60"
        help: |-
          Max number of seconds to wait when --min-expected-messages is used.

          Default is 60 seconds
      - long: --tail
        required: false
        help: |-
          Tail on logs.
        conflicts: [--min-expected-messages, --max-messages]

      - long: --plot-latencies-timestamp-field
        required: false
        arg: timestamp
        help: |-
          🗳 Timestamp field name that represents when record was created in source system

    - name: produce
      filters:
      - schema_registry_running
      group: Topic
      help: |-
         📤 Produce to a topic
      flags:
      - long: --input
        arg: input
        completions:
          - $(playground get-predefined-schemas "$cur")
        default: "-"
        required: false
        help: |- 
          🔥 You can either:
          
          * Set your own schema (avro, json-schema, protobuf) with stdin (see example section). 
          
          * You can also generate json data using json or sql format using syntax from https://github.com/MaterializeInc/datagen

          * Use completion to select predefined schemas (or use your own schema file) 🎓 Tip: use <tab> completion to trigger fzf completion

          * Directly set payload

      - *verbose
      - long: --topic
        short: -t
        required: true
        arg: topic
        completions:
          - $(playground get-topic-list)
        help: |-
          🗳 Topic name
      - long: --nb-messages
        arg: nb-messages
        validate: integer
        required: false
        default: "1"
        help: |-
          💯 Number of messages to produce (default is 1)
      - long: --nb-partitions
        arg: nb-partitions
        validate: integer
        required: false
        default: ""
        help: |-
          🔢 Number of partitions for the topic. (default is 1)
          
          ❌ Important: If topic is existing, it will be re-created before producing to topic.
      - long: --key
        arg: key
        required: false
        help: |-
          🗝️ Key to use. If not set, no key is used.

          If the key contain a number, it will be used as starting point and incremented for each record. 
          
          Example: key1 will start with key1, then key1, etc..
          Example: mykey-10-suffix will start with mykey-10-suffix then mykey-11-suffix, etc..

          Otherwise, the key will be same for all records.
          
      - long: --headers
        arg: headers
        required: false
        help: |-
          🚏 Headers to use for all records. If not set, no header is used.

          Example: --headers "header1:value1,header2:value2"

          Note: CP 7.2+ is required.
      - long: --forced-value
        arg: forced-value
        required: false
        help: |-
          ☢️ Value to use for all records. 
          
          🎓 Tip: use --generate-only first with avro, json-schema or protobuf to get skeleton of messages and then use --forced-value to send the message you need. 
      - long: --generate-only
        required: false
        help: |-
          🚪 Only generate messages without sending to kafka topic.

          Used with --forced-value, this is a powerful way to send specific messages.
      - long: --tombstone
        required: false
        help: |-
          Generate tombstone (record with null value). 
          
          --key must be set when this flag is used.

          Note: CP 7.2+ is required.
      examples: |

        playground topic produce --tombstone --topic a-topic --key mykey

        playground topic produce -t topic-json --nb-messages 10 << 'EOF'
        {
            "_meta": {
                "topic": "",
                "key": "",
                "relationships": []
            },
            "nested": {
                "phone": "faker.phone.imei()",
                "website": "faker.internet.domainName()"
            },
            "id": "iteration.index",
            "name": "faker.internet.userName()",
            "email": "faker.internet.exampleEmail()",
            "phone": "faker.phone.imei()",
            "website": "faker.internet.domainName()",
            "city": "faker.address.city()",
            "company": "faker.company.name()"
        }
        EOF

        playground topic produce -t topic-avro --nb-messages 10 << 'EOF'
        {
            "type": "record",
            "namespace": "com.github.vdesabou",
            "name": "Customer",
            "fields": [
                {
                    "name": "count",
                    "type": "long",
                    "doc": "count"
                },
                {
                    "name": "first_name",
                    "type": "string",
                    "doc": "First Name of Customer"
                },
                {
                    "name": "last_name",
                    "type": "string",
                    "doc": "Last Name of Customer"
                },
                {
                    "name": "address",
                    "type": "string",
                    "doc": "Address of Customer"
                }
            ]
        }
        EOF

        playground topic produce -t topic-json-schema --nb-messages 3 << 'EOF'
        {
          "$schema": "http://json-schema.org/draft-07/schema#",
          "additionalProperties": false,
          "$id": "http://lh.test/Customer.schema.json",
          "title": "Customer",
          "description": "Customer description",
          "type": "object",
          "properties": {
            "name": {
              "description": "Customer name",
              "type": "string",
              "maxLength": 25
            },
            "surname": {
              "description": "Customer surname",
              "type": "string",
              "minLength": 2
            },
            "email": {
              "description": "Email",
              "type": "string",
              "pattern": "^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$"
            }
          },
          "required": [
            "name",
            "surname"
          ]
        }
        EOF


        playground topic produce -t topic-proto --nb-messages 3 << 'EOF'
        syntax = "proto3";

        message Order {
          float         total = 1;
          repeated Item items = 2;

          message Item {
            string name  = 1;
            float  price = 2;
          }
        }
        EOF

        playground topic produce -t vincent-jsql --nb-messages 10 << 'EOF'
        CREATE TABLE "notused"."notused" (
          "id" int PRIMARY KEY,
          "name" varchar COMMENT 'faker.internet.userName()',
          "merchant_id" int NOT NULL COMMENT 'faker.datatype.number()',
          "price" int COMMENT 'faker.datatype.number()',
          "status" int COMMENT 'faker.datatype.boolean()',
          "created_at" datetime DEFAULT (now())
        );
        EOF

    - name: set-schema-compatibility
      filters:
      - schema_registry_running
      group: Topic
      help: |-
        🛡️ Change topic's schema compatibility
      flags:
      - *topic
      - long: --compatibility
        arg: compatibility
        allowed: 
          - BACKWARD
          - BACKWARD_TRANSITIVE
          - FORWARD
          - FORWARD_TRANSITIVE
          - FULL
          - FULL_TRANSITIVE
          - NONE
        required: true
        help: |-
          Schema Registry compatibility rule

    - name: create
      group: Topic
      help: |-
        🆕 Create topic
      flags:
      - long: --topic
        short: -t
        required: true
        arg: topic
        help: |-
          🗳 Topic name
      - long: --nb-partitions
        arg: nb-partitions
        validate: integer
        required: false
        default: ""
        help: |-
          Number of partitions for the topic. (default is 1)
      catch_all:
        label: arguments
        help: |-
          Any arguments to be used with kafka-topics --create
        required: false
      examples: |
        playground topic create --topic atopic
        playground topic create --topic atopic --nb-partitions 8 --config retention.ms=30000
        
    - name: delete
      group: Topic
      help: |-
        ❌ Delete topic
      flags:
      - long: --topic
        short: -t
        required: true
        arg: topic
        completions:
          - $(playground get-topic-list)
        help: |-
          🗳 Topic name

- name: ccloud-connector
  expose: true
  group: Connector
  filters:
  - ccloud_environment
  dependencies:
    confluent: visit $(blue_underlined https://docs.confluent.io/confluent-cli/current/overview.html) to install
  help: |-
    🔗☁️ Fully Managed Connector commands
  environment_variables:
  - name: CLOUD_API_KEY
    help: Cloud API key, see https://docs.confluent.io/cloud/current/access-management/authenticate/api-keys/api-keys.html#cloud-cloud-api-keys
    required: true
  - name: CLOUD_API_SECRET
    help: Cloud API secret, see https://docs.confluent.io/cloud/current/access-management/authenticate/api-keys/api-keys.html#cloud-cloud-api-keys
    required: true

  commands:
  - name: status
    help: 🧩 Show status of all connectors

  - name: plugins
    help: 🎨 Show all plugins installed

  - name: pause
    help: ⏸️  Pause connector
    flags:
    - &ccloudconnector
      long: --connector
      short: -c
      required: false
      arg: connector
      completions:
        - $(playground get-ccloud-connector-list)
      help: |-
        🔗 Connector name

        🎓 Tip: If not specified, the command will apply to all connectors

  - name: resume
    help: ⏯️  Resume connector
    flags:
    - *ccloudconnector

  - name: delete
    help: 🗑️  Delete connector
    flags:
    - *ccloudconnector

  - name: show-lag
    help: 🐢 Show lag of sink connector
    flags:
    - *ccloudconnector
    - &waitforzerolag
      long: --wait-for-zero-lag
      help: |- 
        😴 Wait until lag becomes 0

  - name: show-config
    help: 🔩 Show all possible configuration parameters of connector
    flags:
    - *ccloudconnector
    - long: --open
      short: -o
      help: |- 
        🔖 Save output to a file and open with text editor set with config.ini (default is code)
    - long: --force-refresh
      required: false
      help: |-
        ☢️ Force refresh.

  - name: create-or-update
    help: 🧑‍🎨  Create or update connector
    args:
    - name: json
      
      # Set the default path value to -, which is the standard operator for stdin.
      default: "-"
      help: json (reads from stdin if empty)

    flags:
    - long: --connector
      short: -c
      required: true
      arg: connector
      completions:
        - $(playground get-ccloud-connector-list)
      help: |-
        🔗 Connector name

    examples: |
      playground ccloud-connector create-or-update --connector HttpSink << EOF
      {
          "connector.class": "HttpSink",
          "name": "HttpSink",
          "kafka.auth.mode": "KAFKA_API_KEY",
          "kafka.api.key": "$CLOUD_KEY",
          "kafka.api.secret": "$CLOUD_SECRET",
          "topics": "http-topic",
          "input.data.format": "AVRO",
          "http.api.url": "http://httpstat.us/200/",
          "behavior.on.error": "fail",
          "tasks.max" : "1"
      }
      EOF

- name: connector
  expose: true
  group: Connector
  filters:
  - not_mdc_environment
  - connect_running
  help: |-
    🔗 Connector commands

  commands:
  - name: status
    help: 🧩 Show status of all connectors

  - name: plugins
    help: 🎨 Show all plugins installed

  - name: pause
    help: ⏸️  Pause connector
    flags:
    - &connector
      long: --connector
      short: -c
      required: false
      arg: connector
      completions:
        - $(playground get-connector-list)
      help: |-
        🔗 Connector name

        🎓 Tip: If not specified, the command will apply to all connectors

  - name: versions
    help:  🧞 Get current and latest version available on Confluent Hub for connector(s) used in example

  - name: restart
    help: ♻️  Restart connector
    flags:
    - *connector

  - name: resume
    help: ⏯️  Resume connector
    flags:
    - *connector

  - name: delete
    help: 🗑️  Delete connector
    flags:
    - *connector

  - name: show-lag
    help: 🐢 Show lag of sink connector
    flags:
    - *connector
    - *waitforzerolag

  - name: show-config
    help: 🔩 Show all possible configuration parameters of connector
    flags:
    - *connector
    - long: --open
      short: -o
      help: |- 
        🔖 Save output to a file and open with text editor set with config.ini (default is code)
    - long: --force-refresh
      required: false
      help: |-
        ☢️ Force refresh.

  - name: log-level
    help: |-
      🧬 Set connect log level
    flags:
    - *connector
    - *level

  - name: create-or-update
    help: 🧑‍🎨  Create or update connector
    args:
    - name: json
      
      # Set the default path value to -, which is the standard operator for stdin.
      default: "-"
      help: json (reads from stdin if empty)

    flags:
    - long: --connector
      short: -c
      required: true
      arg: connector
      completions:
        - $(playground get-connector-list)
      help: |-
        🔗 Connector name
    - long: --level
      short: -l
      arg: level
      allowed: [INFO, WARN, DEBUG, TRACE]
      required: false
      help: |-
        ❕Log level
    examples: |
      playground connector create-or-update -c filestream-sink << EOF
      {
          "tasks.max": "1",
          "connector.class": "org.apache.kafka.connect.file.FileStreamSinkConnector",
          "topics": "filestream",
          "file": "/tmp/output.json",
          "key.converter": "org.apache.kafka.connect.storage.StringConverter",
          "value.converter": "org.apache.kafka.connect.json.JsonConverter",
          "value.converter.schemas.enable": "false"
      }
      EOF

  examples:
  - playground connector status
  - playground connector status --json
  - playground connector resume --connector <connector-name>
  - playground connector pause -c <connector-name>
  - playground connector delete -c <connector-name>
