name: playground
version: 1.0.0
dependencies:
  docker: visit https://docs.docker.com/get-docker to install
help: |-
  üß† CLI for Kafka Docker Playground üê≥

  üëâ Check documentation https://kafka-docker-playground.io/#/cli
filters:
- docker_running

flags:
- long: --vvv
  short: -v
  help: |
    üêõ set verbose output (set -x)

    ‚ùó it can print sensitive information ‚ùó

commands:

- name: help
  help: Show help about a command
  args:
  - name: command
    help: üÜò Help command

- name: status
  help: üó∫Ô∏è Show a status

### private commands for completion
- name: get-connector-list
  help: Return some completion for connector list
  private: true

- name: generate-fzf-find-files
  help: force call to generate_fzf_find_files
  private: true

- name: generate-tag-list
  help: generate the confluent platform tag list
  private: true

- name: generate-connector-plugin-list
  help: generate the confluent hub plugin list
  private: true

- name: generate-kafka-region-list
  help: generate the confluent kafka region list
  private: true
  dependencies:
    confluent: visit https://docs.confluent.io/confluent-cli/current/overview.html to install
    
- name: get-connector-plugin
  help: Return some completion for connector plugin
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur

- name: get-ccloud-environment-list
  help: Return some completion for ccloud environment
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur

- name: get-ccloud-cluster-list
  help: Return some completion for ccloud cluster
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur

- name: get-tag-list
  help: Return some completion for confluent platform tag
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur

- name: get-kafka-region-list
  help: Return some completion for confluent cloud kafka cluster region list
  private: true
  dependencies:
    confluent: visit https://docs.confluent.io/confluent-cli/current/overview.html to install
  args:
  - name: cur
    required: false
    help: correspond to completion $cur

- name: get-topic-list
  help: Return some completion for topic list
  private: true
  flags:
  - long: --skip-connect-internal-topics
    required: false

- name: get-subject-list
  help: Return some completion for subject list
  private: true
  flags:
  - long: --deleted
    required: false
    help: |-
      üßü Include soft deleted schemas

- name: get-examples-list-with-fzf
  help: Return some completion for examples list
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur
  flags:
  - long: --without-repro
    required: false
  - long: --sink-only
    required: false
  - long: --ccloud-only
    required: false
  - long: --connector-only
    required: false
  - long: --repro-only
    required: false
  - long: --fully-managed-connector-only
    required: false
  - long: --ksql-only
    required: false
  - long: --schema-registry-only
    required: false
  - long: --rest-proxy-only
    required: false
  - long: --other-playgrounds-only
    required: false

- name: get-zip-or-jar-with-fzf
  help: Return some completion for zip or jar list
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur
  flags:
  - long: --type
    required: false
    arg: type
    allowed: [zip, jar]

- name: get-any-file-with-fzf
  help: Return some completion for any files
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur

- name: get-playground-repro-export-with-fzf
  help: Return some completion for export tgz files
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur

- name: get-predefined-schemas
  help: Return some completion for predefined schemas
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur

- name: bashly-reload
  private: true
  dependencies:
    bashly: visit https://bashly.dannyb.co/installation/ to install

- name: state
  private: true
  commands:
  - name: show
    private: true
    help: Show the entire playground.ini file

  - name: get
    help: Read a value from the playground.ini file
    private: true
    args:
    - name: key
      required: true
      help: playground.ini key
    examples:
    - playground state get hello
    - playground state get user.name

  - name: set
    help: Save a value in the playground.ini file
    private: true
    args:
    - name: key
      required: true
      help: playground.ini key
    - name: value
      required: true
      help: playground.ini value
    examples:
    - playground state set hello world
    - playground state set user.email me@example.com

  - name: del
    help: Remove a value from the playground.ini file
    private: true
    args:
    - name: key
      required: true
      help: playground.ini key
    examples:
    - playground state del hello
    - playground state del user.name


- name: config
  help: ‚öôÔ∏è Configure CLI
  commands:
  - name: show
    private: true
    help: Show the entire playground_config.ini file

  - name: get
    private: true
    help: Read a value from the playground_config.ini file

    args:
    - name: key
      required: true
      help: Config key
    examples:
    - playground config get hello
    - playground config get user.name

  - name: set
    private: true
    help: Save a value in the playground_config.ini file
    args:
    - name: key
      required: true
      help: playground_config.ini key
    - name: value
      required: true
      help: playground_config.ini value
    examples:
    - playground config set hello world
    - playground config set user.email me@example.com

  - name: editor
    help: editor to use to open files
    args:
    - name: editor
      required: true
      help: editor
      validate: editor_exists
    examples:
    - playground config editor vi
    - playground config editor code

  - name: folder_zip_or_jar
    help: |- 
      üìÇ list of folders where to search for zip or jar
      current folder is always included

      default is ~ (home dir)
    args:
    - name: folder
      required: true
      help: folder
      unique: true
      repeatable: true
      validate: dir_exists
    examples:
    - playground config folder_zip_or_jar ~/Downloads ~/Documents/github/kafka-connect-*
    - playground config folder_zip_or_jar ~/Downloads

  - name: clipboard
    help: copy to clipboard connector config (only working on MacOS)
    args:
    - name: enabled
      required: false
      default: "true"
      help: editor
    examples:
    - playground config clipboard false
    - playground config clipboard true

- name: run
  group: Run
  catch_all:
    label: arguments
    help: |-
      Arguments to use by example script

      Most of examples support to get required options either by using arguments or environment variables.
      
      Example with Zendesk:

      playground run -f zendesk-source<tab> <ZENDESK_URL> <ZENDESK_USERNAME> <ZENDESK_PASSWORD>
    required: false
  dependencies:
    fzf: visit https://github.com/junegunn/fzf#installation to install
  help: |-
    üïπÔ∏è Run any example

    ‚õÖ When running Confluent Cloud (ccloud) example:

      All you have to do is to be already logged in with confluent CLI.

      By default, a new Confluent Cloud environment with a Cluster will be created.

      You can configure the new cluster by setting:
    
      --cluster-type (or CLUSTER_TYPE environment variable): The type of cluster (possible values: `basic`, `standard` and `dedicated`, default `basic`)
      --cluster-cloud (or CLUSTER_CLOUD environment variable): The Cloud provider (possible values: `aws`, `gcp` and `azure`, default `aws`)
      --cluster-region (or CLUSTER_REGION environment variable): The Cloud region (use `confluent kafka region list` to get the list, default `eu-west-2` for aws, `westeurope`for azure and `europe-west2` for gcp)
      --cluster-environment (or ENVIRONMENT environment variable) (optional): The environment id where want your new cluster (example: `txxxxx`) 

      In case you want to use your own existing cluster, you need to setup, in addition to previous ones:

      --cluster-name (or CLUSTER_NAME environment variable): The cluster name
      --cluster-creds (or CLUSTER_CREDS environment variable): The Kafka api key and secret to use, it should be separated with colon (example: `<API_KEY>:<API_KEY_SECRET>`)
      --cluster-schema-registry-creds (or SCHEMA_REGISTRY_CREDS environment variable) (optional, if not set, new one will be created): The Schema Registry api key and secret to use, it should be separated with colon (example: `<SR_API_KEY>:<SR_API_KEY_SECRET>`)

  flags:
  - &environment-run
    long: --environment
    required: false
    default: "plaintext"
    arg: environment
    allowed: [ccloud, plaintext, sasl-ssl, sasl-plain, 2way-ssl, sasl-scram, kraft-external-plaintext, kraft-plaintext, kerberos, ssl_kerberos, ldap-authorizer-sasl-plain, ldap-sasl-plain, rbac-sasl-plain]
    help: |-
      üîê The environment to start when running a connector example 
      
      - plaintext
      - ccloud
      - 2way-ssl
      - kerberos
      - kraft-external-plaintext
      - kraft-plaintext
      - ldap-authorizer-sasl-plain
      - ldap-sasl-plain
      - rbac-sasl-plain
      - sasl-plain
      - sasl-scram
      - sasl-ssl
      - ssl_kerberos

      Default is plaintext.
      This is only supported when example is a connector example
  - long: --file
    short: -f
    required: false
    validate: file_exists_with_trick
    arg: file
    completions:
      - $(playground get-examples-list-with-fzf "$cur")
    help: |-
      üîñ Example file to run

      ‚ùï It must be absolute full path

      üéì Tip: use <tab> completion to trigger fzf completion
  - long: --open
    short: -o
    help: üìñ Opening example file with text editor set with playground config editor <editor> (default is code)
  - &tag
    long: --tag
    arg: tag
    required: false
    completions:
      - $(playground get-tag-list "$cur")
    help: |-
      üéØ Confluent Platform (CP) version to use

      Must be greater or equal to 5.3.0

      üéì Tip: use <tab> completion to trigger fzf completion
  - &connector-tag
    long: --connector-tag
    arg: connector_tag
    required: false
    help: |- 
      üîó Connector version to use

      By default, for each connector, the latest available version on Confluent Hub is used

      üéì Tip: set to " " in order to select the version dynamically

    conflicts: [--connector-zip]
  - &connector-zip
    long: --connector-zip
    arg: connector_zip
    required: false
    validate: file_exists_with_trick
    completions:
      - $(playground get-zip-or-jar-with-fzf --type zip "$cur")
    conflicts: [--connector-tag]
    help: |- 
      ü§ê Connector zip to use

      ‚ùï It must be absolute full path

      üéì Tip: use <tab> completion to trigger fzf completion 
              use playground config folder_zip_or_jar <folder1> <folder2>... (default is home folder and current folder is always included) to configure where to search the files

  - &connector-jar
    long: --connector-jar
    arg: connector_jar
    required: false
    validate: file_exists_with_trick
    completions:
      - $(playground get-zip-or-jar-with-fzf --type jar "$cur")
    help: |-
      ‚ô®Ô∏è Connector jar to use

      ‚ùï It must be absolute full path

      üéì Tip: use <tab> completion to trigger fzf completion 
              use playground config folder_zip_or_jar <folder1> <folder2>... (default is home folder and current folder is always included) to configure where to search the files

  - &enable-ksqldb
    long: --enable-ksqldb
    required: false
    help: |-
      üöÄ Enable ksqlDB 
      
      ‚ùó not supported with ccloud examples

      By default, ksqldb-server and ksqldb-cli containers are not started for every test
  - &enable-rest-proxy
    long: --enable-rest-proxy
    required: false
    help: |-
      üß≤ Enable Rest Proxy

      ‚ùó not supported with ccloud examples

      By default, rest-proxy container is not started for every test
  - &enable-control-center
    long: --enable-control-center
    required: false
    help: |-
      üí† Enable Control Center

      By default, control-center container is not started for every test

      Control Center is reachable at http://127.0.0.1:9021
  - &enable-conduktor
    long: --enable-conduktor
    required: false
    help: |- 
      üê∫ Enable Conduktor Platform

      By default, Conduktor Platform container is not started for every test

      Conduktor is reachable at http://127.0.0.1:8080/console (admin/admin)
  - &enable-multiple-brokers
    long: --enable-multiple-brokers
    required: false
    help: |- 
      3Ô∏è‚É£ Enable multiple brokers

      By default, there is only one broker node enabled
  - &enable-multiple-connect-workers
    long: --enable-multiple-connect-workers
    required: false
    help: |-
      ü•â Enable multiple connect node

      By default, there is only one connect node enabled

      It only works when plaintext environment is used
  - &enable-jmx-grafana
    long: --enable-jmx-grafana
    required: false
    help: |-
      Enable Grafana, Prometheus and Pyroscope

      üìä Grafana is reachable at http://127.0.0.1:3000 (login/password is admin/password)

      üõ°Ô∏è Prometheus is reachable at http://127.0.0.1:9090
      
      üìõ Pyroscope is reachable at http://127.0.0.1:4040
  - &enable-kcat
    long: --enable-kcat
    required: false
    help: |-
      üêà‚Äç‚¨õ Enable kcat

      You can use it with:

      $ docker exec kcat kcat -b broker:9092 -L
  - &enable-sql-datagen
    long: --enable-sql-datagen
    required: false
    help: |-
      üå™Ô∏è Enable SQL Datagen injection

      This only works for Oracle, MySql, Postgres and Microsoft Sql Server source connector examples with JDBC and Debezium

  - &cluster-cloud
    long: --cluster-cloud
    required: false
    arg: cluster-cloud
    allowed: [aws, gcp, azure]
    help: |-
      üå§ The cloud provider: aws, gcp or azure. Default is aws

      üéì Tip: you can also use CLUSTER_CLOUD environment variable
  - &cluster-type
    long: --cluster-type
    required: false
    arg: cluster-type
    allowed: [basic, standard, dedicated]
    help: |-
      üîã The cluster type: basic, standard or dedicated. Default is basic

      üéì Tip: you can also use CLUSTER_TYPE environment variable
  - &cluster-region
    long: --cluster-region
    required: false
    arg: cluster-region
    completions:
      - $(playground get-kafka-region-list "$cur")
    help: |-
      üó∫ The Cloud region. 
      
      üéì Tip: you can also use CLUSTER_REGION environment variable
      üéì Tip: use <tab> completion to trigger fzf completion

  - &cluster-environment
    long: --cluster-environment
    required: false
    arg: cluster-environment
    validate: not_empty
    completions:
      - $(playground get-ccloud-environment-list "$cur")
    help: |-
      üåê The environment id where want your new cluster (example: txxxxx)

      ‚ÑπÔ∏è Optional, if not set, new environment will be created

      üéì Tip: you can also use ENVIRONMENT environment variable
      üéì Tip: use <tab> completion to trigger fzf completion

  - &cluster-name
    long: --cluster-name
    required: false
    validate: not_empty
    completions:
      - $(playground get-ccloud-cluster-list "$cur")
    arg: cluster-name
    help: |-
      üé∞ The cluster name. 
      
      ‚ù£Ô∏è Only required if you want to use your own existing cluster

      üéì Tip: you can also use CLUSTER_NAME environment variable
      üéì Tip: use <tab> completion to trigger fzf completion
  - &cluster-creds
    long: --cluster-creds
    required: false
    validate: not_empty
    arg: cluster-creds
    help: |-
      üîí The Kafka api key and secret to use, it should be separated with colon (example: <API_KEY>:<API_KEY_SECRET>)

      ‚ù£Ô∏è Only required if you want to use your own existing cluster

      üéì Tip: you can also use CLUSTER_CREDS environment variable
  - &cluster-schema-registry-creds
    long: --cluster-schema-registry-creds
    required: false
    validate: not_empty
    arg: cluster-schema-registry-creds
    help: |-
      üîí The Schema Registry api key and secret to use, it should be separated with colon (example: <SR_API_KEY>:<SR_API_KEY_SECRET>)

      ‚ÑπÔ∏è Optional, if not set, new credentials will be created

      ‚ù£Ô∏è Only required if you want to use your own existing cluster
      
      üéì Tip: you can also use SCHEMA_REGISTRY_CREDS environment variable
  examples:
  - playground run -f zendesk-source<tab> --tag 7.2.1 --enable-control-center <ZENDESK_URL> <ZENDESK_USERNAME> <ZENDESK_PASSWORD>
  - playground run -f jdbc<tab> --connector-tag 10.6.0 --enable-jmx-grafana --open

- name: re-run
  group: Run
  help: |-
    ‚ö° Simply re-run last example you ran with <playground run>
  catch_all:
    label: arguments
    help: |-
      Arguments to use by example script

      Most of examples support to get required options either by using arguments or environment variables.
      
      Example with Zendesk:

      playground run -f zendesk-source<tab> <ZENDESK_URL> <ZENDESK_USERNAME> <ZENDESK_PASSWORD>
    required: false
  dependencies:
    fzf: visit https://github.com/junegunn/fzf#installation to install
  flags:
    - long: --clear
      required: false
      help: |- 
        üßº Clear any previous flags
    - *environment-run
    - *tag
    - *connector-tag
    - *connector-zip
    - *connector-jar
    - *enable-ksqldb
    - *enable-rest-proxy
    - *enable-control-center
    - *enable-conduktor
    - *enable-multiple-brokers
    - *enable-multiple-connect-workers
    - *enable-jmx-grafana
    - *enable-kcat
    - *enable-sql-datagen
  examples:
  - playground re-run
  - playground re-run --tag 6.2.1


- name: history
  group: Run
  help: |-
    üè∞ Get an history of the examples which were run with run command and run it again
  dependencies:
    fzf: visit https://github.com/junegunn/fzf#installation to install

- name: start-environment
  group: Run
  help: |-
    üîê Simply start an environment listed in http://tinyurl.com/y4ybbw32:

    - ccloud
    - 2way-ssl
    - kerberos
    - kraft-external-plaintext
    - kraft-plaintext
    - ldap-authorizer-sasl-plain
    - ldap-sasl-plain
    - mdc-kerberos
    - mdc-plaintext
    - mdc-sasl-plain
    - plaintext
    - rbac-sasl-plain
    - sasl-plain
    - sasl-scram
    - sasl-ssl
    - ssl_kerberos

    Note: when running an example with <playground run>, it is already automatically done
  catch_all:
    label: arguments
    help: |-
      Arguments to use by example script
    required: false
  flags:
    - &environment
      long: --environment
      required: false
      default: "plaintext"
      arg: environment
      allowed: [ccloud, 2way-ssl, kerberos, kraft-external-plaintext, kraft-plaintext, ldap-authorizer-sasl-plain, ldap-sasl-plain, mdc-kerberos, mdc-plaintext, mdc-sasl-plain, plaintext, rbac-sasl-plain, sasl-plain, sasl-scram, sasl-ssl, ssl_kerberos]
      help: |-
        üîê The environment to start . 
        
        - ccloud
        - 2way-ssl
        - kerberos
        - kraft-external-plaintext
        - kraft-plaintext
        - ldap-authorizer-sasl-plain
        - ldap-sasl-plain
        - mdc-kerberos
        - mdc-plaintext
        - mdc-sasl-plain
        - plaintext
        - rbac-sasl-plain
        - sasl-plain
        - sasl-scram
        - sasl-ssl
        - ssl_kerberos

        Default is plaintext
    - long: --docker-compose-override-file
      short: -f
      validate: file_exists
      arg: docker-compose-override-file
      help: |-
        üîñ docker-compose override file

        ‚ùï It must be absolute full path
    - *tag
    - *enable-ksqldb
    - *enable-rest-proxy
    - *enable-control-center
    - *enable-conduktor
    - *enable-multiple-brokers
    - *enable-multiple-connect-workers
    - *enable-jmx-grafana
    - *enable-kcat
  examples:
  - playground start-environment
  - playground start-environment --environment rbac-sasl-plain

- name: switch-ccloud
  group: Run
  dependencies:
    confluent: visit https://docs.confluent.io/confluent-cli/current/overview.html to install
  help: |-
    üå©Ô∏è  Switch to ccloud environment.
    
    It will bootstrap ccloud environment based on your previously ran ccloud example.

- name: switch-back
  group: Run
  help: |-
    üí∫  Switch back from previous environment before switch-ccloud was called.

- name: update-version
  group: Run
  help: |-
    ‚ú® Update current confluent platform or connector(s) with new version(s)
  flags:
  - *tag
  - *connector-tag
  - *connector-zip
  - *connector-jar

- name: open
  group: Run
  dependencies:
    fzf: visit https://github.com/junegunn/fzf#installation to install
  help: |-
    üëê When --file is not provided, simply open last example you ran with <playground run>

    Otherwise, open any file from the playground using --file.
  flags:
  - long: --file
    short: -f
    required: false
    validate: file_exists_with_trick
    arg: file
    completions:
      - $(playground get-any-file-with-fzf "$cur")
    help: |-
      üîé Search any file and open it.
      
      ‚ùï It must be absolute full path

      üéì Tip: use <tab> completion to trigger fzf completion

- name: stop
  group: Run
  help: |-
    üõë Stop currently running example

- name: remove-all-docker-images
  group: Run
  help: |-
    üß® Remove all docker images (including docker volumes)

- name: open-docs
  group: Run
  help: |-
    üßë‚Äçüéì Open Confluent documentation of currently running example
  flags:
  - long: --only-show-url
    help: |-
      üåê Only show url

- name: repro
  expose: always
  group: Repro
  help: |-
    üë∑‚Äç‚ôÇÔ∏è Reproduction model commands
  environment_variables:
  - name: OUTPUT_FOLDER 
    help: üìÅ Output folder where to generate bootstrapped files
    default: reproduction-models
  dependencies:
    fzf: visit https://github.com/junegunn/fzf#installation to install
  commands:

  - name: export
    help: |-
      üì§ Export as tgz file uncommitted reproduction models from the folder of current reproduction model
    dependencies:
      git: visit https://git-scm.com/downloads to install
    flags:
      - long: --all
        required: false
        help: |-
          Export all uncommitted reproduction models

  - name: import
    help: |-
      üì• Import tgz file which was created with export command
    flags:
    - long: --file
      short: -f
      arg: file
      required: false
      validate: file_exists_with_trick
      completions:
        - $(playground get-playground-repro-export-with-fzf "$cur")
      help: |- 
        ü§ê playground_repro_export.tgz file

        ‚ùï It must be absolute full path

        üéì Tip: use <tab> completion to trigger fzf completion 
                use playground config folder_zip_or_jar <folder1> <folder2>... (default is home folder and current folder is always included) to configure where to search the files

  - name: bootstrap
    help: |-
      üõ†  Bootstrap reproduction model
      
      üëâ Check documentation https://kafka-docker-playground.io/#/reusables?id=%f0%9f%9b%a0-bootstrap-reproduction-model
    catch_all:
      label: arguments
      help: |-
        Arguments to use by example script

        Most of examples support to get required options either by using arguments or environment variables.
        
        Example with Zendesk:

        playground run -f zendesk-source<tab> <ZENDESK_URL> <ZENDESK_USERNAME> <ZENDESK_PASSWORD>
      required: false
    flags:
    - *tag
    - *connector-tag
    - *connector-zip
    - *connector-jar
    - *enable-ksqldb
    - *enable-rest-proxy
    - *enable-control-center
    - *enable-conduktor
    - *enable-multiple-brokers
    - *enable-multiple-connect-workers
    - *enable-jmx-grafana
    - *enable-kcat
    - *enable-sql-datagen
    - *cluster-type
    - *cluster-region
    - *cluster-environment
    - *cluster-name
    - *cluster-creds
    - *cluster-schema-registry-creds

    - long: --file
      short: -f
      required: false
      validate: file_exists_with_trick
      arg: file
      completions:
        - $(playground get-examples-list-with-fzf --without-repro "$cur")
      help: |-
        üîñ Example file to use as basis, if not set, currently running example is used
        
        ‚ùï It must be absolute full path

        üéì Tip: use <tab> completion to trigger fzf completion

    - long: --description
      short: -d
      required: true
      validate: not_empty
      arg: description
      help: |-
        üí≠ Description for the reproduction model

    - long: --producer
      private: true
      short: -p
      arg: producer-type
      conflicts: [--pipeline]
      default: "none"
      allowed: 
        - none
        - avro
        - avro-with-key
        - protobuf
        - protobuf-with-key
        - json-schema
        - json-schema-with-key
      help: |-
        ‚ô®Ô∏è Java producer type to use
        
        One of avro, avro-with-key, protobuf, protobuf-with-key, json-schema, json-schema-with-key

        üéì Tip: Most of times, it's much simpler to use 'playground topic produce'. Use java producer only if you have very specific requirements such as specifying record timestamp or to do perf testing (even though CLI is also good for that)

        üéì Tip: 'with-key' will also produce key with selected converter, otherwise LongConverter is used

    - long: --nb-producers
      private: true
      short: -n
      arg: nb-producers
      validate: integer
      default: ""
      help: |-
        2Ô∏è‚É£ Number of java producers to generate

    - long: --producer-schema-key
      private: true
      required: false
      help: |-
        üî∞ Schema to use for the key

        ‚ú® Copy and paste the schema you want to use for the key, save and close the file to continue

    - long: --producer-schema-value
      private: true
      required: false
      help: |-
        üî∞ Schema to use for the value

        ‚ú® Copy and paste the schema you want to use for the key, save and close the file to continue

    - long: --custom-smt
      help: |-
        ‚öôÔ∏è Add a custom SMT (which is a no-op)

    - long: --pipeline
      required: false
      validate: file_exists_with_trick
      arg: sink_file
      conflicts: [--producer]
      repeatable: true
      completions:
        - $(playground get-examples-list-with-fzf --without-repro --sink-only "$cur")
      help: |-
        üîñ Sink example file to use for creating a pipeline. multiple --pipeline flags can be used to create a pipeline with multiple sinks.
        
        ‚ùï It must be absolute full path. 

        üéì Tip: use <tab> completion to trigger fzf completion

    examples:
    - playground repro bootstrap -f hdfs2<tab> -d "simple test"
    - playground repro bootstrap -f /full/path/hdfs2-sink.sh -d "testing with avro producer" --producer avro --producer-schema-value myschema<tab>
    - playground repro bootstrap -f hdfs2<tab> -d "testing with 2 protobuf producers" --producer protobuf --nb-producers 2
    - playground repro bootstrap -f hdfs2<tab> -d "testing custom smt" --custom-smt
    - playground repro bootstrap -f debeziumpostgres<tab> -d "create pipeline" --pipeline jdbcsink<tab>

- name: get-docker-compose
  group: Kafka
  help: |-
    üêã Get docker-compose

- name: schema
  expose: always
  group: Schema
  help: |-
     üî∞ Schema commands
  commands:

  - name: get
    group: Schema
    filters:
    - not_mdc_environment
    - schema_registry_running
    help: |-
      üî∞ Get all schemas versions for specified subject (if --subject is not specified, all subjects will be used)
    flags:
      - &subject
        long: --subject
        required: false
        arg: subject
        completions:
          - $(playground get-subject-list)
        help: |-
          üìõ Subject name
      - &verbose
        long: --verbose
        short: -v
        help: üêû Show command being ran.

      - long: --deleted
        required: false
        help: |-
          üßü Include soft deleted subjects
    examples:
    - playground schema get
    - playground schema get --subject <SUBJECT>
    - playground schema get --deleted

  - name: register
    group: Schema
    filters:
    - not_mdc_environment
    - schema_registry_running
    help: |-
      ‚è∫Ô∏è Register a schema in specified subject
    flags:
      - &subject_required
        long: --subject
        required: true
        arg: subject
        completions:
          - $(playground get-subject-list)
        help: |-
          üìõ Subject name
      - *verbose
      - long: --schema
        arg: schema
        completions:
          - $(playground get-predefined-schemas "$cur")
        default: "-"
        required: false
        help: |- 
          üî• You can either:
          
          * Set your own schema (avro, json-schema, protobuf) with stdin (see example section). 

          * Use completion to select predefined schemas (or use your own schema file) üéì Tip: use <tab> completion to trigger fzf completion

    examples: |
      playground schema register --subject test-protobuf << 'EOF'
      syntax = "proto3";
      
      package com.github.vdesabou;
      
      message Customer {
          int64 count = 1;
          string first_name = 2;
          string last_name = 3;
          string address = 4;
      }
      EOF

      playground schema register --subject test-avro << 'EOF'
      {
          "type": "record",
          "namespace": "com.github.vdesabou",
          "name": "Customer",
          "fields": [
              {
                  "name": "count",
                  "type": "long",
                  "doc": "count"
              },
              {
                  "name": "first_name",
                  "type": "string",
                  "doc": "First Name of Customer"
              },
              {
                  "name": "last_name",
                  "type": "string",
                  "doc": "Last Name of Customer"
              },
              {
                  "name": "address",
                  "type": "string",
                  "doc": "Address of Customer"
              }
          ]
      }
      EOF

  - name: get-compatibility
    filters:
    - not_mdc_environment
    - schema_registry_running
    group: Schema
    help: |-
      üõ°Ô∏è Get subject-level compatibility
    flags:
    - *subject_required
    - *verbose

  - name: set-compatibility
    filters:
    - not_mdc_environment
    - schema_registry_running
    group: Schema
    help: |-
      üõ°Ô∏è Set subject-level compatibility
    flags:
    - *subject_required
    - *verbose
    - &compatibility-required
      long: --compatibility
      arg: compatibility
      allowed: 
        - BACKWARD
        - BACKWARD_TRANSITIVE
        - FORWARD
        - FORWARD_TRANSITIVE
        - FULL
        - FULL_TRANSITIVE
        - NONE
      required: true
      help: |-
        Schema Registry compatibility rule

  - name: get-mode
    filters:
    - not_mdc_environment
    - schema_registry_running
    group: Schema
    help: |-
      üîè Get subject-level mode
    flags:
    - *subject_required
    - *verbose

  - name: set-mode
    filters:
    - not_mdc_environment
    - schema_registry_running
    group: Schema
    help: |-
      üîè Set subject-level mode

      To enable mode changes on a Schema Registry cluster, you must also set mode.mutability=true in the Schema Registry properties file before starting Schema Registry
    flags:
    - *subject_required
    - *verbose
    - long: --mode
      arg: mode
      allowed: 
        - IMPORT
        - READONLY
        - READWRITE
      required: true
      help: |-
        Schema Registry mode

  - name: delete
    filters:
    - not_mdc_environment
    - schema_registry_running
    group: Schema
    help: |-
      üßü Delete schema
    flags:
    - &subject_not_required
      long: --subject
      required: false
      arg: subject
      completions:
        - $(playground get-subject-list)
      help: |-
        üìõ Subject name to delete:
          
          if --version is provided, only that version will be deleted. Otherwise the complete subject will be deleted
    - long: --version
      required: false
      validate: integer
      arg: version
      help: |-
        üî¢ Schema version of the provided subject to delete

        Can only be used when --subject is provided
    - long: --permanent
      required: false
      help: |-
        üíÄ Hard delete (default is soft delete)
    - *verbose
        
- name: debug
  expose: always
  group: Debug
  help: |-
    üêû Debug commands
  commands:

  - name: install-vscode-extension
    help: |-
      ü™Ñ Install a slightly modified version of "Shell Script Command Completion" Visual Studio Code extension (https://marketplace.visualstudio.com/items?itemName=tetradresearch.vscode-h2o)

      After installation, install "playground" command:

      * Go on a .sh file

      * Type Ctrl+Shift+P (or ‚åò+‚áß+P on macOS) and choose "Shell Completion: Load Command Spec (experimental)"" and then type "playground"
      
      üëâ Check documentation https://kafka-docker-playground.io/#/cli?id=%f0%9f%aa%84-setup-shell-script-command-completion-visual-studio-code-extension
    examples:
    - playground install-vscode-extension
    dependencies:
      code: visit https://code.visualstudio.com/docs/setup/mac#_launching-from-the-command-line to install

  - name: enable-remote-debugging
    help: |-
      ‚ú® Enable java remote debugging for container
      
      üëâ Check documentation https://kafka-docker-playground.io/#/reusables?id=%e2%9c%a8-remote-debugging
    flags:
      - &container
        long: --container
        short: -c
        required: false
        default: "connect"
        arg: container
        completions:
          - $(docker ps --format '{{.Names}}')
        help: |-
          üê≥ Container name
    examples:
    - playground debug enable-remote-debugging
    - playground debug enable-remote-debugging --container broker
    - playground debug enable-remote-debugging -c broker

  - name: testssl
    help: |-
      üîê Testing TLS/SSL encryption using https://testssl.sh/

      testssl <URI>, where <URI> is:

      host|host:port|URL|URL:port   port 443 is default, URL can only contain HTTPS protocol
    args:
    - name: arguments
      help: arguments to pass to testssl, see https://testssl.sh for all options
      required: false
    examples:
    - playground debug testssl https://google.com
    - playground debug testssl pkc-xxxx.us-west-2.aws.confluent.cloud:9092

  - name: generate-diagnostics
    help: |-
      ‚õëÔ∏è Generate a diagnostic bundle with Diagnostics Bundle Tool

      ‚ö†Ô∏è only connect and broker containers are supported for now

      see https://docs.confluent.io/platform/current/tools/diagnostics-tool.html#collect-diagnostics
    flags:
      - *container
    examples:
    - playground debug generate-diagnostics
    - playground debug generate-diagnostics --container broker

  - name: thread-dump
    help: |-
      üéØ Take a java thread dump

      üîñ It will save output to a file and open with text editor set with playground config editor <editor> (default is code)
    flags:
      - *container
    examples:
    - playground debug thread-dump
    - playground debug thread-dump --container broker

  - name: heap-dump
    help: |-
      üëª Take a heap dump

      üîñ It will save output to a .hprof file. VisualVM (https://visualvm.github.io/) or MAT (https://www.eclipse.org/mat/) can be used to read the file.
    flags:
      - *container
    examples:
    - playground debug heap-dump
    - playground debug heap-dump --container broker

  - name: tcp-dump
    help: |-
      üïµÔ∏è‚Äç‚ôÇÔ∏è Take a tcp dump (sniffing network)
    flags:
      - *container
      - long: --port
        arg: port
        validate: integer
        required: false
        help: |-
          Port on which tcp dump should be done, if not set sniffing is done on every port
      - long: --duration
        arg: duration
        validate: integer
        required: false
        default: "30"
        help: |-
          Duration of the dump (default is 30 seconds).
    examples:
    - playground debug tcp-dump --container control-center --port 9021 --duration 60

  - name: block-traffic
    help: |-
      üö´ Blocking traffic using iptables
    flags:
      - *container
      - long: --destination
        arg: destination
        required: true
        help: |-
          Destination: it could be an ip address, a container name or a hostname
      - long: --port
        arg: port
        validate: integer
        required: false
        help: |-
          Port on which tcp traffic should be blocked
      - &action
        long: --action
        allowed: [start, stop]
        arg: action
        required: true
        help: |-
          üü¢ start or stop
    examples:
    - playground debug block-traffic --destination google.com --action start
    - playground debug block-traffic --container broker --destination zookeeper --action start

  - name: flight-recorder
    help: |-
      üõ©Ô∏è Record flight recorder

      Read more about it at https://www.baeldung.com/java-flight-recorder-monitoring

      Open the jfr file with JDK Mission Control JMC(https://jdk.java.net/jmc/)
    flags:
      - *container
      - *action
    examples:
    - playground debug flight-recorder --action start
    - playground debug flight-recorder --action stop

  - name: log-level
    help: |-
      üß¨ Set log level for any package
    filters:
    - connect_running
    commands:
    - name: get
      help: Get log levels
      flags:
      - &package
        long: --package
        short: -p
        required: false
        validate: not_empty
        arg: package
        help: |-
          Package name

    - name: set
      help: Set log level for specific logger
      flags:
      - long: --package
        short: -p
        required: true
        validate: not_empty
        arg: package
        help: |-
          üì¶ Package name

      - &level
        long: --level
        short: -l
        arg: level
        allowed: [INFO, WARN, DEBUG, TRACE]
        required: true
        help: |-
          ‚ùïLog level

    examples:
    - playground debug log-level get
    - playground debug log-level get -p io.confluent.connect.oracle.cdc
    - playground debug log-level get --package io.confluent.connect.oracle.cdc
    - playground debug log-level set -p io.confluent.connect.oracle.cdc.logging.LogUtils -l TRACE

- name: get-jmx-metrics
  group: Kafka
  help: |-
    üî¢ Get JMX metrics from a component
    
    üëâ Check documentation https://kafka-docker-playground.io/#/how-to-use?id=%f0%9f%94%a2-jmx-metrics
  dependencies:
    java: visit https://openjdk.org/install/ to install
  flags:
  - long: --component
    short: -c
    default: "connect"
    required: false
    arg: component
    allowed: [zookeeper, broker, connect, schema-registry]
    help: |-
      Component name
  - long: --open
    short: -o
    help: |- 
      üîñ Save output to a file and open with text editor set with playground config editor <editor> (default is code)

  - long: --domain
    short: -d
    required: false
    arg: domain
    help: |-
      Domain name

  examples:
  - playground get-jmx-metrics --component connect
  - playground get-jmx-metrics --component connect --domain "kafka.connect kafka.consumer kafka.producer"
  - playground get-jmx-metrics -c broker

- name: container
  expose: always
  group: Container
  help: |-
    üê≥ Container commands
  commands:

    - name: get-properties
      help: |-
        üìù Get properties file from a container
        
        üëâ Check documentation https://kafka-docker-playground.io/#/how-to-use?id=%f0%9f%93%9d-see-properties-file

      flags:
      - *container
      examples:
      - playground get-properties
      - playground get-properties --container broker
      - playground get-properties -c broker

    - name: recreate
      group: Container
      help: |-
        üí´ Recreate container(s)
        
        üëâ Check documentation https://kafka-docker-playground.io/#/how-to-use?id=%e2%99%bb%ef%b8%8f-re-create-containers
      flags:
      - long: --ignore-current-versions
        required: false
        help: |-
          Ignore current confluent platform version

          By default, the current version is used

    - name: get-ip-addresses
      group: Container
      help: |-
        üñ•Ô∏è  Get ip address of running containers
      examples:
      - playground get-ip-address-container

    - name: kill-all
      group: Container
      help: |-
        üíÄ Kill all containers

    - name: logs
      group: Container
      help: |-
        üïµÔ∏è  Tail and follow container logs

      flags:
      - *container
      - long: --open
        short: -o
        help: |- 
          üîñ Save output to a file and open with text editor set with playground config editor <editor> (default is code)
        conflicts: [--wait-for-log]
      - long: --wait-for-log
        short: -w
        arg: log
        validate: not_empty
        help: |- 
          üò¥ Wait until log appears
        conflicts: [--open]
      - long: --max-wait
        short: -m
        arg: max_wait
        validate: integer
        default: "600"
        help: |- 
          ‚è≥ Max time in seconds to wait when using --wait-for-log (default 600s)
        conflicts: [--open]

      examples:
      - playground container logs --container connect
      - playground container logs -c connect --open
      - playground container logs -c connect --wait-for-log "StackOverflowError"

    - name: ssh
      group: Container
      help: |-
        üõ¨ SSH into container

      flags:
      - *container

      - long: --shell
        short: -s
        required: false
        default: "bash"
        arg: shell
        allowed: 
          - bash
          - sh
          - ksh
          - zsh
        help: |-
          üíæ Shell to use (default is bash)

      examples:
      - playground ssh -c connect
      - playground ssh -c connect -s sh
      - playground ssh --container connect --shell sh

    - name: exec
      group: Container
      help: |-
        ü™Ñ  Execute command in a container

      flags:
      - *container

      - long: --command
        required: true
        validate: not_empty
        arg: command
        help: |-
          üì≤ Command to execute

      - long: --root
        help: |-
          üëë Run command as root

      - long: --shell
        default: "bash"
        arg: shell
        allowed: 
          - bash
          - sh
          - ksh
          - zsh
        help: |-
          üíæ Shell to use (default is bash)

      examples:
      - playground exec -c connect -d "date"
      - playground exec -c connect -d "whoami" --root
      - playground exec --container connect --command "whoami" --shell sh

    - name: restart
      group: Container
      help: |-
        üîÅ Restart a container

      flags:
      - *container

    - name: pause
      group: Container
      help: |-
        ‚è∏Ô∏è  Pause a container

      flags:
      - *container

    - name: resume
      alias: unpause
      group: Container
      help: |-
        ‚èØÔ∏è  Resume a container

      flags:
      - *container

    - name: kill
      group: Container
      help: |-
        üî´ Kill a container

      flags:
      - *container

- name: topic
  expose: always
  group: Topic
  filters:
  - not_mdc_environment
  help: |-
    üó≥ Topic commands
  commands:

    - name: get-number-records
      group: Topic
      help: |-
        üíØ Get number of records in a topic
      flags:
      - &topic
        long: --topic
        short: -t
        required: false
        arg: topic
        completions:
          - $(playground get-topic-list)
        help: |-
          üó≥ Topic name
      examples:
      - playground get-number-records --topic a-topic
      - playground get-number-records -t a-topic

    - name: display-consumer-offsets
      group: Topic
      help: |-
        üì≠ Display content of __consumer_offsets topic
      flags:
      - *verbose

    - name: list
      group: Topic
      help: |-
        üîò List topics

    - name: describe
      group: Topic
      help: |-
        üî¨ Describe topic
      flags:
      - *topic
      - *verbose

    - name: set-schema-compatibility
      filters:
      - schema_registry_running
      group: Topic
      help: |-
        üõ°Ô∏è Change topic's schema compatibility
      flags:
      - *topic
      - *compatibility-required
      - *verbose

    - name: consume
      filters:
      - schema_registry_running
      group: Topic
      help: |-
        üì• Consume topic from beginning
      flags:
      - *verbose
      - *topic
      - long: --max-messages
        arg: max-messages
        validate: integer
        required: false
        default: "10"
        help: |-
          Max number of messages to display (default is 10)
      - long: --min-expected-messages
        arg: min-expected-messages
        validate: integer
        required: false
        default: ""
        help: |-
          Minimum expected number of messages to be present in topic, returns an error if this is not the case

          Note: --topic should be specified in this case.
      - long: --grep
        arg: grep
        required: false
        default: ""
        help: |-
          Verify that topic content contains record which contains specified string
      - long: --timeout
        arg: timeout
        validate: integer
        required: false
        default: "60"
        help: |-
          Max number of seconds to wait when --min-expected-messages is used.

          Default is 60 seconds
      - long: --tail
        required: false
        help: |-
          Tail on logs.
        conflicts: [--min-expected-messages, --max-messages]

      - long: --plot-latencies-timestamp-field
        required: false
        arg: timestamp
        help: |-
          üó≥ Timestamp field name that represents when record was created in source system

      - long: --key-subject
        required: false
        arg: key-subject
        completions:
          - $(playground get-subject-list)
        help: |-
          üìõ Subject for key in schema-registry to use (useful when data was produced with --key-subject-name-strategy other than TopicNameStrategy)
          
          Note: --topic should be specified in this case.

      - long: --value-subject
        required: false
        arg: value-subject
        completions:
          - $(playground get-subject-list)
        help: |-
          üìõ Subject for value in schema-registry to use (useful when data was produced with --value-subject-name-strategy other than TopicNameStrategy)
          
          Note: --topic should be specified in this case.

      - long: --max-characters
        arg: max-characters
        validate: integer
        required: false
        default: "2500"
        help: |-
          Max characters per message to display (default is 2500)

    - name: produce
      filters:
      - schema_registry_running
      group: Topic
      help: |-
         üì§ Produce to a topic
      flags:

      - long: --key
        arg: key
        required: false
        completions:
          - $(playground get-predefined-schemas "$cur")
        help: |-
          üóùÔ∏è Key to use. If not set, no key is used.

          üî• You can either:
          
          * Set your own schema (avro, json-schema, protobuf) within single quotes (see examples) 
          
          * You can also generate json data using json or sql format using syntax from https://github.com/MaterializeInc/datagen

          * Use completion to select predefined schemas (or use your own schema file) üéì Tip: use <tab> completion to trigger fzf completion

          * Directly set payload ("%g" can be used to generate a counter)

          In case of 'raw' data (i.e not using schema):

          If the key contain a number, it will be used as starting point and incremented for each record. 
          
          Example: key1 will start with key1, then key2, etc..
          Example: mykey-10-suffix will start with mykey-10-suffix then mykey-11-suffix, etc..

          "%g" can also be used to generate a counter

          Example: key%g will start with key1, then key2, etc..

          Otherwise, the key will be same for all records.

      - long: --value
        arg: value
        completions:
          - $(playground get-predefined-schemas "$cur")
        default: "-"
        required: false
        help: |- 
          üî• You can either:
          
          * Set your own schema (avro, json-schema, protobuf) with stdin (see example section). 
          
          * You can also generate json data using json or sql format using syntax from https://github.com/MaterializeInc/datagen

          * Use completion to select predefined schemas (or use your own schema file) üéì Tip: use <tab> completion to trigger fzf completion

          * Directly set payload ("%g" can be used to generate a counter)

      - *verbose
      - long: --debug
        short: -d
        required: false
        private: true
        help: |-
          debug mode (internal)
      - long: --topic
        short: -t
        required: true
        arg: topic
        completions:
          - $(playground get-topic-list)
        help: |-
          üó≥ Topic name
      - long: --nb-messages
        arg: nb-messages
        validate: integer
        required: false
        default: "1"
        help: |-
          üíØ Number of messages to produce (default is 1)
             
          üéì  - if > <value of --max-nb-messages-per-batch> (default 300000), messages will be sent in batches of <value of --max-nb-messages-per-batch> (default 300000) records
              - if you set it to -1, an infinite number of records will also be sent in batches
      - long: --max-nb-messages-per-batch
        arg: max-nb-messages-per-batch
        validate: integer
        required: false
        default: "300000"
        help: |-
          üîº Max number of messages to send per batch when --nb-messages > --max-nb-messages-per-batch
             if --nb-messages is set to -1, this is the number of messages sent per batch
             default is 300000
      - long: --sleep-time-between-batch
        arg: sleep-time-between-batch
        validate: integer
        required: false
        default: "0"
        help: |-
          üí§ Sleep time in seconds between batches
             default is 0
      - long: --nb-partitions
        arg: nb-partitions
        validate: integer
        required: false
        default: ""
        help: |-
          üî¢ Number of partitions for the topic. (default is 1)
          
          ‚ùå Important: If topic is existing, it will be re-created before producing to topic.
      - long: --compression-codec
        arg: compression-codec
        required: false
        allowed: 
          - gzip
          - snappy
          - lz4
          - zstd
        help: |-
          ü§ê The compression codec: either 'gzip', 'snappy', 'lz4', or 'zstd'
          If not set, there is no compression

      - &compatibility
        long: --compatibility
        arg: compatibility
        allowed: 
          - BACKWARD
          - BACKWARD_TRANSITIVE
          - FORWARD
          - FORWARD_TRANSITIVE
          - FULL
          - FULL_TRANSITIVE
          - NONE
        help: |-
          Schema Registry compatibility rule

      - &key-subject-name-strategy
        long: --key-subject-name-strategy
        arg: key-subject-name-strategy
        allowed: 
          - TopicNameStrategy
          - RecordNameStrategy
          - TopicRecordNameStrategy
        help: |-
          Key Subject Name Strategy

      - &value-subject-name-strategy
        long: --value-subject-name-strategy
        arg: value-subject-name-strategy
        allowed: 
          - TopicNameStrategy
          - RecordNameStrategy
          - TopicRecordNameStrategy
        help: |-
          Value Subject Name Strategy

      - long: --headers
        arg: headers
        required: false
        help: |-
          üöè Headers to use for all records. If not set, no header is used.

          Example: --headers "header1:value1,header2:value2"

          Note: CP 7.2+ is required.
      - long: --forced-key
        arg: forced-key
        required: false
        help: |-
          ‚ò¢Ô∏è Key to use for all records. 
          
          üéì Tip: use --generate-only first with avro, json-schema or protobuf to get skeleton of messages and then use --forced-key to send the message you need. 
      - long: --forced-value
        arg: forced-value
        required: false
        help: |-
          ‚ò¢Ô∏è Value to use for all records. 
          
          üéì Tip: use --generate-only first with avro, json-schema or protobuf to get skeleton of messages and then use --forced-value to send the message you need. 
      - long: --generate-only
        required: false
        help: |-
          üö™ Only generate messages without sending to kafka topic.

          Used with --forced-value, this is a powerful way to send specific messages.
      - long: --tombstone
        required: false
        help: |-
          ‚ö∞Ô∏è Generate tombstone (record with null value). 
          
          --key must be set when this flag is used.

          Note: CP 7.2+ is required.
      - long: --validate
        required: false
        help: |-
          ‚òëÔ∏è Validate schema according to connect sink converter used

      - long: --validate-config
        arg: validate-config
        help: |-
          üî© Converter configuration parameters to use 
          
          See docs: https://docs.confluent.io/platform/current/schema-registry/connect.html#using-kconnect-long-with-sr

          üéì Tip: you can pass multiple parameters by specifying --validate-config multiple times
        required: false
        repeatable: true
        allowed: 
          - scrub.invalid.names=true
          - enhanced.avro.schema.support=true
          - connect.meta.data=false
          - object.additional.properties=false
          - use.optional.for.nonrequired=true
          - ignore.default.for.nullables=true
          - generalized.sum.type.support=true
          - enhanced.protobuf.schema.support=true
          - generate.index.for.unions=false
          - int.for.enums=true
          - optional.for.nullables=true
          - generate.struct.for.nulls=true
          - wrapper.for.nullables=true
          - wrapper.for.raw.primitives=false

      - long: --producer-property
        arg: producer-property
        help: |-
          üî© Producer configuration parameters to use 
          
          See docs: https://docs.confluent.io/platform/current/installation/configuration/producer-configs.html#cp-config-producer

          üéì Tip: you can pass multiple parameters by specifying --producer-property multiple times

          Example: --producer-property "max.request.size=990485760" --producer-property "client.id=myid"
        required: false
        repeatable: true

      - long: --record-size
        arg: record-size
        validate: integer
        required: false
        default: "0"
        help: |-
          üèãÔ∏è Record size in bytes, eg. 1048576 for 1MB

          üì¢ If size is > 1Mb, --producer-property max.request.size and topic max.message.bytes will be automatically set to support the record size.

      examples: |

        playground topic produce --tombstone --topic a-topic --key mykey

        playground topic produce -t topic-json --nb-messages 10 << 'EOF'
        {
            "_meta": {
                "topic": "",
                "key": "",
                "relationships": []
            },
            "nested": {
                "phone": "faker.phone.imei()",
                "website": "faker.internet.domainName()"
            },
            "id": "iteration.index",
            "name": "faker.internet.userName()",
            "email": "faker.internet.exampleEmail()",
            "phone": "faker.phone.imei()",
            "website": "faker.internet.domainName()",
            "city": "faker.address.city()",
            "company": "faker.company.name()"
        }
        EOF

        playground topic produce -t topic-avro --nb-messages 10 << 'EOF'
        {
          "fields": [
            {
              "name": "count",
              "type": "long"
            },
            {
              "name": "first_name",
              "type": "string"
            },
            {
              "name": "last_name",
              "type": "string"
            },
            {
              "default": null,
              "name": "address",
              "type": [
                "null",
                "string"
              ]
            },
            {
              "name": "last_sale_date",
              "type": {
                "logicalType": "timestamp-millis",
                "type": "long"
              }
            },
            {
              "name": "last_sale_price",
              "type": {
                "logicalType": "decimal",
                "precision": 15,
                "scale": 2,
                "type": "bytes"
              }
            },
            {
              "name": "last_connection",
              "type": {
                "logicalType": "date",
                "type": "int"
              }
            }
          ],
          "name": "Customer",
          "namespace": "com.github.vdesabou",
          "type": "record"
        }
        EOF

        playground topic produce -t topic-json-schema --nb-messages 3 << 'EOF'
        {
          "$schema": "http://json-schema.org/draft-07/schema#",
          "additionalProperties": false,
          "$id": "http://lh.test/Customer.schema.json",
          "title": "Customer",
          "description": "Customer description",
          "type": "object",
          "properties": {
            "name": {
              "description": "Customer name",
              "type": "string",
              "maxLength": 25
            },
            "surname": {
              "description": "Customer surname",
              "type": "string",
              "minLength": 2
            },
            "email": {
              "description": "Email",
              "type": "string",
              "pattern": "^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$"
            }
          },
          "required": [
            "name",
            "surname"
          ]
        }
        EOF


        playground topic produce -t topic-proto --nb-messages 1 << 'EOF'
        syntax = "proto3";

        package com.github.vdesabou;

        message Customer {
            int64 count = 1;
            string first_name = 2;
            string last_name = 3;
            string address = 4;
        }
        EOF

        playground topic produce -t topic-jsql --nb-messages 10 << 'EOF'
        CREATE TABLE "notused"."notused" (
          "id" int PRIMARY KEY,
          "name" varchar COMMENT 'faker.internet.userName()',
          "merchant_id" int NOT NULL COMMENT 'faker.datatype.number()',
          "price" int COMMENT 'faker.datatype.number()',
          "status" int COMMENT 'faker.datatype.boolean()',
          "created_at" datetime DEFAULT (now())
        );
        EOF

        playground topic produce -t topic-json --nb-messages 1 --producer-property "max.request.size=990485760" < bigjson.json

        playground topic produce -t topic-string --nb-messages 5000 << 'EOF'
        Ad et ut pariatur officia eos.
        Nesciunt fugit nam libero ut qui itaque sed earum at itaque nesciunt eveniet atque.
        Quidem libero quis quod et illum excepturi voluptas et in perspiciatis iusto neque.
        Quibusdam commodi explicabo dolores molestiae qui delectus dolorum fugiat molestiae natus assumenda omnis expedita.
        Et sunt aut architecto suscipit fugiat qui voluptate iure vel doloremque eum culpa.
        Qui enim facilis eos similique aperiam totam eius et at dolor dolores.
        Ut sunt quia qui quia consectetur aut reiciendis.
        Modi adipisci iusto aut voluptatem dolores laudantium.
        Sequi sint quia quibusdam molestias minus et aliquid voluptatum aliquam.
        Rerum aut amet quo possimus nihil velit quisquam ut cumque.
        Pariatur ad officiis voluptatibus quia vel corporis ea fugit adipisci porro.
        EOF

        # key and headers
        # mykey1 %g can also be used
        playground topic produce -t topic-json-multiple-lines --nb-messages 10 --key "mykey1" --headers "header1:value1,header2:value2" << 'EOF'
        {"u_name": "scissors", "u_price": 2.75, "u_quantity": 3}
        {"u_name": "tape", "u_price": 0.99, "u_quantity": 10}
        {"u_name": "notebooks", "u_price": 1.99, "u_quantity": 5}
        EOF

        # avro key
        playground topic produce -t topic-avro-with-key --nb-messages 10 --key '
        {
          "fields": [
            {
              "name": "id",
              "type": "long"
            }
          ],
          "name": "Key",
          "namespace": "com.github.vdesabou",
          "type": "record"
        }
        ' << 'EOF'
        {
          "fields": [
            {
              "doc": "count",
              "name": "count",
              "type": "long"
            },
            {
              "doc": "First Name of Customer",
              "name": "first_name",
              "type": "string"
            },
            {
              "doc": "Last Name of Customer",
              "name": "last_name",
              "type": "string"
            }
          ],
          "name": "Customer",
          "namespace": "com.github.vdesabou",
          "type": "record"
        }
        EOF

        # tombstone
        playground topic produce -t topic-json-multiple-lines --tombstone --key "mykey1"

        # input file
        playground topic produce -t topic-avro-example3 < avro-schema.avsc

        # record-size
        playground topic produce -t topic-avro-example-big-size --nb-messages 3 --record-size 10000000 << 'EOF'
        {
          "fields": [
            {
              "doc": "count",
              "name": "count",
              "type": "long"
            },
            {
              "doc": "First Name of Customer",
              "name": "first_name",
              "type": "string"
            },
            {
              "doc": "Last Name of Customer",
              "name": "last_name",
              "type": "string"
            },
            {
              "doc": "Address of Customer",
              "name": "address",
              "type": "string"
            }
          ],
          "name": "Customer",
          "namespace": "com.github.vdesabou",
          "type": "record"
        }
        EOF

        # validate
        playground topic produce -t topic-json-schema-validate --nb-messages 3 --validate << 'EOF'
        {
          "$schema": "http://json-schema.org/draft-07/schema#",
          "additionalProperties": false,
          "$id": "http://lh.test/Customer.schema.json",
          "title": "Customer",
          "description": "Customer description",
          "type": "object",
          "properties": {
            "name": {
              "description": "Customer name",
              "type": "string",
              "maxLength": 25
            },
            "surname": {
              "description": "Customer surname",
              "type": "string",
              "minLength": 2
            },
            "email": {
              "description": "Email",
              "type": "string",
              "pattern": "^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$"
            },
            "holiday": {
              "oneOf": [
                {
                  "title": "Not included",
                  "type": "null"
                },
                {}
              ]
            },
            "f2": {}
          },
          "required": [
            "name",
            "surname"
          ]
        }
        EOF

        #  --value-subject-name-strategy
        playground topic produce -t topic-avro-example-value-subject-name-strategy --nb-messages 10 --value-subject-name-strategy TopicRecordNameStrategy << 'EOF'
        {
          "fields": [
            {
              "doc": "count",
              "name": "count",
              "type": "long"
            },
            {
              "doc": "First Name of Customer",
              "name": "first_name",
              "type": "string"
            },
            {
              "doc": "Last Name of Customer",
              "name": "last_name",
              "type": "string"
            },
            {
              "doc": "Address of Customer",
              "name": "address",
              "type": "string"
            }
          ],
          "name": "Customer",
          "namespace": "com.github.vdesabou",
          "type": "record"
        }
        EOF

        # --generate-only
        playground topic produce -t topic-avro-example-forced-value --nb-messages 10  --generate-only << 'EOF'
        {
          "fields": [
            {
              "doc": "count",
              "name": "count",
              "type": "long"
            },
            {
              "doc": "First Name of Customer",
              "name": "first_name",
              "type": "string"
            },
            {
              "doc": "Last Name of Customer",
              "name": "last_name",
              "type": "string"
            },
            {
              "doc": "Address of Customer",
              "name": "address",
              "type": "string"
            },
            {
              "name": "createdDate",
              "type": {
                "logicalType": "timestamp-millis",
                "type": "long"
              }
            },
            {
              "default": null,
              "name": "warranty_expiration",
              "type": [
                "null",
                {
                  "logicalType": "date",
                  "type": "int"
                }
              ]
            }
          ],
          "name": "Customer",
          "namespace": "com.github.vdesabou",
          "type": "record"
        }
        EOF

        # --forced-value
        playground topic produce -t topic-avro-example-forced-value --nb-messages 1 --forced-value '{"count":4,"first_name":"Vincent","last_name":"de Saboulin","address":"xxx","createdDate":1697852606000,"warranty_expiration":{"int":19653}}' << 'EOF'
        {
          "fields": [
            {
              "doc": "count",
              "name": "count",
              "type": "long"
            },
            {
              "doc": "First Name of Customer",
              "name": "first_name",
              "type": "string"
            },
            {
              "doc": "Last Name of Customer",
              "name": "last_name",
              "type": "string"
            },
            {
              "doc": "Address of Customer",
              "name": "address",
              "type": "string"
            },
            {
              "name": "createdDate",
              "type": {
                "logicalType": "timestamp-millis",
                "type": "long"
              }
            },
            {
              "default": null,
              "name": "warranty_expiration",
              "type": [
                "null",
                {
                  "logicalType": "date",
                  "type": "int"
                }
              ]
            }
          ],
          "name": "Customer",
          "namespace": "com.github.vdesabou",
          "type": "record"
        }
        EOF
    - name: create
      group: Topic
      help: |-
        üÜï Create topic
      flags:
      - *verbose
      - long: --topic
        short: -t
        required: true
        arg: topic
        help: |-
          üó≥ Topic name
      - long: --nb-partitions
        arg: nb-partitions
        validate: integer
        required: false
        default: ""
        help: |-
          Number of partitions for the topic. (default is 1)
      catch_all:
        label: arguments
        help: |-
          Any arguments to be used with kafka-topics --create
        required: false
      examples: |
        playground topic create --topic atopic
        playground topic create --topic atopic --nb-partitions 8 --config retention.ms=30000 --config cleanup.policy=compact
        
    - name: delete
      group: Topic
      help: |-
        ‚ùå Delete topic and associated schema/subject if applicable
      flags:
      - *verbose
      - long: --topic
        short: -t
        required: true
        arg: topic
        completions:
          - $(playground get-topic-list)
        help: |-
          üó≥ Topic name
      - long: --skip-delete-schema
        arg: skip-delete-schema
        required: false
        help: |-
          üî∞ Do not delete subject/schema

    - name: alter
      group: Topic
      help: |-
        ü™õ Alter topic config
      flags:
      - *verbose
      - long: --topic
        short: -t
        required: true
        arg: topic
        completions:
          - $(playground get-topic-list)
        help: |-
          üó≥ Topic name
      catch_all:
        label: arguments
        help: |-
          Any arguments to be used with kafka-configs --alter. If the topic does not exist, it is created first.
        required: false
      examples: |
        playground topic alter --topic atopic --add-config max.message.bytes=5242940

- name: connector-plugin
  expose: always
  group: Connector-Plugin
  help: |-
    üîå Connector-plugin commands

  commands:
  - name: search-jar
    help: ‚òï List jars for a connector plugin from confluent hub https://www.confluent.io/hub/
          Search for specific class and display method signatures
    dependencies:
      javap: visit https://openjdk.org/install/ to install
    flags:
    - &connector-plugin
      long: --connector-plugin
      short: -c
      required: true
      arg: connector-plugin
      completions:
        - $(playground get-connector-plugin "$cur")
      help: |-
        üîå Connector plugin name

        üéì Tip: use <tab> completion to trigger fzf completion
    - *connector-tag
    - long: --class
      arg: class
      required: false
      help: |- 
        ‚òï Java class name to search for in all jars
    examples: |
      playground connector-plugin search-jar --connector-plugin confluentinc/kafka-connect-s3 --class WebIdentityTokenCredentialsProvider

  - name: versions
    help: üíØ List versions for a connector plugin from confluent hub https://www.confluent.io/hub/
    flags:
    - *connector-plugin
    - &force_refresh
      long: --force-refresh
      required: false
      help: |-
        ‚ò¢Ô∏è Force refresh.
    - long: --last
      arg: last
      required: false
      validate: integer
      conflicts: [--all]
      help: |-
        üÜï Number of last versions to show
    examples: |
      playground connector-plugin versions --connector-plugin confluentinc/kafka-connect-s3

- name: connector
  expose: always
  group: Connector
  filters:
  - not_mdc_environment
  help: |-
    üîó Connector commands

  commands:
  - name: status
    help: üß© Show status of all connectors
    flags:
    - *verbose
    - &connector
      long: --connector
      short: -c
      required: false
      arg: connector
      completions:
        - $(playground get-connector-list)
      help: |-
        üîó Connector name

        üéì Tip: If not specified, the command will apply to all connectors

  - name: plugins
    help: üé® Show all connector plugins installed. You can also display transforms, converters and predicates using --all flag
    flags:
    - *verbose
    - long: --all
      required: false
      help: |-
        üåï Show also transforms, converters, predicates available

  - name: pause
    help: ‚è∏Ô∏è  Pause connector
    flags:
    - *verbose
    - *connector

  - name: versions
    help:  |
      üßû Get current and latest versions available on Confluent Hub for connector(s) used in example

  - name: restart
    help: ‚ôªÔ∏è  Restart connector
    flags:
    - *verbose
    - *connector

  - name: stop
    help: üõë Stop connector (only available if CP > 7.5 )
    flags:
    - *verbose
    - *connector

  - name: resume
    alias: unpause
    help: ‚èØÔ∏è  Resume connector
    flags:
    - *verbose
    - *connector

  - name: delete
    help: üóëÔ∏è  Delete connector
    flags:
    - *verbose
    - *connector

  - name: show-lag
    help: |
      üê¢ Show lag of sink connector

      It will run until all lag becomes 0 (press ctrl-c to exit)
    flags:
    - *verbose
    - *connector
    - long: --interval
      arg: interval
      validate: integer
      required: false
      default: "20"
      help: |-
        Interval between lag checks (default is 20 seconds).

  - name: show-config
    help:  |
      üß∞ Show current connector config that was applied
      
      use --force-rest-endpoint to get results with REST API /config endpoint (https://docs.confluent.io/platform/current/connect/references/restapi.html#get--connectors-(string-name)-config)
    flags:
    - *verbose
    - *connector
    - &noclipboard
      long: --no-clipboard
      required: false
      private: true
      help: |-
        do not copy to clipboard (internal)
    - long: --force-rest-endpoint
      required: false
      help: |-
        ‚ò¢Ô∏è Force using REST API /config endpoint (https://docs.confluent.io/platform/current/connect/references/restapi.html#get--connectors-(string-name)-config)

  - name: show-config-parameters
    help: üî© Show all possible configuration parameters of connector
    flags:
    - *verbose
    - *connector
    - long: --open
      short: -o
      help: |- 
        üîñ Save output to a file and open with text editor set with playground config editor <editor> (default is code)
    - *force_refresh
    -  &only_show_file_path
      long: --only-show-file-path
      required: false
      private: true
      help: |-
        üìÇ Only show the path of the file containing the configuration parameters
    - &only_show_json
      long: --only-show-json
      required: false
      help: |-
        üìó Only show list of all available parameters for connector (with default value when applicable)
    -  &only_show_json_file_path
      long: --only-show-json-file-path
      required: false
      private: true
      help: |-
        üìÇ Only show the path of the json file containing the configuration parameters

  - name: select-config
    help: |-
      üóúÔ∏è Easily select config from all possible configuration parameters of connector

      üéì Tip: use <tab> to select multiple config at once !
    dependencies:
      fzf: visit https://github.com/junegunn/fzf#installation to install
    flags:
    - *connector

  - name: snippets
    help: üîå useful snippets
    flags:
    - long: --converter
      required: false
      arg: converter
      allowed: 
        - avro
        - protobuf
        - json-schema
        - json
        - json-schema-enabled
        - string
        - bytearray
      help: |-
        üîå Converter
    - long: --dlq
      required: false
      help: |- 
        üíÄ dlq
    examples: |
      playground connector snippets --converter avro --dlq

  - name: open-docs
    help: |-
      üßë‚Äçüéì Open connector documentation of currently running conector(s)
    flags:
    - long: --only-show-url
      help: |-
        üåê Only show url

  - name: log-level
    help: |-
      üß¨ Set connect log level

      üéì Tip: it will also set io.confluent.kafka.schemaregistry.client.rest.RestService (to see schema registry rest requests) and org.apache.kafka.connect.runtime.TransformationChain (to see records before and after SMTs)
    flags:
    - *connector
    - *level

  - name: create-or-update
    help: üßë‚Äçüé®  Create or update connector
    args:
    - name: json
      
      # Set the default path value to -, which is the standard operator for stdin.
      default: "-"
      help: json (reads from stdin if empty)

    flags:
    - *verbose
    - long: --connector
      short: -c
      required: true
      arg: connector
      completions:
        - $(playground get-connector-list)
      help: |-
        üîó Connector name
    - long: --level
      short: -l
      arg: level
      allowed: [INFO, WARN, DEBUG, TRACE]
      required: false
      help: |-
        ‚ùïLog level

        ‚ö†Ô∏è Not available for ccloud connectors
    - *package
    - long: --validate
      required: false
      help: |-
        ‚úÖ Validate config using PUT /connector-plugins/(string:name)/config/validate (https://docs.confluent.io/platform/current/connect/references/restapi.html#put--connector-plugins-(string-name)-config-validate)
    examples: |
      playground connector create-or-update -c filestream-sink << EOF
      {
          "tasks.max": "1",
          "connector.class": "org.apache.kafka.connect.file.FileStreamSinkConnector",
          "topics": "filestream",
          "file": "/tmp/output.json",
          "key.converter": "org.apache.kafka.connect.storage.StringConverter",
          "value.converter": "org.apache.kafka.connect.json.JsonConverter",
          "value.converter.schemas.enable": "false"
      }
      EOF

  - name: update
    help: üõ†Ô∏è Update connector configuration by opening current connector config in text editor set with playground config editor <editor> (default is code). Once file is saved, the new configuration is updated.
    flags:
    - *connector
    examples: |
      playground connector update -c filestream-sink

  examples:
  - playground connector status
  - playground connector status --json
  - playground connector resume --connector <connector-name>
  - playground connector pause -c <connector-name>
  - playground connector delete -c <connector-name>
